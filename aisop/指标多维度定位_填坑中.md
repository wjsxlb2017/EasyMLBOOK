[TOC]

# 问题描述

<http://iops.ai/competition_detail/?competition_id=8&flag=1>


在运维场景中对监控指标的多个维度进行根因定位。具体来说，当某个总指标（如总流量）发生异常时，需要快速准确地定位到是哪个交叉维度的细粒度指标（如“省份=北京 & 运营商=联通”的流量）的异常导致的，以便尽快做进一步的修复止损操作。图示如下：

# 算法框架



调研hotspot，整体算法框架如下：

![image-20190322210515877](/Users/stellazhao/EasyML_BOOK/_image/image-20190322210515877.png)


1. 对KPI使用N-sigma进行实时异常检测，如果异常进入2

2. for  layer=1到layer= L:


   1. 剪枝：对于layer l中如果的element的属性值，没有出现在l-1(上一层的Bset中)，那就把elements去掉。剪掉之后生成备选的elements给2用。
   2. 使用蒙特卡洛搜索树寻找最有可能是根因的维度组合$B_set$，这里的reward function = potential score（potential score翻译成根因概率吧，表示该维度为故障根因的概率)，

   3. 如果potential score超过指定PS或者迭代时长超过给定值或者所有维度都便利过了一遍，迭代终止，返回对应的维度组合。




# 符号说明

![image-20190322211056826](/Users/stellazhao/EasyML_BOOK/_image/image-20190322211056826.png)



$e_i$: $e=(p, i, d, c) ​$，表示多个属性值的组合，是有具体的取值的.![image-20190322212044105](/Users/stellazhao/Library/Application Support/typora-user-images/image-20190322212044105.png)

$v(e_i)​$:某个维度上指标的实际值。

$f(e_i)​$:某个维度上指标的预测值。

cuboids:粒度可以任意细，任意粗  $ \left\{B_{P}, B_{P, I}, B_{P, I, D}, \ldots\right\}​$
layer1，layer2，。。。layer3的解释如下
![image-20190322220603157](/Users/stellazhao/EasyML_BOOK/_image/image-20190322220603157.png)



data cube: 多维的时序数据

ps: 衡量一组$S=\{e_i\}$是根因的概率。

e的后继结点：$\operatorname{Desc}(e)=\left\{e^{\prime} | e^{\prime} \text { is a descendant of } e\right\}$

e的后继LEAF结点：$\operatorname{Desc}^{\prime} (e)=\left\{e^{\prime} | e^{\prime}  \left(p^{\prime},i^{\prime}, d^{\prime}, c^{\prime}\right) \in L E A F, e^{\prime} \in \operatorname{Desc}(e) \right\}$

为什么要单独定义LEAF维度？因为它具有可加性，加起来等于它的父节点,如下

$\begin{array}{c}{v(e)=\sum\limits_{e^{\prime} \in D e s c^{\prime}(e)} v\left(e^{\prime}\right)} \\ {\text { e.g. }} \\ {v(\text { Bei jing }, *, *, *)=\sum\limits_{j, k, h} v\left(\text {Beijing}, i_{j}, d_{k}, c_{h}\right),} \\ {\text { Total } P V=v(*, *, *, *)=\sum\limits_{i, j, k, h} v\left(p_{i}, i_{j}, d_{k}, c_{h}\right)}\end{array}​$




# potential score 

##  potential score的计算公式

- .ps的计算公式如下

  $\text { Potential Score }=\max \left(1-\frac{d(\vec{v}, \vec{a})}{d(\vec{v}, \vec{f})}, 0\right)​$

  - a表示某维度确为根因的假设下，LEAF的预期值
  - v表示LEAF的真实值
  - f表示LEAF的预期值，跟疑似维度无关

  原理就是：比较在疑似故障这个假设下，LEAF相对真实值的区别，跟没有这个假设的前提下，LEAF相对真实值的区别。这两个区别越大，越说明这个假设是显著的。

  强行令他大于0，是因为想取到0~1 之间的值，当成概率。

- potential score指标计算公式基于的假设是：如果某个维度是故障的根因，那么在这个维度上的kpi的变化率 跟 它 的所有后代维度（descendant）的实际变化率应该是一致的。所以可以使用某个维度的kpi变化率减去后代的kpi变化率，基于这个difference的值算根因概率potential score，这个差值越大，根因概率越小，反之亦然。

- 这个绝对变化是 预测值（历史均值f）和实际值(v）的差(delta)。

## potential score计算步骤示例



假设现在最细粒度的LEAF维度有如下6个取值

$\vec{y}$=[(Beijing;Mobile);(Shanghai;Mobile);

(Guangdong;Mobile); (Bei jing;Unicom);

 (Shanghai;Unicom); (Guangdong;Unicom)].

那么

 $\vec f = (20;15;10;10;25;20)$, 

$\vec v= (14;9;10;7;)​$

对于cuboid--$B_p​$,它包含3个属性值（elements）:

[(Beijing;\*);(Shanghai; \*);(Guangdong;*)]

所以$B_p​$的所有子集有7个，上面3个ele的排列组合：

$S_{p 1}=\{(B e i j i n g, *)\}​$,

$ S_{p 2}=\{(\text {Shanghai}, *)\}​$

....

$S_{p 7}=\{(\text {Beijing}, *), \quad \text { (Shanghai,*) },(\text {Guangdong,*}) \}$

![image-20190322212356628](/Users/stellazhao/EasyML_BOOK/_image/image-20190322212356628.png)

- 注：上图中箭头左边是预测值($\vec{f}$)，右边的是真实值($\vec v$)

  现在以$S_{p1}=\{(B e i j i n g, *)\}$,$为例，算它的根因概率（ps），步骤如下

（1）如果$S_{p1}$是故障根因，受其影响，最细维度（LEAF）的预测值为：

- (a)$S$不是LEAF

  - $y_i$ 不属于$D e s c^{\prime}(S)$（非leaf后继）

    $a\left(y_{i}\right)=f\left(y_{i}\right)$

  - $y_i$ 属于$D e s c^{\prime}(S)$(leaf后继)

    $a\left(y_{i}^{\prime}\right)=f\left(y_{i}^{\prime}\right)-h(x) \times \frac{f\left(y_{i}^{\prime}\right)}{f(x)},(f(x) \neq 0)$

- (b)$S$是LEAF:

  - $y_i$ 不属于S， $a(y_i)= f(y_i)$

  - $y_i$ 属于S，$ a(y_i)= v(y_i)$

$\vec{a}\left(S_{p 1}\right)=(14,15,10,7,25,20)$

   (2) 最细维度（LEAF）对应的真实值为:

$\vec{v}=\left[v\left(y_{1}\right), v\left(y_{2}\right), v\left(y_{3}\right), \ldots, v\left(y_{n}\right)\right]​$

  (3) 不管$S_{p1}​$是不是故障根因，最细维度（LEAF）上面的预测值为:

$\vec{f}=\left[f\left(y_{1}\right), f\left(y_{2}\right), f\left(y_{3}\right), \ldots, f\left(y_{n}\right)\right]$



# 蒙特卡洛搜索树

## 符号说明

$A(s)$: 表示状态=s时的所有action集合，

$N(s)​$: 表示s被访问的次数，s就是维度集合

$N(s;a)$: 表示边(s;a) 被访问的次数

$Q(s, a)$: 表示action function，取$s^{\prime}$的ps和$s^{\prime}$后继节点的ps的较大值。

$Q(s, a)=\max _{u \in\left\{s^{\prime}\right\} \cup \operatorname{descendent}\left(s^{\prime}\right)} p s(S(u))$



蒙特卡洛搜索树是强化学习框架下的一种数值算法。



##执行步骤

1）selection：根据当前的s和Q选取最优的action

$a=\underset{a \in A(s)}{\arg \max }\left\{Q(s, a)+C \sqrt{\frac{\ln N(s)}{N(s, a)}}\right\}​$

上式中C(*)表示exploration。

初始状态N(S, A)=0，怎么办？对这些未被访问的(s,a),赋予一定的访问概率R

$$R=1-Q\left(s, a_{\max }\right)$$, ---（没懂，为什么Q越大，概率越小）

$a_{max} = \arg\max \limits_{a \in A(s) \cap N(s, a)=0} Q(s, a)$

selection起始于根节点，终于LEAF节点,（注意，终止于LEAF的维度值，而不是树的叶子节点）。

![image-20190325133227795](/Users/stellazhao/EasyML_BOOK/_image/image-20190325133227795.png)

2) expand：起于上一步的LEAF节点，终于其子节点。在里面加一个ele。

![image-20190325133205483](/Users/stellazhao/EasyML_BOOK/_image/image-20190325133205483.png)

3）evaluation：计算2)$s'$的ps，Q，和N

![image-20190325133147984](/Users/stellazhao/EasyML_BOOK/_image/image-20190325133147984.png)

4) backup：更新

从树的根节点到$s'$的路径中，更新经过节点的Q和N。

注意：只有当子节点的Q > 父节点的Q时，我们采取更新父节点的Q

![image-20190325133126318](/Users/stellazhao/EasyML_BOOK/_image/image-20190325133126318.png)



对每个cubic使用MTCS，迭代终止，如果以下条件之一满足：

1）$$B S e t=S$$ if $$ p s(S) \geqslant P T$$

2)   集合中所有可能的节点（维度值）都已经expanded完了

3）迭代时长超过给定值（根据经验人工确定）



## 层次剪枝

为了进一步减少搜索空间 ，HotSpot使用了层次剪枝的策略。

这里剪枝不是剪的蒙特卡洛搜索树，是剪的原始的action空间。

基本原理是：

由于MTCS是一层一层搜索的cuboids的，在搜索lay较小的cubics，例如（layer=1的$B_p$）

就可以剪掉一些ps较小的elements，因为这些elements的后继节点也不太可能是根因。

## 符号说明

$$B S e t_{l, B}​$$: 使用MCTS对layer=l的cubic B, 算出来的ps最大的Set。

hotspot剪枝的策略：对每层l中的elements不在$$B S e t_{l, B}$$, 剪掉。这个策略跟关联规则挖掘中的Apriori Principle很像，叫层次剪枝这个名字是因为利用到了layer的信息。



## 示例

![image-20190325135442670](/Users/stellazhao/EasyML_BOOK/_image/image-20190325135442670.png)



假设第一层的维度MCTS搜索出来的结果：
$$B S e t_{1, B_{P}}=\{(F u j i a n, *),(\text {Jiangsu}, *)\}$$并且$$ps(B S e t_{l, B_P})=0.5$$

$$B S e t_{1, B_{I}}=\{(*,Mobile),(*, \text {Unicom})\}$$并且$$ps(B S e t_{l, B_I})=0.32$$

现在MCTS要去搜索第二层了

就把 (Zhe jiang; Unicom) 和 (Zhe jiang;Unicom)这两个elements给剪掉了，因为他们的父节点 (Zhe jiang;)不在第一层维度的BSets里面，因此，第二层维度，我们只搜索剩下的4个elements，看哪种组合最优可能是根因的维度集合。

上面的剪枝将蒙特卡洛搜索树的action空间从63减少到了15 ($2^6- 1​$ 到 $2^4 -  1​$). 

然后使用蒙特卡洛搜索树搜到得分最高的set，也是根因维度

$$R S e t=B \operatorname{Set}_{2, B_{P, I}}=\{(\text { Fujian, Mobile), (Jiangsu, Unicom) }\}$$且$$ps(B \operatorname{Set}_{2, B_{P, I}})=1$$



# 参考资料

[1] Yongqian Sun, Youjian Zhao, Ya su, et al., “HotSpot:Anomaly Localization for Additive KPIs withMulti-Dimensional Attributes”, IEEE Access, 2018.<https://netman.aiops.org/wp-content/uploads/2018/12/sunyq_IEEEAccess2018_HotSpot.pdf>

https://mp.weixin.qq.com/s/Kj309bzifIv4j80nZbGVZw




































