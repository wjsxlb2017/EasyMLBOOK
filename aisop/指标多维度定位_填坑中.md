[TOC]

# 问题描述

<http://iops.ai/competition_detail/?competition_id=8&flag=1>


在运维场景中对监控指标的多个维度进行根因定位。具体来说，当某个总指标（如总流量）发生异常时，需要快速准确地定位到是哪个交叉维度的细粒度指标（如“省份=北京 & 运营商=联通”的流量）的异常导致的，以便尽快做进一步的修复止损操作。图示如下：

# 算法框架



调研hotspot，整体算法框架如下：

![image-20190322210515877](/Users/stellazhao/EasyML_BOOK/_image/image-20190322210515877.png)


1. 对KPI使用N-sigma进行实时异常检测，如果异常进入2

2. 使用蒙特卡洛搜索树寻找最有可能是根因的维度组合：从第一层的维度开始，搜索value function = potential score最高（potential score翻译成根因概率吧，表示该维度为故障根因的概率)的维度组合，对于potential score较低的维度组合会提前终止，即层次剪枝（hierarchical pruning）。（背后的逻辑是，如果父维度为故障根因的概率很小，那么其子维度为故障的可能性也很小），所以可以被剪枝掉了。
3. 直到potential score超过指定阈值，返回对应的维度组合。




# 符号说明

![image-20190322211056826](/Users/stellazhao/EasyML_BOOK/_image/image-20190322211056826.png)



$e_i$: $e=(p, i, d, c) ​$，表示多个属性值的组合，是有具体的取值的.![image-20190322212044105](/Users/stellazhao/Library/Application Support/typora-user-images/image-20190322212044105.png)

$v(e_i)​$:某个维度上指标的实际值。

$f(e_i)​$:某个维度上指标的预测值。

cuboids:粒度可以任意细，任意粗  $ \left\{B_{P}, B_{P, I}, B_{P, I, D}, \ldots\right\}​$
layer1，layer2，。。。layer3的解释如下
![image-20190322220603157](/Users/stellazhao/EasyML_BOOK/_image/image-20190322220603157.png)



data cube: 多维的时序数据

ps: 衡量一组$S=\{e_i\}$是根因的概率。

e的后继结点：$\operatorname{Desc}(e)=\left\{e^{\prime} | e^{\prime} \text { is a descendant of } e\right\}​$

LEAF维度：$\operatorname{Desc}^{\prime} (e)=\left\{e^{\prime} | e^{\prime}  \left(p^{\prime},i^{\prime}, d^{\prime}, c^{\prime}\right) \in L E A F, e^{\prime} \in \operatorname{Desc}(e) \right\}​$

为什么要找LEAF维度？因为它具有可加性，加起来等于它的父节点,如下

$\begin{array}{c}{v(e)=\sum\limits_{e^{\prime} \in D e s c^{\prime}(e)} v\left(e^{\prime}\right)} \\ {\text { e.g. }} \\ {v(\text { Bei jing }, *, *, *)=\sum\limits_{j, k, h} v\left(\text {Beijing}, i_{j}, d_{k}, c_{h}\right),} \\ {\text { Total } P V=v(*, *, *, *)=\sum\limits_{i, j, k, h} v\left(p_{i}, i_{j}, d_{k}, c_{h}\right)}\end{array}​$




# potential score 

##  potential score的计算公式

- .ps的计算公式如下

  $\text { Potential Score }=\max \left(1-\frac{d(\vec{v}, \vec{a})}{d(\vec{v}, \vec{f})}, 0\right)​$

  - a表示疑似根因维度的影响下，LEAF的预期值
  - v表示LEAF的真实值
  - f表示LEAF的预期值，跟疑似维度无关

  原理就是：比较在疑似故障这个假设下，LEAF相对真实值的区别，跟没有这个假设的前提下，LEAF相对真实值的区别。这两个区别越大，越说明这个假设是显著的。

  没想明白的地方，为啥要在大于0这里截断

- potential score指标计算公式基于的假设是：如果某个维度是故障的根因，那么在这个维度上的kpi的变化率 跟 它 的所有后代维度（descendant）的实际变化率应该是一致的。所以可以使用某个维度的kpi变化率减去后代的kpi变化率，基于这个difference的值算根因概率potential score，这个差值越大，根因概率越小，反之亦然。

- 这个绝对变化是 预测值（历史均值 ， f(*)）和实际值(v(*))的差(delta)。

## potential score计算步骤示例



假设现在最细粒度的LEAF维度有如下6个取值

$\vec{y}$=[(Beijing;Mobile);(Shanghai;Mobile);

(Guangdong;Mobile); (Bei jing;Unicom);

 (Shanghai;Unicom); (Guangdong;Unicom)].

那么

 $\vec f = (20;15;10;10;25;20)$, 

$\vec v= (14;9;10;7;)​$

对于cuboid--$B_p​$,它包含3个属性值（elements）:

[(Beijing;\*);(Shanghai; \*);(Guangdong;*)]

所以$B_p​$的所有子集有7个，上面3个ele的排列组合：

$S_{p 1}=\{(B e i j i n g, *)\}$,

$ S_{p 2}=\{(\text {Shanghai}, *)\}$

....

$S_{p 7}=\{(\text {Beijing}, *), \quad \text { (Shanghai,*) },(\text {Guangdong,*}) \}$

![image-20190322212356628](/Users/stellazhao/EasyML_BOOK/_image/image-20190322212356628.png)

- 注：上图中箭头左边是预测值($\vec{f}$)，右边的是真实值($\vec v$)

  现在以$S_{p1}$为例，算他的故障根因的概率得分（ps），步骤如下

（1）如果$S_{p1}​$是故障根因，最细维度（LEAF）的预测值为：

$\vec{a}\left(S_{p 1}\right)=(14,15,10,7,25,20)​$

- (a)$S​$不是LEAF

  - $y_i​$ 不属于$D e s c^{\prime}(S)​$

  - $y_i​$ 属于$D e s c^{\prime}(S)​$

    $a\left(y_{i}^{\prime}\right)=f\left(y_{i}^{\prime}\right)-h(x) \times \frac{f\left(y_{i}^{\prime}\right)}{f(x)},(f(x) \neq 0)$

- (b)$S$是LEAF:

  - $y_i​$ 不属于S， $a(y_i)= f(y_i)​$
  - $y_i​$ 属于S，$ a(y_i)= v(y_i)​$

   (2) 最细维度（LEAF）对应的真实值为:

$\vec{v}=\left[v\left(y_{1}\right), v\left(y_{2}\right), v\left(y_{3}\right), \ldots, v\left(y_{n}\right)\right]​$

  (3) 不管$S_{p1}​$是不是故障根因，最细维度（LEAF）上面的预测值为:

$\vec{f}=\left[f\left(y_{1}\right), f\left(y_{2}\right), f\left(y_{3}\right), \ldots, f\left(y_{n}\right)\right]​$



# 蒙特卡洛搜索树



















































































































# 技术方案

# 代码实现

git地址：

http://gitlab-paas.open.oa.com/bkdata/datamining/opsai-monitor/tree/master/rca





# 调研资料

[1] Yongqian Sun, Youjian Zhao, Ya su, et al., “HotSpot:Anomaly Localization for Additive KPIs withMulti-Dimensional Attributes”, IEEE Access, 2018.<https://netman.aiops.org/wp-content/uploads/2018/12/sunyq_IEEEAccess2018_HotSpot.pdf>

https://mp.weixin.qq.com/s/Kj309bzifIv4j80nZbGVZw

[2] R. Bhagwan, R. Kumar, and R. o. Ramjee, “Adtributor: Revenue debugging in advertising systems,” NSDI, 2014, pp. 43–55.<https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/main-14.pdf>

[3] Q. Lin, J. Lou, H. Zhang, and D. Zhang, “idice: problem identification for emerging issues,” ICSE, 2016, ACM,, pp. 214–224.<https://www.microsoft.com/en-us/research/wp-content/uploads/2016/07/ICSE-2016-1-iDice-Problem-Identification-for-Emerging-Issues.pdf>


































