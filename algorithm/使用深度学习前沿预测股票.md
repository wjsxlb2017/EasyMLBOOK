[TOC]

# 1.引言

Using the latest advancements in deep learning to predict stock price movements
利用深度学习的最新进展来预测股票价格走势



![img](https://cdn-images-1.medium.com/max/1600/1*h6eC4YRmN1JDbnJO4kd11A.jpeg)

Overview of the complete architecture. 完整体系结构概述

> Link to the complete notebook: 链接到完整的笔记本:<https://github.com/borisbanushev/stockpredictionai>

In this notebook I will create a complete process for predicting stock price movements. Follow along and we will achieve some pretty good results. For that purpose we will use a **Generative Adversarial Network** (GAN) with **LSTM**, a type of Recurrent Neural Network, as generator, and a Convolutional Neural Network, **CNN**, as a discriminator. We use LSTM for the obvious reason tha t we are trying to predict time series data. Why we use GAN and specifically CNN as a discriminator? That is a good question: there are special sections on that later.

在这个笔记本中，我将创建一个预测股票价格走势的完整流程。 继续下去，我们将取得一些相当不错的结果。 为了达到这个目的，我们将使用生成对抗体网络(Generative Adversarial Network，GAN)和 LSTM，LSTM 是递归神经网络的一种，作为生成器，CNN 的卷积神经网络，作为鉴别器。 我们使用 LSTM 显然是为了预测时间序列数据。 为什么我们使用 GAN，特别是 CNN 作为一个歧视者？ 这是一个很好的问题: 后面会有专门的章节讨论。

We will go into greater details for each step, of course, but the most difficult part is the GAN: very tricky part of successfully training a GAN is getting the right set of hyperparameters. For that reason we will use **Bayesian optimisation** (along with Gaussian processes) and **Deep Reinforcement learning** (DRL) for deciding when and how to change the GAN’s hyper parameters (the exploration vs. exploitation dilemma). In creating the reinforcement learning I will use the most recent advancements in the field, such as **Rainbow** and **PPO**.

当然，我们将对每个步骤进行更详细的介绍，但最困难的部分是 GAN: 成功训练 GAN 的非常棘手的部分是获得正确的超参数集。 出于这个原因，我们将使用贝叶斯优化(连同高斯过程)和深强化学习(DRL)来决定何时以及如何改变 GAN 的超参数(探索与开发的困境)。 在创建强化学习时，我将使用该领域的最新进展，如彩虹和 PPO。

We will use a lot of different types of input data. Along with the stock’s historical trading data and technical indicators, we will use the newest advancements in **NLP** (using ‘Bidirectional Embedding Representations from Transformers’, **BERT**, sort of a transfer learning for NLP) to create sentiment analysis (as a source for fundamental analysis), Fourier transforms for extracting overall trend directions, **stacked autoencoders** for identifying other high-level features, **Eigen portfolios** for finding correlated assets, autoregressive integrated moving average (**ARIMA**) for the stock function approximation, and many more, in order to capture as much information, patterns, dependencies, etc, as possible about the stock. As we all know, the more (data) the merrier. Predicting stock price movements is an extremely complex task, so the more we know about the stock (from different perspectives) the higher our changes are.

我们将使用许多不同类型的输入数据。 除了股票的历史交易数据和技术指标，我们将使用 NLP 的最新进展(使用'来自变形金刚的双向嵌入表示'，BERT，类似于 NLP 的传递学习)来创建情绪分析(作为基本面分析的一个来源) ，傅里叶变换来提取总体趋势方向，堆叠式自动编码器来识别其他高级特征，Eigen 投资组合来寻找相关资产，股票 / ARIMA模型 / 函数逼近，等等，以获取尽可能多的关于股票的信息，模式，等等。 众所周知，数据越多越好。 预测股票价格走势是一项极其复杂的任务，因此我们对股票(从不同的角度)了解得越多，我们的变化就越大。

For the purpose of creating all neural nets we will use **MXNet** and its high-level API — Gluon, and train them on multiple GPUs.

为了创建所有的神经网络，我们将使用 MXNet 及其高级 API ー Gluon，并在多个 gpu 上训练它们。

**Note**: *Although I try to get into details of the math and the mechanisms behind almost all algorithms and techniques, this notebook is not explicitly intended to explain how machine/deep learning, or the stock markets, work. The purpose is rather to show how we can use different techniques and algorithms for the purpose of accurately predicting stock price movements, and to also give rationale behind the reason and usefulness of using each technique at each step.*

注意: 尽管我试图深入了解几乎所有算法和技术背后的数学和机制的细节，但是这个笔记本并没有明确地解释机器 / 深度学习，或者股票市场是如何工作的。 其目的是展示我们如何使用不同的技术和算法来准确地预测股票价格的变动，并给出在每个步骤中使用每种技术的原因和有用性的理由。

- https://medium.com/p/2edd6fac689d#42bb)



Accurately predicting the stock markets is a complex task as there are millions of events and pre-conditions for a particular stock to move in a particular direction. So we need to be able to capture as many of these pre-conditions as possible. We also need make several important assumptions: 1) markets are not 100% random, 2) history repeats, 3) markets follow people’s rational behavior, and 4) the markets are ‘*perfect*’. And, please, do read the Disclaimer at the bottom.

准确地预测股票市场是一项复杂的任务，因为一只股票朝着特定的方向运动有数以百万计的事件和前提条件。 所以我们需要尽可能多地捕捉这些前提条件。 我们还需要做出几个重要的假设: 1)市场不是100% 随机的，2)历史重复，3)市场遵循人们的理性行为，4)市场是"完美的"。 另外，请务必阅读底部的免责声明。

We will try to predict the price movements of **Goldman Sachs** (NYSE: GS). For the purpose, we will use the daily closing price from January 1st, 2010 to December 31st, 2018 (seven years for training purposes and two years for validation purposes). *We will use the terms ‘Goldman Sachs’ and ‘GS’ interchangeably*.

我们将试图预测高盛(NYSE: GS)的价格走势。 为此，我们将使用2010年1月1日至2018年12月31日的每日收盘价(用于培训目的为7年，用于确认目的为2年)。 我们将交替使用"高盛"和"高盛"这两个术语。

------

# 2. 数据



We need to understand what affects whether GS’s stock price will move up or down. It is what people as a whole think. Hence, we need to incorporate as much information (depicting the stock from different aspects and angles) as possible. (We will use daily data — 1,585 days to train the various algorithms (70% of the data we have) and predict the next 680 days (test data). Then we will compare the predicted results with a test (hold-out) data. Each type of data (we will refer to it as *feature*) is explained in greater detail in later sections, but, as a high-level overview, the features we will use are:

我们需要了解是什么影响了 GS 的股价是上涨还是下跌。 这是人们作为一个整体的想法。 因此，我们需要纳入尽可能多的信息(描述股票从不同的方面和角度)。 (我们将使用每日数据ー1,585天来训练各种算法(我们已有的数据的70%) ，并预测未来680天(测试数据)。 然后我们将预测的结果与试验数据进行比较。 每种类型的数据(我们将称之为特性)在后面的章节中会有更详细的解释，但是，作为一个高层次的概述，我们将使用以下特性:

1. **Correlated assets** — these are other assets (any type, not necessarily stocks, such as commodities, FX, indices, or even fixed income securities). A big company, such as Goldman Sachs, obviously doesn’t ‘live’ in an isolated world — it depends on, and interacts with, many external factors, including its competitors, clients, the global economy, the geo-political situation, fiscal and monetary policies, access to capital, etc. The details are listed later. 相关资产ーー这些是其他资产(任何类型，不一定是股票，如大宗商品、外汇、指数，甚至固定收益证券)。 像高盛这样的大公司显然不是生活在一个孤立的世界里ーー它依赖许多外部因素，并与之互动，包括竞争对手、客户、全球经济、地缘政治形势、财政和货币政策、获得资本的途径等等。 具体细节稍后列出
2. **Technical indicators** — a lot of investors follow technical indicators. We will include the most popular indicators as independent features. Among them — 7 and 21 days moving average, exponential moving average, momentum, Bollinger bands, MACD. 技术指标ーー许多投资者追随技术指标。 我们将包括最流行的指标作为独立的功能。 其中ー7天和21天移动平均线、指数移动平均线、动量、布林带、 MACD
3. **Fundamental analysis** — A very important feature indicating whether a stock might move up or down. There are two features that can be used in fundamental analysis: 1) Analysing the company performance using 10-K and 10-Q reports, analysing ROE and P/E, etc (we will not use this), and 2) News — potentially news can indicate upcoming events that can potentially move the stock in certain direction. We will read all daily news for Goldman Sachs and extract whether the total sentiment about Goldman Sachs on that day is positive, neutral, or negative (as a score from 0 to 1). As many investors closely read the news and make investment decisions based (partially of course) on news, there is a somewhat high chance that if, say, the news for Goldman Sachs today are extremely positive the stock will surge tomorrow. *One crucial point, we will perform feature importance (meaning how indicative it is for the movement of GS) on absolutely every feature (including this one) later on and decide whether we will use it. More on that later*. 
    For the purpose of creating accurate sentiment prediction, we will use Neural Language Processing (**NLP**). We will use **BERT** — Google’s recently announced NLP approach for transfer learning for sentiment classification stock news sentiment extraction. 基本面分析ーー一个显示股票是上升还是下降的非常重要的特征。 有两个特征可以用于基本面分析: 1)使用10-K 和10-Q 报告分析公司业绩，分析净资产收益率和市盈率等(我们不会使用这个) ，2)新闻——潜在的新闻可以显示即将发生的事件，可能会推动股票朝某个方向走。 我们将阅读高盛的所有每日新闻，并摘录当天对高盛的总体情绪是积极的、中性的，还是消极的(得分从0到1)。 随着许多投资者密切关注新闻，并根据新闻(当然是部分)做出投资决策，如果(比如说)高盛今天的消息极为乐观，那么该股明天将大幅飙升的可能性有些高。 至关重要的一点是，稍后我们将对每个特性(包括这个特性)执行特性重要性(这意味着它对于 GS 的移动有多么重要) ，并决定是否使用它。 稍后将详细介绍。 为了创建准确的情绪预测，我们将使用神经语言处理(NLP)。 我们将使用 BERT ー Google 最近宣布的 NLP 方法进行情绪分类股票新闻情绪提取的转移学习
4. **Fourier transforms** — Along with the daily closing price, we will create Fourier transforms in order to generalize several long- and short-term trends. Using these transforms we will eliminate a lot of noise (random walks) and create approximations of the real stock movement. Having trend approximations can help the LSTM network pick its prediction trends more accurately. 傅立叶变换ーー除了每日收盘价外，我们将创建傅立叶变换，以概括几个长期和短期趋势。 使用这些变换，我们将消除大量的噪音(随机游动) ，并创造逼近真正的股票运动。 趋势近似可以帮助 LSTM 网络更准确地选择其预测趋势
5. Autoregressive Integrated Moving Average (**ARIMA**) — This was one of the most popular techniques for predicting future values of time series data (in the pre-neural networks ages). Let’s add it and see if it comes off as an important predictive feature. ARIMA模型时间序列(ARIMA)ー这是预测时间序列数据未来值(在前神经网络时代)最流行的技术之一。 让我们添加它，看看它是否是一个重要的预测特性
6. **Stacked autoencoders** — most of the aforementioned features (fundamental analysis, technical analysis, etc) were found by people after decades of research. But maybe we have missed something. Maybe there are hidden correlations that people cannot comprehend due to the enormous amount of data points, events, assets, charts, etc. With stacked autoencoders (type of neural networks) we can use the power of computers and probably find new types of features that affect stock movements. Even though we will not be able to understand these features in human language, we will use them in the GAN. 堆叠式自动编码器ー大多数上述特征(基本分析，技术分析等)是人们经过几十年的研究发现的。 但也许我们漏掉了什么。 也许由于海量的数据点、事件、资产、图表等等，人们无法理解其中隐藏的相关性。 通过堆叠式自动编码器(一种神经网络) ，我们可以利用计算机的能力，并可能发现影响股票走势的新类型的特征。 尽管我们无法理解人类语言中的这些特征，但我们将在 GAN 中使用它们
7. **Deep Unsupervised learning** for anomaly detection in options pricing. We will use one more feature — for every day we will add the price for 90-days call option on Goldman Sachs stock. Options pricing itself combines a lot of data. The price for options contract depends on the future value of the stock (analysts try to also predict the price in order to come up with the most accurate price for the call option). Using deep unsupervised learning (Self-organized Maps) we will try to spot anomalies in every day’s pricing. Anomaly (such as a drastic change in pricing) might indicate an event that might be useful for the LSTM to learn the overall stock pattern. 期权定价的深层次非监督式学习异常检测。 我们将使用另一个功能ーー我们每天都会增加高盛股票90天看涨期权的价格。 期权定价本身结合了大量的数据。 期权合约的价格取决于股票的未来价值(分析师也试图预测价格，以便为看涨期权提供最准确的价格)。 使用深度非监督式学习(自组织地图) ，我们将尝试在每天的定价中发现异常。 异常现象(例如定价的剧烈变化)可能表明一个事件，这个事件可能有助于 LSTM 了解整个股票模式

Next, having so many features, we need to perform a couple of important steps:

接下来，有了这么多功能，我们需要执行几个重要步骤:

1. Perform statistical checks for the ‘quality’ of the data. If the data we create is flawed, then no matter how sophisticated our algorithms are, the results will not be positive. The checks include making sure the data does not suffer from heteroskedasticity, multicollinearity, or serial correlation. 对数据的"质量"进行统计检查。 如果我们创建的数据是有缺陷的，那么无论我们的算法多么复杂，结果都不会是正面的。 这些检查包括确保数据不受异方差性、多重共线性或序列相关性的影响
2. Create feature importance. If a feature (e.g. another stock or a technical indicator) has no explanatory power to the stock we want to predict, then there is no need for us to use it in the training of the neural nets. We will using **XGBoost** (eXtreme Gradient Boosting), a type of boosted tree regression algorithms. 创建特性的重要性。 如果一个特征(例如另一只股票或一个技术指标)与我们想要预测的股票没有解释力，那么我们就没有必要在神经网络的训练中使用它。 我们将使用 XGBoost (eXtreme 梯度提升) ，这是一种增强的树回归算法

As a final step of our data preparation, we will also create **Eigen portfolios**using Principal Component Analysis (**PCA**) in order to reduce the dimensionality of the features created from the autoencoders.

作为我们数据准备的最后一步，我们还将使用主成分分析(PCA)创建特征投资组合，以降低由自动编码器创建的特征的维数。

```
print('There are {} number of days in the dataset.'.format(dataset_ex_df.shape[0]))
output >>> There are 2265 number of days in the dataset.
```

Let’s visualize the stock for the last nine years. The dashed vertical line represents the separation between training and test data.

让我们想象一下过去九年的股票。 虚线垂直线表示训练数据和测试数据的分割线。



![img](https://cdn-images-1.medium.com/max/1600/1*eHeqBsFLcfMzDIvyL01-eg.png)

Goldman Sachs stock price (NYSE:GS) 高盛股票价格(纽约证券交易所: GS)

## 2.1. Correlated assets


As explained earlier we will use other assets as features, not only GS.

正如前面解释的，我们将使用其他资产作为特征，而不仅仅是 GS。

So what other assets would affect GS’s stock movements? Good understanding of the company, its lines of businesses, competitive landscape, dependencies, suppliers and client type, etc is very important for picking the right set of correlated assets:

那么，还有哪些资产会影响 GS 的股价走势呢？ 对公司、业务范围、竞争环境、依赖性、供应商和客户类型等有良好的了解，对于选择正确的相关资产非常重要:

- First are the **companies** similar to GS. We will add JPMorgan Chase and Morgan Stanley, among others, to the dataset. 首先是与 GS 类似的公司。 我们将把摩根大通和摩根士丹利等公司加入到数据库中
- As an investment bank, Goldman Sachs depends on the **global economy**. Bad or volatile economy means no M&As or IPOs, and possibly limited proprietary trading earnings. That is why we will include global economy indices. Also, we will include LIBOR (USD and GBP denominated) rate, as possibly shocks in the economy might be accounted for by analysts to set these rates, and other **FI** securities. 作为一家投资银行，高盛依赖全球经济。 糟糕或动荡的经济意味着没有并购或首次公开发行(ipo) ，自营交易收益可能受到限制。 这就是为什么我们将包括全球经济指数。 此外，我们还将包括伦敦银行同业拆借利率(LIBOR，以美元和英镑计价) ，因为分析师设定这些利率可能会对经济造成冲击，以及其他金融工具证券
- Daily volatility index (**VIX**) — for the reason described in the previous point. 日波动率指数(VIX)ーー原因如前所述
- **Composite indices** — such as NASDAQ and NYSE (from USA), FTSE100 (UK), Nikkei225 (Japan), Hang Seng and BSE Sensex (APAC) indices. 综合指数ーー例如纳斯达克和纽约证券交易所(来自美国)、 FTSE100(英国)、 Nikkei225(日本)、恒生指数和 BSE Sensex 指数
- **Currencies** — global trade is many times reflected into how currencies move, ergo we’ll use a basket of currencies (such as USDJPY, GBPUSD, etc) as features. 货币ーー全球贸易多次反映在货币的走势上，因此我们将使用一篮子货币(如美元兑日元、 GBPUSD 等)作为特征

Overall, we have 72 other assets in the dataset — daily price for every asset.

总体而言，我们在数据集中还有72种其他资产ーー每种资产的每日价格

 

## 2.2. 技术指标

我们已经讨论了什么是技术指标，以及为什么要使用它们，所以让我们直接跳到代码。 我们将为GS 构建技术指标。

```python
""" Function to create the technical indicators """
def get_technical_indicators(dataset):
    # Create 7 and 21 days Moving Average
    dataset['ma7'] = dataset['price'].rolling(window=7).mean()
    dataset['ma21'] = dataset['price'].rolling(window=21).mean()
    
    # Create MACD
    dataset['26ema'] = pd.ewma(dataset['price'], span=26)
    dataset['12ema'] = pd.ewma(dataset['price'], span=12)
    dataset['MACD'] = (dataset['12ema']-dataset['26ema'])
# Create Bollinger Bands
    dataset['20sd'] = pd.stats.moments.rolling_std(dataset['price'],20)
    dataset['upper_band'] = dataset['ma21'] + (dataset['20sd']*2)
    dataset['lower_band'] = dataset['ma21'] - (dataset['20sd']*2)
    
    # Create Exponential moving average
    dataset['ema'] = dataset['price'].ewm(com=0.5).mean()
    
    # Create Momentum
    dataset['momentum'] = dataset['price']-1
    
    return dataset
```

So we have the technical indicators (including MACD, Bollinger bands, etc) for every trading day. We have in total 12 technical indicators.

所以我们有每个交易日的技术指标(包括 MACD，Bollinger 波段，等等)。 我们总共有12个技术指标。

Let’s visualise the last 400 days for these indicators.

让我们想象一下这些指标过去400天的情况。



![img](https://cdn-images-1.medium.com/max/1600/1*TQEcFB7KMrM0x6Dp1l-LEQ.png)

Technical indicators for Goldman Sachs — last 400 days. 高盛的技术指标ーー持续400天


## 2.3. 基本面分析

For fundamental analysis we will perform sentiment analysis on all daily news about GS. Using sigmoid at the end, result will be between 0 and 1. The closer the score is to 0 — the more negative the news is (closer to 1 indicates positive sentiment). For each day, we will create the average daily score (as a number between 0 and 1) and add it as a feature.

对于基本面分析，我们将对所有关于 GS 的日常新闻进行情感分析。 在最后使用 sigmoid，结果在0到1之间。 得分越接近0，负面消息就越多(接近1表示正面情绪)。对每一天我们构建一个日均得分(介于0和1之间) ，将它作为一个特征加入。


### 2.3.1.  BERT


为了将新闻分为正面或负面(或中性) ，我们将使用 [BERT](https://arxiv.org/abs/1810.04805)，这是一种预训练的语言表征。

Pre-trained BERT models are already available in MXNet/Gluon. We just need to instantiated them and add two (arbitrary number) `Dense` layers, going to softmax - the score is from 0 to 1.

预训练的 BERT 模型在MXNet/Gluon中已经可用。 我们只需要实例化他们，并添加两个(或任意数量)`Dense`层，接着使用softmax计算出1个得分。

```python
import bert
```



## 2.4. 使用傅里叶变换做趋势分析


**傅里叶变换**用来对函数做一次变换，产生一系列正弦波(具有不同的振幅和帧)。 合并这些正弦波后得到的信号近似于原函数。 从数学的角度来说，变换看起来是这样的:

![img](https://cdn-images-1.medium.com/max/1600/1*64AWoIDiBdVJLw5KkkqzOw.png)


我们将使用傅立叶变换提取 GS 股票的全局和局部趋势，同时也减少一些噪音。 让我们来看看它是如何工作的。

```python
""" Code to create the Fuorier trasfrom  """
data_FT = dataset_ex_df[['Date', 'GS']]
close_fft = np.fft.fft(np.asarray(data_FT['GS'].tolist()))
fft_df = pd.DataFrame({'fft':close_fft})
fft_df['absolute'] = fft_df['fft'].apply(lambda x: np.abs(x))
fft_df['angle'] = fft_df['fft'].apply(lambda x: np.angle(x))
plt.figure(figsize=(14, 7), dpi=100)
fft_list = np.asarray(fft_df['fft'].tolist())
for num_ in [3, 6, 9, 100]:
    fft_list_m10= np.copy(fft_list); fft_list_m10[num_:-num_]=0
    plt.plot(np.fft.ifft(fft_list_m10), label='Fourier transform with {} components'.format(num_))
plt.plot(data_FT['GS'],  label='Real')
plt.xlabel('Days')
plt.ylabel('USD')
plt.title('Figure 3: Goldman Sachs (close) stock prices & Fourier transforms')
plt.legend()
plt.show()
```



![img](https://cdn-images-1.medium.com/max/1600/1*UTWq-m6nsWp4NrlP47NGhw.png)

图3: 高盛股票的傅里叶变换


正如图3所示，我们使用的傅里叶变换分量越多，逼近函数就越接近真实的股票价格(100个成分的转换几乎与原始函数相同ー红线和紫线几乎重叠)。 我们使用傅立叶变换来提取长期和短期趋势，因此我们将分别使用3、6和9个成分的转换。 可以推断出，包含3个成分的转换表示长期趋势。


另一种用来去除数据噪声的技术叫做 **小波**。 小波和傅里叶变换给出了类似的结果，所以我们只使用傅立叶变换。


## 2.5. 使用ARIMA作为特征


**Arima**是一种时间序列数据的预测技术。我们将展示如何使用它，虽然我们最终不会使用ARIMA预测，但我们将用它来降噪，并(可能)提取一些新的模式或特征。

![img](https://cdn-images-1.medium.com/max/1600/1*sp4wrN9u3XkMCT5r3oaNQA.png)

在高盛股票上应用ARIMA

```python
error = mean_squared_error(test, predictions)
print('Test MSE: %.3f' % error)
output >>> Test MSE: 10.151
```



从图5中看到的，ARIMA 给出了一个非常好的股票价格近似值。 我们将使用 ARIMA 的预测价格作为 LSTM 的输入特征，因为正如我们之前提到的，我们希望捕捉尽可能多的关于高盛股票的特征和模式。 我们去测试 MSE (均方差)的10.151，这本身是一个不错的结果(考虑到我们确实有很多测试数据) ，但是，我们仍然只使用它作为 LSTM 的一个特征。

## 2.6. 统计检测



确保数据具有良好的质量对于我们的模型非常重要。 为了确保我们的数据是合适的，我们将执行一些简单的检查，以确保我们实现和观察的结果是真实的，而不是由于假设数据分布错误而受到损失。


### 2.6.1. 异方差，多重共线性，序列相关

- **异方差（Conditional Heteroskedasticity）**：当误差项(回归预测值与实际值之差)依赖于数据时，就会发生条件异方差性，例如，当数据点(沿 x 轴)增长时，误差项就会增长。
- **多重共线性（Multicollinearity）**：多重共线性是指错误项(也称为残差)相关。
- **序列相关（Serial correlation）**：  序列相关是当一个数据(特征)是另一个特征的表达式，或者完全依赖另外一个特征。

这里我们不会深入讨论代码，因为它很简单，而且我们的重点更多地放在深度学习部分，但是数据是定性的。


## 2.7. 特征工程

```python
print('Total dataset has {} samples, and {} features.'.format(dataset_total_df.shape[0],                                                          dataset_total_df.shape[1]))
output >>> Total dataset has 2265 samples, and 112 features.
```



因此，在添加了所有类型的数据(相关资产、技术指标、基本面分析、傅立叶和 Arima)之后，我们在2265天内总共有112个特征(然而，正如前面提到的，只有1585天用于训练数据)。



我们还有一些自动编码器生成的特征。


### 2.7.1. 使用 XGBoost计算特性重要性



拥有如此多的特征之后，我们必须考虑是否所有这些特性都能预测 GS股票的走势。 例如，我们在数据集中包括了以美元计价的伦敦银行同业拆借利率（LIBOR），因为我们认为伦敦银行同业拆借利率的变化可能预示着经济的变化，相应的，可能预示着 GS 股票行为的变化。 但是我们需要测试。 有许多方法可以测试特征的重要性，但是我们将要应用XGBoost，因为它在分类和回归问题上都提供了最好的结果。



由于特征数据非常大，为了在这里进行演示，我们将只使用技术指标。 在真正的特征重要性测试时，所有特征都很重要，所以我们不扔掉任何特征，而是直接训练GAN。

```python
regressor = xgb.XGBRegressor(gamma=0.0,n_estimators=150,base_score=0.7,colsample_bytree=1,learning_rate=0.05)
xgbModel = regressor.fit(X_train_FI,y_train_FI, eval_set = [(X_train_FI, y_train_FI), (X_test_FI, y_test_FI)], verbose=False)
fig = plt.figure(figsize=(8,8))
plt.xticks(rotation='vertical')
plt.bar([i for i in range(len(xgbModel.feature_importances_))], xgbModel.feature_importances_.tolist(), tick_label=X_test_FI.columns)
plt.title('Figure 6: Feature importance of the technical indicators.')
plt.show()
```



![img](https://cdn-images-1.medium.com/max/1600/1*rWs7xnMkjm7V6R7v5QhstA.png)

使用XGBoost 的特性重要性

毫不奇怪(对于那些有股票交易经验的人来说) ，MA7、 MACD 和 BB 是其中的重要特征。

I followed the same logic for performing feature importance over the whole dataset — just the training took longer and results were a little more difficult to read, as compared with just a handful of features.

我按照同样的逻辑对整个数据集执行特征重要性操作ーー训练花费了更长的时间，而且结果有点难以阅读，和只有少数几个特征的情况相比。


## 2.8. 基于堆叠自编码器提取高级特征



在我们继续使用自编码器之前，我们将探索一种替代的激活函数。


### 2.8.1. 激活函数ー GELU (Gaussian Error)

最近提出了 GELU- [link](https://arxiv.org/pdf/1606.08415.pdf). 作者在论文中给出了几个实例，结果表明使用 GELU 作为激活函数的神经网络优于使用 ReLU 作为激活函数的神经网络。BERT中也使用了GELU，这是我们用于新闻情感分析的 NLP 方法。

我们将使用 GELU 作为自动编码器。

**注意**: 下面的单元格显示了 GELU 数学背后的逻辑。 它并不是一个激活函数的真实实现。 我必须在 MXNet 中实现 GELU。 如果您将代码从 `act_type='relu'` 改为 `act_type='gelu'`，它不起作用，除非您更改 MXNet 的实现。 对整个项目发出请求，以访问 GELU 的 MXNet 实现。

让我们可视化 GELU、 ReLU 和 LeakyReLU (最后一个主要用于 GANs ——我们也使用它)。

```python
def gelu(x):
    return 0.5 * x * (1 + math.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * math.pow(x, 3))))
def relu(x):
    return max(x, 0)
def lrelu(x):
    return max(0.01*x, x)
plt.figure(figsize=(15, 5))
plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=.5, hspace=None)
ranges_ = (-10, 3, .25)
plt.subplot(1, 2, 1)
plt.plot([i for i in np.arange(*ranges_)], [relu(i) for i in np.arange(*ranges_)], label='ReLU', marker='.')
plt.plot([i for i in np.arange(*ranges_)], [gelu(i) for i in np.arange(*ranges_)], label='GELU')
plt.hlines(0, -10, 3, colors='gray', linestyles='--', label='0')
plt.title('Figure 7: GELU as an activation function for autoencoders')
plt.ylabel('f(x) for GELU and ReLU')
plt.xlabel('x')
plt.legend()
plt.subplot(1, 2, 2)
plt.plot([i for i in np.arange(*ranges_)], [lrelu(i) for i in np.arange(*ranges_)], label='Leaky ReLU')
plt.hlines(0, -10, 3, colors='gray', linestyles='--', label='0')
plt.ylabel('f(x) for Leaky ReLU')
plt.xlabel('x')
plt.title('Figure 8: LeakyReLU')
plt.legend()
plt.show()
```



![img](https://cdn-images-1.medium.com/max/1600/1*XAJdlKP_tHY6dWuTnKc6lg.png)

Gelu、 ReLU 和 LeakyReLU 的比较

**注意**: 在这个笔记本的未来版本中，我将尝试使用 **U-Net** ([link](https://arxiv.org/abs/1505.04597))，并尝试利用卷积层提取(和创建)更多股票的运动模式的特征。 现在，我们将只使用一个简单的自编码器只从`dense`层。

好了，回到自动编码器，下面描述(图像只是示意图，它不代表真正的layers，units。

**注意**: 在后面的版本中讨论的一件事情是移除decoder的最后一层。 一般情况下，在autoencoders中encoders的数量等于decoders的数量。 但是，我们希望提取更高级别的特征(而不是创建相同的输入) ，所以我们就可以跳过decoders的最后一层。 在训练期间，我们用相同数量的层来构建编码器和解码器，但是当我们创建输出时，我们使用了倒数第二层，因为它包含了更高层次的特征。



![img](https://cdn-images-1.medium.com/max/1600/1*-9iJNftM1g9eYksBNNTLyQ.jpeg)





我们从autoencoder中构建了112个特征。 由于我们只想要高层次的特征(整体模式) ，我们对112个特征使用主成分分析分析(PCA)。 这将减少数据的维度(列数)。 

注意: 再一次，这是纯实验性的。 我不能100% 确定所描述的逻辑是否正确。 就像人工智能和深度学习中的其他东西一样，这是一门艺术，需要实验。


# 3 生成对抗网络(GAN)

![img](https://cdn-images-1.medium.com/max/1600/1*hN0QKvuY4n07jxQCwRSmpg.jpeg)

GAN的架构图



GANs是如何工作的？



正如前面提到的，这个笔记本的目的不是详细解释深度学习背后的数学，而是展示它的应用。 当然，在我看来，彻底和非常扎实的理解从基础到最小的细节，是非常必要的。 因此，我们将尝试做一个平衡，给出一个高层次的GAN如何工作的概述，以便读者充分理解使用GANS在预测股票价格变动背后的原理。



一个 GAN 网络由两个模型组成: 一个Generator(G)和Discriminator(D)。 训练GANS的步骤如下:

1. Generator：使用随机数据(**z**)生成数据，试图使"生成"的数据与真实数据难以区分，或者非常接近真实数据。 其目的是学习真实数据的分布。
2. Discriminator就是一个分类器，通过学习真实的和生成的数据，来判断数据是来自Generator还是真实世界的。 D估计输入样本在真实数据集分布上的概率。 (两种分布的更多信息参考3.2 ).
3. 然后，将 G 和 D 的losses合并，并向后传播给generator。 因此，generator的loss取决于generator和discriminator。 这一步能帮助 Generator 更好的学习真实数据的分布。 如果Generator不能很好地生成真实数据(即跟真实数据有相同的分布) ，那么Discriminator就很容易区分出真实的和生成的。 因此，Discriminator的损失将非常小。 小的Discriminator损失会导致较大的generator损失。这使得构建discriminator有点棘手，因为太好的discriminator总是会导致巨大的generator损失，使generator无法学习。
4.  这个过程一直持续，直到Discriminator不能从区分真实数据和生成数据。

当 d 和 g 组合在一起时，d 和 g 就像在玩一个极小极大的游戏(Generator试图愚弄Discriminator，使它增加了生成数据的概率，即最小化 Ez ∼ pz (z)[ log (1-d (g (z)))]。 Discriminator希望通过最大化 Ex ∼ pr (x)[ logD (x)]来分离来自Generator的数据$$ D(G (z))$$的数据。 然而，在分离了损失函数之后，我们还不清楚如何将这两个函数聚合在一起(这就是为什么我们使用了一些进阶版的gans，如 Wasserstein GAN)。 总的来说，综合损失函数看起来像:



注意: 训练GANS的资料可以在这里找到。 [here](https://github.com/soumith/ganhacks).


## 3.1. 为什么使用GAN 用于股票市场预测

生成式对抗网络(GAN)最近主要用于创造逼真的图像、绘画和视频剪辑。GAN在预测时间序列数据方面的应用并不多，就像我们的例子一样。 然而，主要思想应该是相同的ーー我们希望预测未来的股市走势。 在未来，GS 股票的模式和行为应该或多或少跟历史是相同的(除非它开始以一种完全不同的方式运作，或者经济发生巨大的变化)。 因此，我们希望为未来"生成"数据，这些数据的分布与我们已有的数据——历史交易数据——相似(当然不是完全相同)。 因此，在理论上，它应该可行。

在我们的例子中，我们将使用 LSTM 作为时间序列generator，使用 CNN 作为discriminator。

## 3.2. Metropolis-Hastings GAN 和 Wasserstein GAN

注意: 接下来的几节假设您有一些使用 GANs 的经验。

####  I. Metropolis-Hastings GAN

Uber的工程团队最近对传统的 GANs 进行了改进，称为 Metropolis-Hastings GAN (MHGAN)。 Uber 方法背后的理念(他们是这么说的)有点类似于谷歌和加州大学伯克利分校创造的另一种方法——**Discriminator Rejection Sampling** ([DRS](https://arxiv.org/pdf/1810.06758.pdf))。 基本上，当我们训练 GAN 时，我们使用D的唯一目的是更好地训练G。 通常，在对 GAN训练好后，我们不再使用D。 然而，MHGAN 和 DRS 试图使用D来选择G生成的样本中接近真实数据分布的数据(MHGAN 和 DRS的细微差别在于 MHGAN 使用马尔科夫蒙特卡洛(MCMC)进行抽样)。

MHGAN 从G产生 k 样本($$x_0'$$到$$ x_K'$$) ，并依次传入D,让D决定是否保留。 



注意: MHGAN 最初是由 Uber 在 pytorch 中实现的。 我只是把它转移到 mxnet / gluon。

#### 

图10: MHGAN 的可视化表示(来自最初的 Uber 帖子)。



![img](https://cdn-images-1.medium.com/max/1600/1*0iif-P3BGvCfDlsziH5xcg.png)

#### II. Wasserstein GAN

Training GANs is quite difficult. Models may never converge and mode collapse can easily happen. We will use a modification of GAN called **Wasserstein** GAN — [WGAN](https://arxiv.org/pdf/1701.07875.pdf).

训练GANs是相当困难的。 模型可能永远不会收敛，模式崩溃很容易发生。 我们将使用Wasserstein** GAN — [WGAN](https://arxiv.org/pdf/1701.07875.pdf).的 GAN改良版。

Again, we will not go into details, but the most notable points to make are:

同样，我们不会详细讨论，但最值得注意的是:

- As we know the main goal behind GANs is for the Generator to start transforming random noise into some given data that we want to mimic. Ergo, the idea of comparing the similarity between two distributions is very imperative in GANs. The two most widely used such metrics are: 正如我们所知道的，GANs 背后的主要目标是让 Generator 开始将随机噪声转换成我们想要模拟的给定数据。 因此，比较两个发行版之间的相似性在广域网中是非常必要的。 使用最广泛的两个指标是:
- **KL divergence** (Kullback–Leibler) — DKL(p‖q)=∫xp(x)logp(x)q(x)dx. DKL is zero when p(x) is equal to q(x), Kl 散度(Kullback-Leibler)ー DKL (p ‖ q)∫ xp (x) logp (x) q (x) dx。 当 p (x)等于 q (x)时，DKL 为零,
- **JS Divergence** (Jensen–Shannon). JS divergence is bounded by 0 and 1, and, unlike KL divergence, is symmetric and smoother. Significant success in GAN training was achieved when the loss was switched from **KL** to **JS**divergence. Js 散度(Jensen-Shannon)。 Js 散度以0和1为界，与 KL 散度不同，JS 散度是对称的、平滑的。 当损失从 KL 转换到 JS 发散时，GAN 培训取得了显著的成功
- WGAN uses **Wasserstein distance**, W(pr,pg)=1Ksup‖f‖L≤K𝔼x∼pr[f(x)]−𝔼x∼pg[f(x)] (where sup stands for *supremum*), as a loss function (also called Earth Mover’s distance, because it normally is interpreted as moving one pile of, say, sand to another one, both piles having different probability distributions, using minimum energy during the transformation). Compared to KL and JS divergences, Wasserstein metric gives a smooth measure (without sudden jumps in divergence). This makes it much more suitable for creating a stable learning process during the gradient descent. Wgan 使用 Wasserstein 距离 w (pr，pg)1Ksup ‖ f ‖ l ≤ KEx ∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼∼。 与 KL 和 JS 发散相比，Wasserstein 度量给出了一个平滑的度量(在发散中没有突然的跳跃)。 这使得它更适合在梯度下降法期间创建一个稳定的学习过程
- Also, compared to **KL** and **JS**, Wasserstein distance is differentiable nearly everywhere. As we know, during backpropagation, we differentiate the loss function in order to create the gradients, which in turn update the weights. Therefore, having a differentiable loss function is quite important. 另外，与 KL 和 JS 相比，Wasserstein 距离几乎处处可微。 正如我们所知，在反向传播过程中，我们区分损失函数，以创建梯度，从而更新权重。 因此，有一个可微的损失函数是相当重要的

#### Hands down, this was the toughest part of this notebook. Mixing WGAN and MHGAN took me three days.

#### 毫无疑问，这是这本笔记本中最难的部分。 Wgan 和 MHGAN 的混合花了我三天时间

### 3.4. The Generator — One layer RNN

### 3.4. 生成器ー单层递归神经网络

#### 3.4.1. LSTM or GRU

#### 3.4.1. Lstm 或 GRU

As mentioned before, the generator is a LSTM network a type of Recurrent Neural Network (RNN). RNNs are used for time-series data because they keep track of all previous data points and can capture patterns developing through time. Due to their nature, RNNs many time suffer from *vanishing gradient* — that is, the changes the weights receive during training become so small, that they don’t change, making the network unable to converge to a minimal loss (The opposite problem can also be observed at times — when gradients become too big. This is called *gradient exploding*, but the solution to this is quite simple — clip gradients if they start exceeding some constant number, i.e. gradient clipping). Two modifications tackle this problem — Gated Recurrent Unit (**GRU**) and Long-Short Term Memory (**LSTM**). The biggest differences between the two are: 1) GRU has 2 gates (update and reset) and LSTM has 4 (update, input, forget, and output), 2) LSTM maintains an internal memory state, while GRU doesn’t, and 3) LSTM applies a nonlinearity (sigmoid) before the output gate, GRU doesn’t.

正如前面提到的，生成器是一个 LSTM 网络，一种类型的递归神经网络。 Rnn 用于时间序列数据，因为它们跟踪所有以前的数据点，并可以捕捉随时间发展的模式。 由于 RNNs 的特性，它们经常受到梯度消失的困扰，也就是说，在训练过程中权值的变化变得很小，以至于它们不会发生变化，使得网络不能收敛到最小的损失(当梯度变得太大时，有时也会出现相反的问题)。 这就是所谓的梯度爆炸，但解决这个问题相当简单---- 如果梯度开始超过某个常数，例如梯度剪辑，那么就会出现剪辑梯度。 针对这一问题，提出了门控循环单元(GRU)和长短时记忆(LSTM)两种改进算法。 两者最大的区别是: 1) GRU 有2个门(更新和重置) ，LSTM 有4个门(更新、输入、忘记和输出) ，2) LSTM 保持内存状态，而 GRU 没有，3) LSTM 在输出门之前使用非线性(sigmoid) ，而 GRU 没有。

In most cases, LSTM and GRU give similar results in terms of accuracy but GRU is much less computational intensive, as GRU has much fewer trainable params. LSTMs, however, and much more used.

在大多数情况下，LSTM 和 GRU 在准确性方面给出了类似的结果，但是 GRU 的计算强度要小得多，因为 GRU 的可训练比喻要少得多。 然而，lstm，以及更多的应用。

Strictly speaking, the math behind the LSTM cell (the gates) is:

严格地说，LSTM 单元(门)背后的数学是:



![img](https://cdn-images-1.medium.com/max/1600/1*DUeR85B1raizYc_heyeRRA.png)

The math behind the LSTM cell Lstm 单元格背后的数学

where ⊙is an element-wise multiplication operator, and, for all x=[x1,x2,…,xk]⊤∈R^k the two activation functions:,

其中⊙是元素相乘运算符，对于所有的 x [ x1，x2，... ，xk ] something ∈ r ^ k 这两个激活函数: ,



![img](https://cdn-images-1.medium.com/max/1600/1*nyZL1-UP-AZQ6vNXRi34kQ.png)

#### 3.4.2. The LSTM architecture

#### 3.4.2. Lstm 体系结构

The LSTM architecture is very simple — one `LSTM` layer with 112 input units (as we have 112 features in the dataset) and 500 hidden units, and one `Dense`layer with 1 output - the price for every day. The initializer is Xavier and we will use L1 loss (which is mean absolute error loss with **L1** regularization - see section 3.4.5. for more info on regularization).

Lstm 的体系结构非常简单: 一个 LSTM 层有112个输入单元(因为我们在数据集中有112个特征)和500个隐藏单元，一个稠密层有1个输出——每天的价格。 初始化式是 Xavier，我们将使用 L1损失(即 L1正则化时的平均绝对误差损失——参见第3.4.5节。 更多关于正规化的信息)。

**Note** — In the code you can see we use `Adam` (with `learning rate` of .01) as an optimizer. Don't pay too much attention on that now - there is a section specially dedicated to explain what hyperparameters we use (learning rate is excluded as we have learning rate scheduler - section 3.4.3.) and how we optimize these hyperparameters - section 3.6.

注意: 在代码中你可以看到我们使用 Adam (学习率为. 01)作为优化器。 现在不要太在意这一点——有一节专门解释我们使用的超参数(学习速率被排除在外，因为我们有学习速率调度器——3.4.3节) 以及我们如何优化这些超参数-第3.6节。

```
gan_num_features = dataset_total_df.shape[1]
sequence_length = 17
class RNNModel(gluon.Block):
    def __init__(self, num_embed, num_hidden, num_layers, bidirectional=False, sequence_length=sequence_length, **kwargs):
        super(RNNModel, self).__init__(**kwargs)
        self.num_hidden = num_hidden
        with self.name_scope():
            self.rnn = rnn.LSTM(num_hidden, num_layers, input_size=num_embed, bidirectional=bidirectional, layout='TNC')
            self.decoder = nn.Dense(1, in_units=num_hidden)
    
    def forward(self, inputs, hidden):
        output, hidden = self.rnn(inputs, hidden)
        decoded = self.decoder(output.reshape((-1,self.num_hidden)))
        return decoded, hidden
    
    def begin_state(self, *args, **kwargs):
        return self.rnn.begin_state(*args, **kwargs)
    
lstm_model = RNNModel(num_embed=gan_num_features, num_hidden=500, num_layers=1)
lstm_model.collect_params().initialize(mx.init.Xavier(), ctx=mx.cpu())
trainer = gluon.Trainer(lstm_model.collect_params(), 'adam', {'learning_rate': .01})
loss = gluon.loss.L1Loss()
```

We will use 500 neurons in the LSTM layer and use Xavier initialization. For regularization we’ll use L1. Let’s see what’s inside the `LSTM` as printed by MXNet.

我们将在 LSTM 层使用500个神经元，并使用 Xavier 初始化。 为了正规化，我们将使用 L1。 让我们看看由 MXNet 打印的 LSTM 中有什么。

```
print(lstm_model)
output >>>
RNNModel(
   (rnn): LSTM(112 -> 500, TNC)
   (decoder): Dense(500 -> 1, linear)
)
```

As we can see, the input of the LSTM are the 112 features (`dataset_total_df.shape[1]`) which then go into 500 neurons in the LSTM layer, and then transformed to a single output - the stock price value.

我们可以看到，LSTM 的输入是112个特性(dataset total df)。 形状[1]) ，然后进入 LSTM 层的500个神经元，然后转换成一个单一的输出-股票价值。

The logic behind the LSTM is: we take 17 (`sequence_length`) days of data (again, the data being the stock price for GS stock every day + all the other feature for that day - correlated assets, sentiment, etc.) and try to predict the 18th day. Then we move the 17 days window with one day and again predict the 18th. We iterate like this over the whole dataset (of course in batches).

Lstm 背后的逻辑是: 我们用17天(序列长度)的数据(同样，这些数据是 GS 股票每天的股票价格 + 该日相关资产的所有其他特征，情绪等) ，并试图预测第18天。 然后我们把17天窗口改为1天，再次预测18天。 我们像这样迭代整个数据集(当然是批处理)。

In another post I will explore whether modification over the vanilla LSTM would be more beneficial, such as:

在另一篇文章中，我将探讨修改普通的 LSTM 是否会更有益，例如:

- using **bidirectional** LSTM layer — in theory, going backwards (from end of the data set towards the beginning) might somehow help the LSTM figure out the pattern of the stock movement. 使用双向 LSTM 层ー在理论上，向后(从数据集的末端到开始)可能有助于 LSTM 找出股票的运动模式
- using **stacked** RNN architecture — having not only one LSTM layer but 2 or more. This, however, might be dangerous, as we might end up overfitting the model, as we don’t have a lot of data (we have just 1,585 day worth of data). 使用堆叠 RNN 结构ーー不仅有一个 LSTM 层，而且有2个或更多层。 然而，这可能是危险的，因为我们可能最终会过度拟合模型，因为我们没有太多的数据(我们只有1585天的数据)
- Exploring **GRU** — as already explained, GRUs’ cells are much simpler. 探索 GRU ーー正如已经解释过的，GRUs 的细胞要简单得多
- Adding **attention** vectors to the RNN. 向神经网络添加注意向量

#### 3.4.3. Learning rate scheduler

#### 3.4.3. 学习速率调度程序

One of the most important hyperparameters is the learning rate. Setting the learning rate for almost every optimizer (such as **SGD**, **Adam**, or **RMSProp**) is crucially important when training neural networks because it controls both the speed of convergence and the ultimate performance of the network. One of the simplest learning rate strategies is to have a fixed learning rate throughout the training process. Choosing a small learning rate allows the optimizer find good solutions, but this comes at the expense of limiting the initial speed of convergence. Changing the learning rate over time can overcome this tradeoff.

最重要的超参数之一是学习率。 在训练神经网络时，设置几乎每个优化器(如 SGD、 Adam 或 RMSProp)的学习速率至关重要，因为它控制着网络的收敛速度和最终性能。 最简单的学习率策略之一是在整个培训过程中有一个固定的学习率。 选择一个小的学习速率可以让优化器找到好的解决方案，但是这是以限制初始收敛速度为代价的。 随着时间的推移，改变学习速率可以克服这种权衡。

Recent papers, such as [this](https://arxiv.org/pdf/1806.01593.pdf) one, show the benefits of changing the global learning rate during training, in terms of both convergence and time. Let’s plot the learning rates we’ll be using for each epoch.

最近的一些论文，比如这篇论文，展示了在训练过程中改变全局学习速度的好处，包括收敛性和时间。 让我们画出每个时代的学习速率。

```
schedule = CyclicalSchedule(TriangularSchedule, min_lr=0.5, max_lr=2, cycle_length=500)
iterations=1500
plt.plot([i+1 for i in range(iterations)],[schedule(i) for i in range(iterations)])
plt.title('Learning rate for each epoch')
plt.xlabel("Epoch")
plt.ylabel("Learning Rate")
plt.show()
```



![img](https://cdn-images-1.medium.com/max/1600/1*kY6bUOtF9AlyUBwei8Noug.png)

#### 3.4.4. How to prevent overfitting and the bias-variance trade-off

#### 3.4.4. 如何防止过拟合和偏差-方差权衡

Having a lot of features and neural networks we need to make sure we prevent overfitting and be mindful of the total loss.

有很多的特点和神经网络，我们需要确保我们防止过度装修和留意的总损失。

We use several techniques for preventing overfitting (not only in the LSTM, but also in the CNN and the auto-encoders):

我们使用了几种技术来防止过拟合(不仅在 LSTM 中，而且在 CNN 和自动编码器中) :

- **Ensuring data quality**. We already performed statistical checks and made sure the data doesn’t suffer from multicollinearity or serial autocorrelation. Further we performed feature importance check on each feature. Finally, the initial feature selection (e.g. selecting correlated assets, technical indicators, etc.) was done with some domain knowledge about the mechanics behind the way stock markets work. 确保数据质量。 我们已经进行了统计检查，确保数据不会受到多重共线性或序列自相关的影响。 进一步，我们对每个特性进行了特性重要性检查。 最后，初始特征选择(例如选择相关资产、技术指标等)是利用股票市场运行机制的一些领域知识完成的
- **Regularization** (or weights penalty). The two most widely used regularization techniques are LASSO (**L1**) and Ridge (**L2**). L1 adds the mean absolute error and L2 adds mean squared error to the loss. Without going into too many mathematical details, the basic differences are: lasso regression (L1) does both variable selection and parameter shrinkage, whereas Ridge regression only does parameter shrinkage and end up including all the coefficients in the model. In presence of correlated variables, ridge regression might be the preferred choice. Also, ridge regression works best in situations where the least square estimates have higher variance. Therefore, it depends on our model objective. The impact of the two types of regularizations is quite different. While they both penalize large weights, L1 regularization leads to a non-differentiable function at zero. L2 regularization favors smaller weights, but L1 regularization favors weights that go to zero. So, with L1 regularization you can end up with a sparse model — one with fewer parameters. In both cases the parameters of the L1 and L2 regularized models “shrink”, but in the case of L1 regularization the shrinkage directly impacts the complexity (the number of parameters) of the model. Precisely, ridge regression works best in situations where the least square estimates have higher variance. L1 is more robust to outliers, is used when data is sparse, and creates feature importance. We will use L1. 正规化(或加权惩罚)。 最常用的两种正则化技术是 LASSO (L1)和 Ridge (L2)。 1加上平均绝对误差，l 2加上均方差。 在不涉及太多数学细节的情况下，它们的基本区别是: L1同时进行变量选择和参数收缩，而岭回归只进行参数收缩，最终包括模型中的所有系数。 在存在相关变量的情况下，岭回归可能是首选。 此外，岭回归工作最好的情况下，最小二乘估计有较高的方差。 因此，这取决于我们的模型目标。 这两种调整的影响是完全不同的。 L1正则化使得 L1正则化函数在零点处是不可微的。 L2正则化倾向于更小的权重，但 L1正则化倾向于权重趋于零。 因此，使用 L1正则化，您可以得到一个稀疏模型ー一个参数较少的模型。 在这两种情况下，L1和 L2正则化模型的参数"收缩"，但在 L1正则化情况下，收缩直接影响模型的复杂性(参数数目)。 确切地说，岭回归在最小二乘估计方差较大的情况下效果最好。 L1对异常值更具鲁棒性，在数据稀疏时使用，并创建特征的重要性。 我们将使用 L1
- **Dropout**. Dropout layers randomly remove nodes in the hidden layers. 退学。 辍学层随机删除隐藏层中的节点
- **Dense-sparse-dense training**. — [link](https://arxiv.org/pdf/1607.04381v1.pdf) 稠疏稠密训练。 链接
- **Early stopping**. 提前停车

Another important consideration when building complex neural networks is the bias-variance trade-off. Basically, the error we get when training nets is a function of the bias, the variance, and irreducible error — σ (error due to noise and randomness). The simplest formula of the trade-off is: Error=bias^2+variance+σ.

建立复杂神经网络的另一个重要考虑因素是偏差-方差权衡。 基本上，训练网络的误差是偏差、方差和不可约误差(噪声和随机性造成的误差)的函数。 最简单的折衷公式是: 误差偏差 ^ 2 + 方差 + 。

- **Bias**. Bias measures how well a trained (on training dataset) algorithm can generalize on unseen data. High bias (underfitting) meaning the model cannot work well on unseen data. 偏见。 偏差衡量一个经过训练的(训练数据集上的)算法在看不见的数据上的概括能力。 高偏差(欠拟合)意味着该模型不能很好地处理看不见的数据
- **Variance**. Variance measures the sensitivity of the model to changes in the dataset. High variance is the overfitting. 方差。 方差度量模型对数据集变化的敏感性。 高方差是过度拟合

### 3.5. The Discriminator — One Dimentional CNN

### 3.5. 一维细胞神经网络鉴别器

#### 4.5.1. Why CNN as a discriminator?

#### 4.5.1. 为什么 CNN 是一个歧视者？

We usually use CNNs for work related to images (classification, context extraction, etc). They are very powerful at extracting features from features from features, etc. For example, in an image of a dog, the first convolutional layer will detect edges, the second will start detecting circles, and the third will detect a nose. In our case, data points form small trends, small trends form bigger, trends in turn form patterns. CNNs’ ability to detect features can be used for extracting information about patterns in GS’s stock price movements.

我们通常使用 cnn 处理与图像相关的工作(分类、上下文提取等)。 它们在从特征中提取特征方面非常强大。 例如，在狗的图像中，第一卷积层将检测边缘，第二层将开始检测圆圈，第三层将检测鼻子。 在我们的案例中，数据点形成小趋势，小趋势形成大趋势，趋势反过来形成模式。 Cnn 检测特征的能力可用于提取 GS 股票价格波动模式的信息。

Another reason for using CNN is that CNNs work well on spatial data — meaning data points that are closer to each other are more related to each other, than data points spread across. This should hold true for time series data. In our case each data point (for each feature) is for each consecutive day. It is natural to assume that the closer two days are to each other, the more related they are to each other. One thing to consider (although not covered in this work) is seasonality and how it might change (if at all) the work of the CNN.

使用 CNN 的另一个原因是 CNN 能很好地处理空间数据ーー也就是说，相互靠近的数据点彼此之间的联系要比散布在各处的数据点之间的联系更加紧密。 这对于时间序列数据来说是正确的。 在我们的例子中，每个数据点(对于每个特性)都是连续的每一天。 人们自然而然地认为，两天的时间越接近，彼此之间的关系就越密切。 需要考虑的一件事(尽管本文没有涉及)是季节性以及它可能如何改变(如果有的话) CNN 的工作。

**Note**: As many other parts in this notebook, using CNN for time series data is experimental. We will inspect the results, without providing mathematical or other proofs. And results might vary using different data, activation functions, etc.

注意: 和这个笔记本的其他部分一样，使用 CNN 获取时间序列数据是实验性的。 我们将检查结果，而不提供数学或其他证明。 使用不同的数据、激活函数等，结果可能会有所不同。

#### 3.5.1. The CNN Architecture

#### 3.5.1. 的架构



![img](https://cdn-images-1.medium.com/max/1600/1*My1hiYMJeYWIBbuUQJfqKg.jpeg)

The architecture of the proposed CNN model. 提出的 CNN 模型的体系结构

Without going through the full code, we’ll just show the CNN as printed by MXNet.

没有通过完整的代码，我们将只显示由 MXNet 打印的 CNN。

```
Sequential(
   (0): Conv1D(None -> 32, kernel_size=(5,), stride=(2,)) 
   (1): LeakyReLU(0.01) 
   (2): Conv1D(None -> 64, kernel_size=(5,), stride=(2,)) 
   (3): LeakyReLU(0.01) 
   (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None) 
   (5): Conv1D(None -> 128, kernel_size=(5,), stride=(2,)) 
   (6): LeakyReLU(0.01) 
   (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None) 
   (8): Dense(None -> 220, linear) 
   (9): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None) 
   (10): LeakyReLU(0.01) 
   (11): Dense(None -> 220, linear) 
   (12): Activation(relu) 
   (13): Dense(None -> 1, linear) 
)
```

### 3.6. Hyperparameters

### 3.6. 超参数

The hyperparameters that we will track and optimize are:

我们将跟踪和优化的超参数是:

- `batch_size` : batch size of the LSTM and CNN : LSTM 和 CNN 的批量大小
- `cnn_lr`: the learningrate of the CNN : CNN 的学习速度
- `strides`: the number of strides in the CNN : 美国有线电视新闻网的进步数字
- `lrelu_alpha`: the alpha for the LeakyReLU in the GAN : 互联网组织里的 LeakyReLU 的 alpha
- `batchnorm_momentum`: momentum for the batch normalisation in the CNN 美国有线电视新闻网正常化的势头
- `padding`: the padding in the CNN : 美国有线电视新闻网的填充
- `kernel_size':1`: kernel size in the CNN : 内核大小在 CNN
- `dropout`: dropout in the LSTM : 伦敦科学技术学院辍学
- `filters`: the initial number of filters : 过滤器的初始数目

We will train over 200 `epochs`.

我们将训练200多个时代。

------

### 4. Hyperparameters optimisation

### 图4。 超参数优化

After the GAN trains on the 200 epochs it will record the MAE (which is the error function in the LSTM, the GG) and pass it as a reward value to the Reinforcement learning that will decide whether to change the hyperparameters of keep training with the same set of hyperparameters. As described later, this approach is strictly for experimenting with RL.

当 GAN 在200个时代训练后，它将记录 MAE (这是 LSTM，GG 中的错误函数) ，并将其作为奖励值传递给强化学习，后者将决定是否改变相同超参数集继续训练的超参数。 正如后面所描述的，这种方法严格地用于 RL 的实验。

If the RL decides it will update the hyperparameters it will call Bayesian optimisation (discussed below) library that will give the next best expected set of the hyperparams

如果 RL 决定更新超参数，它将称为贝叶斯优化(下面讨论)库，它将提供超参数的下一个最佳预期集

### 4.1. Reinforcement learning for hyperparameters optimization

### 4.1. 超参数优化强化学习

Why do we use reinforcement learning in the hyperparameters optimization? Stock markets change all the time. Even if we manage to train our GAN and LSTM to create extremely accurate results, the results might only be valid for a certain period. Meaning, we need to constantly optimise the whole process. To optimize the process we can:

为什么我们要在超参数优化中使用强化学习？ 股票市场一直在变化。 即使我们设法训练我们的 GAN 和 LSTM 来创建极其精确的结果，结果可能只在一定时期内有效。 也就是说，我们需要不断优化整个过程。 为了优化过程，我们可以:

- Add or remove features (e.g. add new stocks or currencies that might be correlated) 添加或删除功能(例如添加可能相关的新股票或货币)
- Improve our deep learning models. One of the most important ways to improve the models is through the hyper parameters (listed in Section 5). Once having found a certain set of hyperparameters we need to decide when to change them and when to use the already known set (exploration vs. exploitation). Also, stock market represents a continuous space that depends on millions parameters. 改进我们的深度学习模式。 改进模型的最重要的方法之一是通过超参数(在第5节中列出)。 一旦找到了一组特定的超参数，我们就需要决定什么时候更改它们，什么时候使用已知的超参数集(探索与开发)。 同时，股票市场是一个依赖于数百万个参数的连续空间

**Note**: The purpose of the whole reinforcement learning part of this notebook is more research oriented. We will explore different RL approaches using the GAN as an environment. There are many ways in which we can successfully perform hyperparameter optimization on our deep learning models without using RL. But… why not.

注意: 这本笔记本的整个强化学习部分的目的是更多的研究导向。 我们将探索使用氮化镓作为环境的不同 RL 方法。 有许多方法可以成功地对我们的深度学习模型进行超参数优化，而无需使用 RL。 但是... 为什么不呢。

**Note**: The next several sections assume you have some knowledge about RL — especially policy methods and Q-learning.

注: 接下来的几节假设你有一些 RL 的知识，特别是政策方法和 q 学习。

#### 4.1.1. Reinforcement Learning Theory

#### 4.1.1. 强化学习理论

Without explaining the basics of RL we will jump into the details of the specific approaches we implement here. We will use model-free RL algorithms for the obvious reason that we do not know the whole environment, hence there is no defined model for how the environment works — if there was we wouldn’t need to predict stock prices movements — they will just follow the model. We will use the two subdivisions of model-free RL — Policy optimization and Q-learning.

在没有解释 RL 的基础知识的情况下，我们将跳转到我们在这里实现的具体方法的细节。 我们将使用无模型 RL 算法，显然是因为我们不了解整个环境，因此没有关于环境如何运作的定义模型ーー如果有的话，我们就不需要预测股票价格的走势ーー他们只会遵循这个模型。 我们将使用无模型 RL 的两个子集: 策略优化和 q 学习。

- **Q-learning** — in Q-learning we learn the **value** of taking an action from a given state. **Q-value** is the expected return after taking the action. We will use **Rainbow** which is a combination of seven Q learning algorithms. Q 学习——在 q 学习中，我们学习从给定状态采取行动的价值。 Q 值是采取行动后的预期收益。 我们将使用彩虹，它是七个 q 学习算法的组合
- **Policy Optimization** — in policy optimization we learn the action to take from a given state. (if we use methods like Actor/Critic) we also learn the value of being in a given state. We will use **Proximal Policy Optimization**. 政策优化ーー在政策优化中，我们学习从给定状态采取的行动。 (如果我们使用像 actor / critic 这样的方法)我们还可以了解处于给定状态的价值。 我们将使用最近策略优化

One crucial aspect of building a RL algorithm is accurately setting the reward. It has to capture all aspects of the environment and the agent’s interaction with the environment. We define the reward, **R**, as:

建立 RL 算法的一个关键方面是准确地设置奖励。 它必须捕获环境的所有方面以及代理与环境的交互。 我们将奖励定义为 r:

Reward=2∗lossG+lossD+accuracyG,

奖励2次 / 次 lossG + lossD + accuracyG,

where lossG, accuracyG, and lossD are the Generator’s loss and accuracy, and Discriminator’s loss, respectively. The environment is the **GAN** and the results of the **LSTM** training. The action the different agents can take is how to change the hyperparameters of the GAN’s D and G nets.

其中，losg、 accuracyG 和 lossD 分别是生成器的损失和准确性，以及鉴别器的损失。 环境是氮化镓和 LSTM 培训的结果。 不同的代理人可以采取的行动是如何改变氮化镓的 d 和 g 网的超参数。

#### 4.1.1.1. Rainbow

#### 4.1.1.1. 彩虹

**What is Rainbow?**

什么是彩虹？

**Rainbow** ([link](https://arxiv.org/pdf/1710.02298.pdf)) is a Q learning based off-policy deep reinforcement learning algorithm combining seven algorithm together:

彩虹(链接)是一种基于 q 学习的非策略深度强化学习算法，它将7种算法结合在一起:

- **DQN**. DQN is an extension of Q learning algorithm that uses a neural network to represent the Q value. Similar to supervised (deep) learning, in DQN we train a neural network and try to minimize a loss function. We train the network by randomly sampling transitions (state, action, reward). The layers can be not only fully connected ones, but also convolutional, for example. Dqn. Dqn 是 q 学习算法的一个扩展，它使用神经网络来表示 q 值。 类似于有监督(深度)学习，在 DQN 我们训练一个神经网络，并试图减少损失函数。 我们通过随机采样转换(状态、动作、奖励)来训练网络。 例如，这些层不仅可以是完全连接的，还可以是卷积的
- **Double Q Learning**. Double QL handles a big problem in Q learning, namely the overestimation bias. 双 q 学习。 双 QL 处理 q 学习中的一个大问题，即高估偏差
- **Prioritized replay**. In the vanilla DQN, all transitions are stored in a replay buffer and it uniformly samples this buffer. However, not all transitions are equally beneficial during the learning phase (which also makes learning inefficient as more episodes are required). Prioritized experience replay doesn’t sample uniformly, rather it uses a distribution that gives higher probability to samples that have had higher Q loss in previous iterations. 优先重放。 在普通 DQN 中，所有转换都存储在重播缓冲区中，它统一采样这个缓冲区。 然而，并不是所有的转换在学习阶段都同样有益(这也使得学习效率低下，因为需要更多的片段)。 优先级经验重放不是统一的样本，而是使用一个分布，给予更高的概率样本有更高的 q 损失在前一次迭代
- **Dueling networks.** Dueling networks change the Q learning architecture a little by using two separate streams (i.e. having two different mini-neural networks). One stream is for the value and one for the *advantage*. Both of them share a convolutional encoder. The tricky part is the merging of the streams — it uses a special aggregator (*Wang et al. 2016*). 决斗网络。 决斗网络通过使用两个独立的流(即拥有两个不同的微型神经网络)稍微改变了 q 学习结构。 一个流是为了价值，一个流是为了优势。 它们都共享一个卷积编码器。 棘手的部分是流的合并ー它使用了一个特殊的聚合器(Wang 等人，2016)

*(Advantage*, formula is A(s,a)=Q(s,a)−V(s), generally speaking is a comparison of how good an action is compared to the average action for a specific state. Advantages are sometimes used when a ‘wrong’ action cannot be penalized with negative reward. So *advantage* will try to further reward good actions from the average actions.)

(优点，公式是 a (s，a) q (s，a)-v (s) ，一般来说是一个动作与一个特定状态下的平均动作的比较。 当一个"错误"的行为不能用负面的奖励来惩罚时，优势有时会被使用。 所以优势会进一步奖励平均行为的好行为。)

- **Multi-step learning.** The big difference behind Multi-step learning is that it calculates the Q-values using N-step returns (not only the return from the next step), which naturally should be more accurate. 多步学习。 多步学习背后最大的区别是它使用 n 步返回值(不仅仅是下一步返回值)来计算 q 值，这自然应该更准确
- **Distributional RL**. Q learning uses average estimated Q-value as target value. However, in many cases the Q-values might not be the same in different situations. Distributional RL can directly learn (or approximate) the distribution of Q-values rather than averaging them. Again, the math is much more complicated than that, but for us the benefit is more accurate sampling of the Q-values. 分布式电路。 Q 学习采用平均估计 q 值作为目标值。 然而，在许多情况下，q 值在不同情况下可能是不一样的。 分布式 RL 可以直接学习(或近似) q 值的分布，而不是求平均值。 同样，数学要比这复杂得多，但对我们来说，好处是 q 值的采样更准确
- **Noisy Nets**. Basic DQN implements a simple 𝜀-greedy mechanism to do exploration. This approach to exploration inefficient at times. The way Noisy Nets approach this issue is by adding a noisy linear layer. Over time, the network will learn how to ignore the noise (added as a noisy stream). But this learning comes at different rates in different parts of the space, allowing for state exploration. 吵闹的蚊帐。 基本 DQN 实现了一个简单的贪婪机制来进行探索。 这种勘探方法有时效率不高。 噪声网络处理这个问题的方法是通过添加一个噪声线性层。 随着时间的推移，网络将学会如何忽略噪音(作为一个嘈杂的流)。 但是这种学习在空间的不同部分以不同的速度进行，允许状态探索

**Note: Stay tuned — I will upload a MXNet/Gluon implementation on Rainbow to Github in early February 2019.**

注意: 请继续关注-我将在2019年2月初向 Github 上传一个关于 Rainbow 的 mxnet / gluon 实现。

#### 4.1.1.2. PPO

#### 4.1.1.2. 多酚氧化酶

**Proximal Policy Optimization** ([PPO](https://arxiv.org/pdf/1707.06347.pdf)) is a policy optimization model-free type of reinforcement learning. It is much simpler to implement that other algorithms and gives very good results.

最近策略优化是一种无模型的策略优化强化学习。 它比其他算法的实现简单得多，并且得到了很好的结果。

Why do we use PPO? One of the advantages of PPO is that it directly learns the policy, rather than indirectly via the values (the way Q Learning uses Q-values to learn the policy). It can work well in continuous action spaces, which is suitable in our use case and can learn (through mean and standard deviation) the distribution probabilities (if softmax is added as an output).

我们为什么要使用 PPO？ Ppo 的优点之一是它可以直接学习策略，而不是通过值间接学习(q 学习使用 q 值学习策略的方式)。 它可以很好地工作在连续的动作空间，这是适合我们的用例和可以学习(通过均值和标准差)的分布概率(如果软最大作为一个输出)。

The problem of policy gradient methods is that they are extremely sensitive to the step size choice — if it is small the progress takes too long (most probably mainly due to the need of a second-order derivatives matrix); if it is large, there is a lot noise which significantly reduces the performance. Input data is nonstationary due to the changes in the policy (also the distributions of the reward and observations change). As compared to supervised learning, poorly chosen step can be much more devastating as it affects the whole distribution of next visits. PPO can solve these issues. What is more, compared to some other approaches, PPO:

策略梯度方法的问题在于，它们对步长的选择极为敏感ーー如果步长较小，则进展时间过长(很可能主要是由于需要一个二阶导数矩阵) ; 如果步长较大，则存在大量噪声，从而显著降低了性能。 输入数据是非平稳的，这是由于策略的变化(也是奖励和观察值分布的变化)。 与监督式学习相比，选择不当的步骤可能更具破坏性，因为它影响到下一次访问的整个分布。 Ppo 可以解决这些问题。 更重要的是，与其他一些方法相比，PPO:

- is much less complicated, for example compared to **ACER**, which requires additional code for keeping the off-policy correlations and also a replay buffer, or **TRPO** which has a constraint imposed on the surrogate objective function (the KL divergence between the old and the new policy). This constraint is used to control the policy of changing too much — which might create instability. PPO reduces the computation (created by the constraint) by utilizing a *clipped (between [1- 𝜖, 1+𝜖]) surrogate objective function* and modifying the objective function with a penalty for having too big of an update. 例如，与 ACER 相比，它需要额外的代码来保持非策略关联性，还需要一个重放缓冲区，或者 TRPO 对替代目标函数(新旧策略之间的 KL 差异)施加约束。 这种约束被用来控制过度改变的政策ーー这可能会造成不稳定。 Ppo 通过利用[1-，1 + ]代理目标函数的截断和修改目标函数来减少计算量(由约束创建) ，修改后的目标函数会因更新过大而受到惩罚
- gives compatibility with algos that share parameters between value and policy function or auxiliary losses, as compared to TRPO (although PPO also have the gain of trust region PO). 与 TRPO 相比，给出了与共享价值和政策功能或辅助损失之间的参数的 algos 的兼容性(虽然 PPO 也有信赖域 PO 的增益)

**Note**: For the purpose of our exercise we won’t go too much into the research and optimization of RL approaches, PPO and the others included. Rather, we will take what is available and try to fit into our process for hyperparameter optimization for our **GAN**, **LSTM**, and **CNN** models. The code we will reuse and customize is created by OpenAI and is available [here](https://github.com/openai/baselines).

注意: 在我们的练习中，我们不会对包括 PPO 在内的 RL 方法进行过多的研究和优化。 相反，我们将利用现有资源，并尝试适应我们的 GAN、 LSTM 和 CNN 模型的超参数优化过程。 我们将重用和定制的代码是由 OpenAI 创建的，可以在这里找到。

#### 4.1.2. Further work on Reinforcement learning

#### 4.1.2. 关于强化学习的进一步工作

Some ideas for further exploring reinforcement learning:

关于进一步探索强化学习的一些想法:

- One of the first things I will introduce next is using **Augmented Random Search** ([link](https://arxiv.org/pdf/1803.07055.pdf)) as an alternative algorithm. The authors of the algorithm (out of UC, Berkeley) have managed to achieve similar rewards results as other state of the art approaches, such as PPO, but on average 15 times faster. 我接下来要介绍的第一件事是使用增强随机搜索(链接)作为替代算法。 该算法的作者(来自加州大学伯克利分校)已经设法实现了与其他最先进的方法(如 PPO)类似的奖励结果，但平均要快15倍
- Choosing a reward function is very important. I stated the currently used reward function above, but I will try to play with different functions as an alternative. 选择奖励函数是非常重要的。 我在上面提到了当前使用的奖励功能，但是我会尝试使用不同的功能作为替代
- Using **Curiosity** as an exploration policy. 使用好奇号作为一种探索策略
- Create **multi-agent** architecture as proposed by Berkeley’s AI Research team (BAIR) — [link](https://bair.berkeley.edu/blog/2018/12/12/rllib/). 按照伯克利人工智能研究团队(BAIR)ー link 的提议，创建多 agent 体系结构

### 4.2. Bayesian optimization

### 4.2. 贝叶斯优化

Instead of the grid search, that can take a lot of time to find the best combination of hyperparameters, we will use **Bayesian optimization**. The library that we’ll use is already implemented — [link](https://github.com/fmfn/BayesianOptimization).

我们将使用贝叶斯优化，而不是网格搜索，这需要花费大量的时间来寻找超参数的最佳组合。 我们将要使用的库已经实现了ー link。

#### 4.2.1. Gaussian process

#### 4.2.1. 高斯过程



![img](https://cdn-images-1.medium.com/max/1600/1*JCO5-noInHvLHeZaqU5Saw.png)

Gaussian process for Bayesian hyperparameter optimisation 贝叶斯超参数优化的高斯过程

------

### 5. The Result

### 5. 结果

Finally we will compare the output of the LSTM when the unseen (test) data is used as an input after different phases of the process.

最后，我们将比较 LSTM 的输出时，看不见的(测试)数据用作输入后，不同阶段的过程。

1. Plot after the first epoch. 第一轮epoch后画图

```
from utils import plot_prediction
plot_prediction('Predicted and Real price - after first epoch.')
```



![img](https://cdn-images-1.medium.com/max/1600/1*uKkExoSy4o6zo3dwfPoPwg.png)

\2. Plot after 50 epochs.

50轮epoch后画图

```
plot_prediction('Predicted and Real price - after first 50 epochs.')
```



![img](https://cdn-images-1.medium.com/max/1600/1*cqfAntAtxKMw-eo8s1b3MA.png)

```
plot_prediction('Predicted and Real price - after first 200 epochs.')
```



![img](https://cdn-images-1.medium.com/max/1600/1*-VuHm3t1eGQMziCU7xjcVA.png)

The RL run for ten episodes (we define an eposide to be one full GAN training on the 200 epochs.)

在 RL 运行10集(我们定义了一个完整的氮化物训练的200个时代的一个时代。)

```
plot_prediction('Final result.')
```



![img](https://cdn-images-1.medium.com/max/1600/1*FeWF_24neEhH9Gpra1DGmA.png)

#### As a next step, I will try to take everything separately and provide some analysis on what worked and why. Why did we receive these results and is it just by coinscidence? So stay tuned.

#### 作为下一步，我将尝试将所有事情分开，并提供一些关于什么起作用以及为什么起作用的分析。 为什么我们会得到这样的结果，仅仅是巧合吗？ 所以请继续关注

------


### 6 展望

- Next, I will try to create a RL environment for testing trading algorithms that decide when and how to trade. The output from the GAN will be one of the parameters in the environment. 接下来，我将尝试创建一个 RL 环境，用于测试决定何时以及如何进行交易的交易算法。 氮化镓的输出将是环境中的一个参数

------

### 7 免责声明

**This notebook is entirely informative. None of the content presented in this notebook constitutes a recommendation that any particular security, portfolio of securities, transaction or investment strategy is suitable for any specific person. Futures, stocks and options trading involves substantial risk of loss and is not suitable for every investor. The valuation of futures, stocks and options may fluctuate, and, as a result, clients may lose more than their original investment.**

这本笔记本信息量很大。 本笔记本中的任何内容都不构成建议，即任何特定证券、证券组合、交易或投资策略适合于任何特定的人。 期货、股票和期权交易涉及巨大的亏损风险，并不适合每个投资者。 期货、股票和期权的估值可能会波动，因此，客户损失的可能会超过他们最初的投资。

**All trading strategies are used at your own risk.**

所有的交易策略都是你自己承担风险。

在选择数据特征、选择算法、调优算法等方面，还有许多细节需要探索。 这个版本的笔记本花了我两个星期的时间才完成。 我相信这个过程中还有许多未经修饰的部分。 因此，任何意见和建议ー请分享。 我很乐意在当前的过程中添加和测试任何想法。

