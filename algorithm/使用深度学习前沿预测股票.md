[TOC]

# 1.å¼•è¨€

Using the latest advancements in deep learning to predict stock price movements
åˆ©ç”¨æ·±åº¦å­¦ä¹ çš„æœ€æ–°è¿›å±•æ¥é¢„æµ‹è‚¡ç¥¨ä»·æ ¼èµ°åŠ¿



![img](https://cdn-images-1.medium.com/max/1600/1*h6eC4YRmN1JDbnJO4kd11A.jpeg)

Overview of the complete architecture. å®Œæ•´ä½“ç³»ç»“æ„æ¦‚è¿°

> Link to the complete notebook: é“¾æ¥åˆ°å®Œæ•´çš„ç¬”è®°æœ¬:<https://github.com/borisbanushev/stockpredictionai>

In this notebook I will create a complete process for predicting stock price movements. Follow along and we will achieve some pretty good results. For that purpose we will use a **Generative Adversarial Network** (GAN) with **LSTM**, a type of Recurrent Neural Network, as generator, and a Convolutional Neural Network, **CNN**, as a discriminator. We use LSTM for the obvious reason tha t we are trying to predict time series data. Why we use GAN and specifically CNN as a discriminator? That is a good question: there are special sections on that later.

åœ¨è¿™ä¸ªç¬”è®°æœ¬ä¸­ï¼Œæˆ‘å°†åˆ›å»ºä¸€ä¸ªé¢„æµ‹è‚¡ç¥¨ä»·æ ¼èµ°åŠ¿çš„å®Œæ•´æµç¨‹ã€‚ ç»§ç»­ä¸‹å»ï¼Œæˆ‘ä»¬å°†å–å¾—ä¸€äº›ç›¸å½“ä¸é”™çš„ç»“æœã€‚ ä¸ºäº†è¾¾åˆ°è¿™ä¸ªç›®çš„ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç”Ÿæˆå¯¹æŠ—ä½“ç½‘ç»œ(Generative Adversarial Networkï¼ŒGAN)å’Œ LSTMï¼ŒLSTM æ˜¯é€’å½’ç¥ç»ç½‘ç»œçš„ä¸€ç§ï¼Œä½œä¸ºç”Ÿæˆå™¨ï¼ŒCNN çš„å·ç§¯ç¥ç»ç½‘ç»œï¼Œä½œä¸ºé‰´åˆ«å™¨ã€‚ æˆ‘ä»¬ä½¿ç”¨ LSTM æ˜¾ç„¶æ˜¯ä¸ºäº†é¢„æµ‹æ—¶é—´åºåˆ—æ•°æ®ã€‚ ä¸ºä»€ä¹ˆæˆ‘ä»¬ä½¿ç”¨ GANï¼Œç‰¹åˆ«æ˜¯ CNN ä½œä¸ºä¸€ä¸ªæ­§è§†è€…ï¼Ÿ è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é—®é¢˜: åé¢ä¼šæœ‰ä¸“é—¨çš„ç« èŠ‚è®¨è®ºã€‚

We will go into greater details for each step, of course, but the most difficult part is the GAN: very tricky part of successfully training a GAN is getting the right set of hyperparameters. For that reason we will use **Bayesian optimisation** (along with Gaussian processes) and **Deep Reinforcement learning** (DRL) for deciding when and how to change the GANâ€™s hyper parameters (the exploration vs. exploitation dilemma). In creating the reinforcement learning I will use the most recent advancements in the field, such as **Rainbow** and **PPO**.

å½“ç„¶ï¼Œæˆ‘ä»¬å°†å¯¹æ¯ä¸ªæ­¥éª¤è¿›è¡Œæ›´è¯¦ç»†çš„ä»‹ç»ï¼Œä½†æœ€å›°éš¾çš„éƒ¨åˆ†æ˜¯ GAN: æˆåŠŸè®­ç»ƒ GAN çš„éå¸¸æ£˜æ‰‹çš„éƒ¨åˆ†æ˜¯è·å¾—æ­£ç¡®çš„è¶…å‚æ•°é›†ã€‚ å‡ºäºè¿™ä¸ªåŸå› ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–(è¿åŒé«˜æ–¯è¿‡ç¨‹)å’Œæ·±å¼ºåŒ–å­¦ä¹ (DRL)æ¥å†³å®šä½•æ—¶ä»¥åŠå¦‚ä½•æ”¹å˜ GAN çš„è¶…å‚æ•°(æ¢ç´¢ä¸å¼€å‘çš„å›°å¢ƒ)ã€‚ åœ¨åˆ›å»ºå¼ºåŒ–å­¦ä¹ æ—¶ï¼Œæˆ‘å°†ä½¿ç”¨è¯¥é¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œå¦‚å½©è™¹å’Œ PPOã€‚

We will use a lot of different types of input data. Along with the stockâ€™s historical trading data and technical indicators, we will use the newest advancements in **NLP** (using â€˜Bidirectional Embedding Representations from Transformersâ€™, **BERT**, sort of a transfer learning for NLP) to create sentiment analysis (as a source for fundamental analysis), Fourier transforms for extracting overall trend directions, **stacked autoencoders** for identifying other high-level features, **Eigen portfolios** for finding correlated assets, autoregressive integrated moving average (**ARIMA**) for the stock function approximation, and many more, in order to capture as much information, patterns, dependencies, etc, as possible about the stock. As we all know, the more (data) the merrier. Predicting stock price movements is an extremely complex task, so the more we know about the stock (from different perspectives) the higher our changes are.

æˆ‘ä»¬å°†ä½¿ç”¨è®¸å¤šä¸åŒç±»å‹çš„è¾“å…¥æ•°æ®ã€‚ é™¤äº†è‚¡ç¥¨çš„å†å²äº¤æ˜“æ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ NLP çš„æœ€æ–°è¿›å±•(ä½¿ç”¨'æ¥è‡ªå˜å½¢é‡‘åˆšçš„åŒå‘åµŒå…¥è¡¨ç¤º'ï¼ŒBERTï¼Œç±»ä¼¼äº NLP çš„ä¼ é€’å­¦ä¹ )æ¥åˆ›å»ºæƒ…ç»ªåˆ†æ(ä½œä¸ºåŸºæœ¬é¢åˆ†æçš„ä¸€ä¸ªæ¥æº) ï¼Œå‚…é‡Œå¶å˜æ¢æ¥æå–æ€»ä½“è¶‹åŠ¿æ–¹å‘ï¼Œå †å å¼è‡ªåŠ¨ç¼–ç å™¨æ¥è¯†åˆ«å…¶ä»–é«˜çº§ç‰¹å¾ï¼ŒEigen æŠ•èµ„ç»„åˆæ¥å¯»æ‰¾ç›¸å…³èµ„äº§ï¼Œè‚¡ç¥¨ / ARIMAæ¨¡å‹ / å‡½æ•°é€¼è¿‘ï¼Œç­‰ç­‰ï¼Œä»¥è·å–å°½å¯èƒ½å¤šçš„å…³äºè‚¡ç¥¨çš„ä¿¡æ¯ï¼Œæ¨¡å¼ï¼Œç­‰ç­‰ã€‚ ä¼—æ‰€å‘¨çŸ¥ï¼Œæ•°æ®è¶Šå¤šè¶Šå¥½ã€‚ é¢„æµ‹è‚¡ç¥¨ä»·æ ¼èµ°åŠ¿æ˜¯ä¸€é¡¹æå…¶å¤æ‚çš„ä»»åŠ¡ï¼Œå› æ­¤æˆ‘ä»¬å¯¹è‚¡ç¥¨(ä»ä¸åŒçš„è§’åº¦)äº†è§£å¾—è¶Šå¤šï¼Œæˆ‘ä»¬çš„å˜åŒ–å°±è¶Šå¤§ã€‚

For the purpose of creating all neural nets we will use **MXNet** and its high-level APIâ€Šâ€”â€ŠGluon, and train them on multiple GPUs.

ä¸ºäº†åˆ›å»ºæ‰€æœ‰çš„ç¥ç»ç½‘ç»œï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ MXNet åŠå…¶é«˜çº§ API ãƒ¼ Gluonï¼Œå¹¶åœ¨å¤šä¸ª gpu ä¸Šè®­ç»ƒå®ƒä»¬ã€‚

**Note**: *Although I try to get into details of the math and the mechanisms behind almost all algorithms and techniques, this notebook is not explicitly intended to explain how machine/deep learning, or the stock markets, work. The purpose is rather to show how we can use different techniques and algorithms for the purpose of accurately predicting stock price movements, and to also give rationale behind the reason and usefulness of using each technique at each step.*

æ³¨æ„: å°½ç®¡æˆ‘è¯•å›¾æ·±å…¥äº†è§£å‡ ä¹æ‰€æœ‰ç®—æ³•å’ŒæŠ€æœ¯èƒŒåçš„æ•°å­¦å’Œæœºåˆ¶çš„ç»†èŠ‚ï¼Œä½†æ˜¯è¿™ä¸ªç¬”è®°æœ¬å¹¶æ²¡æœ‰æ˜ç¡®åœ°è§£é‡Šæœºå™¨ / æ·±åº¦å­¦ä¹ ï¼Œæˆ–è€…è‚¡ç¥¨å¸‚åœºæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚ å…¶ç›®çš„æ˜¯å±•ç¤ºæˆ‘ä»¬å¦‚ä½•ä½¿ç”¨ä¸åŒçš„æŠ€æœ¯å’Œç®—æ³•æ¥å‡†ç¡®åœ°é¢„æµ‹è‚¡ç¥¨ä»·æ ¼çš„å˜åŠ¨ï¼Œå¹¶ç»™å‡ºåœ¨æ¯ä¸ªæ­¥éª¤ä¸­ä½¿ç”¨æ¯ç§æŠ€æœ¯çš„åŸå› å’Œæœ‰ç”¨æ€§çš„ç†ç”±ã€‚

- https://medium.com/p/2edd6fac689d#42bb)



Accurately predicting the stock markets is a complex task as there are millions of events and pre-conditions for a particular stock to move in a particular direction. So we need to be able to capture as many of these pre-conditions as possible. We also need make several important assumptions: 1) markets are not 100% random, 2) history repeats, 3) markets follow peopleâ€™s rational behavior, and 4) the markets are â€˜*perfect*â€™. And, please, do read the Disclaimer at the bottom.

å‡†ç¡®åœ°é¢„æµ‹è‚¡ç¥¨å¸‚åœºæ˜¯ä¸€é¡¹å¤æ‚çš„ä»»åŠ¡ï¼Œå› ä¸ºä¸€åªè‚¡ç¥¨æœç€ç‰¹å®šçš„æ–¹å‘è¿åŠ¨æœ‰æ•°ä»¥ç™¾ä¸‡è®¡çš„äº‹ä»¶å’Œå‰ææ¡ä»¶ã€‚ æ‰€ä»¥æˆ‘ä»¬éœ€è¦å°½å¯èƒ½å¤šåœ°æ•æ‰è¿™äº›å‰ææ¡ä»¶ã€‚ æˆ‘ä»¬è¿˜éœ€è¦åšå‡ºå‡ ä¸ªé‡è¦çš„å‡è®¾: 1)å¸‚åœºä¸æ˜¯100% éšæœºçš„ï¼Œ2)å†å²é‡å¤ï¼Œ3)å¸‚åœºéµå¾ªäººä»¬çš„ç†æ€§è¡Œä¸ºï¼Œ4)å¸‚åœºæ˜¯"å®Œç¾çš„"ã€‚ å¦å¤–ï¼Œè¯·åŠ¡å¿…é˜…è¯»åº•éƒ¨çš„å…è´£å£°æ˜ã€‚

We will try to predict the price movements of **Goldman Sachs** (NYSE: GS). For the purpose, we will use the daily closing price from January 1st, 2010 to December 31st, 2018 (seven years for training purposes and two years for validation purposes). *We will use the terms â€˜Goldman Sachsâ€™ and â€˜GSâ€™ interchangeably*.

æˆ‘ä»¬å°†è¯•å›¾é¢„æµ‹é«˜ç››(NYSE: GS)çš„ä»·æ ¼èµ°åŠ¿ã€‚ ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨2010å¹´1æœˆ1æ—¥è‡³2018å¹´12æœˆ31æ—¥çš„æ¯æ—¥æ”¶ç›˜ä»·(ç”¨äºåŸ¹è®­ç›®çš„ä¸º7å¹´ï¼Œç”¨äºç¡®è®¤ç›®çš„ä¸º2å¹´)ã€‚ æˆ‘ä»¬å°†äº¤æ›¿ä½¿ç”¨"é«˜ç››"å’Œ"é«˜ç››"è¿™ä¸¤ä¸ªæœ¯è¯­ã€‚

------

# 2. æ•°æ®



We need to understand what affects whether GSâ€™s stock price will move up or down. It is what people as a whole think. Hence, we need to incorporate as much information (depicting the stock from different aspects and angles) as possible. (We will use daily dataâ€Šâ€”â€Š1,585 days to train the various algorithms (70% of the data we have) and predict the next 680 days (test data). Then we will compare the predicted results with a test (hold-out) data. Each type of data (we will refer to it as *feature*) is explained in greater detail in later sections, but, as a high-level overview, the features we will use are:

æˆ‘ä»¬éœ€è¦äº†è§£æ˜¯ä»€ä¹ˆå½±å“äº† GS çš„è‚¡ä»·æ˜¯ä¸Šæ¶¨è¿˜æ˜¯ä¸‹è·Œã€‚ è¿™æ˜¯äººä»¬ä½œä¸ºä¸€ä¸ªæ•´ä½“çš„æƒ³æ³•ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦çº³å…¥å°½å¯èƒ½å¤šçš„ä¿¡æ¯(æè¿°è‚¡ç¥¨ä»ä¸åŒçš„æ–¹é¢å’Œè§’åº¦)ã€‚ (æˆ‘ä»¬å°†ä½¿ç”¨æ¯æ—¥æ•°æ®ãƒ¼1,585å¤©æ¥è®­ç»ƒå„ç§ç®—æ³•(æˆ‘ä»¬å·²æœ‰çš„æ•°æ®çš„70%) ï¼Œå¹¶é¢„æµ‹æœªæ¥680å¤©(æµ‹è¯•æ•°æ®)ã€‚ ç„¶åæˆ‘ä»¬å°†é¢„æµ‹çš„ç»“æœä¸è¯•éªŒæ•°æ®è¿›è¡Œæ¯”è¾ƒã€‚ æ¯ç§ç±»å‹çš„æ•°æ®(æˆ‘ä»¬å°†ç§°ä¹‹ä¸ºç‰¹æ€§)åœ¨åé¢çš„ç« èŠ‚ä¸­ä¼šæœ‰æ›´è¯¦ç»†çš„è§£é‡Šï¼Œä½†æ˜¯ï¼Œä½œä¸ºä¸€ä¸ªé«˜å±‚æ¬¡çš„æ¦‚è¿°ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä»¥ä¸‹ç‰¹æ€§:

1. **Correlated assets**â€Šâ€”â€Šthese are other assets (any type, not necessarily stocks, such as commodities, FX, indices, or even fixed income securities). A big company, such as Goldman Sachs, obviously doesnâ€™t â€˜liveâ€™ in an isolated worldâ€Šâ€”â€Šit depends on, and interacts with, many external factors, including its competitors, clients, the global economy, the geo-political situation, fiscal and monetary policies, access to capital, etc. The details are listed later. ç›¸å…³èµ„äº§ãƒ¼ãƒ¼è¿™äº›æ˜¯å…¶ä»–èµ„äº§(ä»»ä½•ç±»å‹ï¼Œä¸ä¸€å®šæ˜¯è‚¡ç¥¨ï¼Œå¦‚å¤§å®—å•†å“ã€å¤–æ±‡ã€æŒ‡æ•°ï¼Œç”šè‡³å›ºå®šæ”¶ç›Šè¯åˆ¸)ã€‚ åƒé«˜ç››è¿™æ ·çš„å¤§å…¬å¸æ˜¾ç„¶ä¸æ˜¯ç”Ÿæ´»åœ¨ä¸€ä¸ªå­¤ç«‹çš„ä¸–ç•Œé‡Œãƒ¼ãƒ¼å®ƒä¾èµ–è®¸å¤šå¤–éƒ¨å› ç´ ï¼Œå¹¶ä¸ä¹‹äº’åŠ¨ï¼ŒåŒ…æ‹¬ç«äº‰å¯¹æ‰‹ã€å®¢æˆ·ã€å…¨çƒç»æµã€åœ°ç¼˜æ”¿æ²»å½¢åŠ¿ã€è´¢æ”¿å’Œè´§å¸æ”¿ç­–ã€è·å¾—èµ„æœ¬çš„é€”å¾„ç­‰ç­‰ã€‚ å…·ä½“ç»†èŠ‚ç¨ååˆ—å‡º
2. **Technical indicators**â€Šâ€”â€Ša lot of investors follow technical indicators. We will include the most popular indicators as independent features. Among themâ€Šâ€”â€Š7 and 21 days moving average, exponential moving average, momentum, Bollinger bands, MACD. æŠ€æœ¯æŒ‡æ ‡ãƒ¼ãƒ¼è®¸å¤šæŠ•èµ„è€…è¿½éšæŠ€æœ¯æŒ‡æ ‡ã€‚ æˆ‘ä»¬å°†åŒ…æ‹¬æœ€æµè¡Œçš„æŒ‡æ ‡ä½œä¸ºç‹¬ç«‹çš„åŠŸèƒ½ã€‚ å…¶ä¸­ãƒ¼7å¤©å’Œ21å¤©ç§»åŠ¨å¹³å‡çº¿ã€æŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿ã€åŠ¨é‡ã€å¸ƒæ—å¸¦ã€ MACD
3. **Fundamental analysis**â€Šâ€”â€ŠA very important feature indicating whether a stock might move up or down. There are two features that can be used in fundamental analysis: 1) Analysing the company performance using 10-K and 10-Q reports, analysing ROE and P/E, etc (we will not use this), and 2) Newsâ€Šâ€”â€Špotentially news can indicate upcoming events that can potentially move the stock in certain direction. We will read all daily news for Goldman Sachs and extract whether the total sentiment about Goldman Sachs on that day is positive, neutral, or negative (as a score from 0 to 1). As many investors closely read the news and make investment decisions based (partially of course) on news, there is a somewhat high chance that if, say, the news for Goldman Sachs today are extremely positive the stock will surge tomorrow. *One crucial point, we will perform feature importance (meaning how indicative it is for the movement of GS) on absolutely every feature (including this one) later on and decide whether we will use it. More on that later*. 
    For the purpose of creating accurate sentiment prediction, we will use Neural Language Processing (**NLP**). We will use **BERT**â€Šâ€”â€ŠGoogleâ€™s recently announced NLP approach for transfer learning for sentiment classification stock news sentiment extraction. åŸºæœ¬é¢åˆ†æãƒ¼ãƒ¼ä¸€ä¸ªæ˜¾ç¤ºè‚¡ç¥¨æ˜¯ä¸Šå‡è¿˜æ˜¯ä¸‹é™çš„éå¸¸é‡è¦çš„ç‰¹å¾ã€‚ æœ‰ä¸¤ä¸ªç‰¹å¾å¯ä»¥ç”¨äºåŸºæœ¬é¢åˆ†æ: 1)ä½¿ç”¨10-K å’Œ10-Q æŠ¥å‘Šåˆ†æå…¬å¸ä¸šç»©ï¼Œåˆ†æå‡€èµ„äº§æ”¶ç›Šç‡å’Œå¸‚ç›ˆç‡ç­‰(æˆ‘ä»¬ä¸ä¼šä½¿ç”¨è¿™ä¸ª) ï¼Œ2)æ–°é—»â€”â€”æ½œåœ¨çš„æ–°é—»å¯ä»¥æ˜¾ç¤ºå³å°†å‘ç”Ÿçš„äº‹ä»¶ï¼Œå¯èƒ½ä¼šæ¨åŠ¨è‚¡ç¥¨æœæŸä¸ªæ–¹å‘èµ°ã€‚ æˆ‘ä»¬å°†é˜…è¯»é«˜ç››çš„æ‰€æœ‰æ¯æ—¥æ–°é—»ï¼Œå¹¶æ‘˜å½•å½“å¤©å¯¹é«˜ç››çš„æ€»ä½“æƒ…ç»ªæ˜¯ç§¯æçš„ã€ä¸­æ€§çš„ï¼Œè¿˜æ˜¯æ¶ˆæçš„(å¾—åˆ†ä»0åˆ°1)ã€‚ éšç€è®¸å¤šæŠ•èµ„è€…å¯†åˆ‡å…³æ³¨æ–°é—»ï¼Œå¹¶æ ¹æ®æ–°é—»(å½“ç„¶æ˜¯éƒ¨åˆ†)åšå‡ºæŠ•èµ„å†³ç­–ï¼Œå¦‚æœ(æ¯”å¦‚è¯´)é«˜ç››ä»Šå¤©çš„æ¶ˆæ¯æä¸ºä¹è§‚ï¼Œé‚£ä¹ˆè¯¥è‚¡æ˜å¤©å°†å¤§å¹…é£™å‡çš„å¯èƒ½æ€§æœ‰äº›é«˜ã€‚ è‡³å…³é‡è¦çš„ä¸€ç‚¹æ˜¯ï¼Œç¨åæˆ‘ä»¬å°†å¯¹æ¯ä¸ªç‰¹æ€§(åŒ…æ‹¬è¿™ä¸ªç‰¹æ€§)æ‰§è¡Œç‰¹æ€§é‡è¦æ€§(è¿™æ„å‘³ç€å®ƒå¯¹äº GS çš„ç§»åŠ¨æœ‰å¤šä¹ˆé‡è¦) ï¼Œå¹¶å†³å®šæ˜¯å¦ä½¿ç”¨å®ƒã€‚ ç¨åå°†è¯¦ç»†ä»‹ç»ã€‚ ä¸ºäº†åˆ›å»ºå‡†ç¡®çš„æƒ…ç»ªé¢„æµ‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç¥ç»è¯­è¨€å¤„ç†(NLP)ã€‚ æˆ‘ä»¬å°†ä½¿ç”¨ BERT ãƒ¼ Google æœ€è¿‘å®£å¸ƒçš„ NLP æ–¹æ³•è¿›è¡Œæƒ…ç»ªåˆ†ç±»è‚¡ç¥¨æ–°é—»æƒ…ç»ªæå–çš„è½¬ç§»å­¦ä¹ 
4. **Fourier transforms**â€Šâ€”â€ŠAlong with the daily closing price, we will create Fourier transforms in order to generalize several long- and short-term trends. Using these transforms we will eliminate a lot of noise (random walks) and create approximations of the real stock movement. Having trend approximations can help the LSTM network pick its prediction trends more accurately. å‚…ç«‹å¶å˜æ¢ãƒ¼ãƒ¼é™¤äº†æ¯æ—¥æ”¶ç›˜ä»·å¤–ï¼Œæˆ‘ä»¬å°†åˆ›å»ºå‚…ç«‹å¶å˜æ¢ï¼Œä»¥æ¦‚æ‹¬å‡ ä¸ªé•¿æœŸå’ŒçŸ­æœŸè¶‹åŠ¿ã€‚ ä½¿ç”¨è¿™äº›å˜æ¢ï¼Œæˆ‘ä»¬å°†æ¶ˆé™¤å¤§é‡çš„å™ªéŸ³(éšæœºæ¸¸åŠ¨) ï¼Œå¹¶åˆ›é€ é€¼è¿‘çœŸæ­£çš„è‚¡ç¥¨è¿åŠ¨ã€‚ è¶‹åŠ¿è¿‘ä¼¼å¯ä»¥å¸®åŠ© LSTM ç½‘ç»œæ›´å‡†ç¡®åœ°é€‰æ‹©å…¶é¢„æµ‹è¶‹åŠ¿
5. Autoregressive Integrated Moving Average (**ARIMA**)â€Šâ€”â€ŠThis was one of the most popular techniques for predicting future values of time series data (in the pre-neural networks ages). Letâ€™s add it and see if it comes off as an important predictive feature. ARIMAæ¨¡å‹æ—¶é—´åºåˆ—(ARIMA)ãƒ¼è¿™æ˜¯é¢„æµ‹æ—¶é—´åºåˆ—æ•°æ®æœªæ¥å€¼(åœ¨å‰ç¥ç»ç½‘ç»œæ—¶ä»£)æœ€æµè¡Œçš„æŠ€æœ¯ä¹‹ä¸€ã€‚ è®©æˆ‘ä»¬æ·»åŠ å®ƒï¼Œçœ‹çœ‹å®ƒæ˜¯å¦æ˜¯ä¸€ä¸ªé‡è¦çš„é¢„æµ‹ç‰¹æ€§
6. **Stacked autoencoders**â€Šâ€”â€Šmost of the aforementioned features (fundamental analysis, technical analysis, etc) were found by people after decades of research. But maybe we have missed something. Maybe there are hidden correlations that people cannot comprehend due to the enormous amount of data points, events, assets, charts, etc. With stacked autoencoders (type of neural networks) we can use the power of computers and probably find new types of features that affect stock movements. Even though we will not be able to understand these features in human language, we will use them in the GAN. å †å å¼è‡ªåŠ¨ç¼–ç å™¨ãƒ¼å¤§å¤šæ•°ä¸Šè¿°ç‰¹å¾(åŸºæœ¬åˆ†æï¼ŒæŠ€æœ¯åˆ†æç­‰)æ˜¯äººä»¬ç»è¿‡å‡ åå¹´çš„ç ”ç©¶å‘ç°çš„ã€‚ ä½†ä¹Ÿè®¸æˆ‘ä»¬æ¼æ‰äº†ä»€ä¹ˆã€‚ ä¹Ÿè®¸ç”±äºæµ·é‡çš„æ•°æ®ç‚¹ã€äº‹ä»¶ã€èµ„äº§ã€å›¾è¡¨ç­‰ç­‰ï¼Œäººä»¬æ— æ³•ç†è§£å…¶ä¸­éšè—çš„ç›¸å…³æ€§ã€‚ é€šè¿‡å †å å¼è‡ªåŠ¨ç¼–ç å™¨(ä¸€ç§ç¥ç»ç½‘ç»œ) ï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨è®¡ç®—æœºçš„èƒ½åŠ›ï¼Œå¹¶å¯èƒ½å‘ç°å½±å“è‚¡ç¥¨èµ°åŠ¿çš„æ–°ç±»å‹çš„ç‰¹å¾ã€‚ å°½ç®¡æˆ‘ä»¬æ— æ³•ç†è§£äººç±»è¯­è¨€ä¸­çš„è¿™äº›ç‰¹å¾ï¼Œä½†æˆ‘ä»¬å°†åœ¨ GAN ä¸­ä½¿ç”¨å®ƒä»¬
7. **Deep Unsupervised learning** for anomaly detection in options pricing. We will use one more featureâ€Šâ€”â€Šfor every day we will add the price for 90-days call option on Goldman Sachs stock. Options pricing itself combines a lot of data. The price for options contract depends on the future value of the stock (analysts try to also predict the price in order to come up with the most accurate price for the call option). Using deep unsupervised learning (Self-organized Maps) we will try to spot anomalies in every dayâ€™s pricing. Anomaly (such as a drastic change in pricing) might indicate an event that might be useful for the LSTM to learn the overall stock pattern. æœŸæƒå®šä»·çš„æ·±å±‚æ¬¡éç›‘ç£å¼å­¦ä¹ å¼‚å¸¸æ£€æµ‹ã€‚ æˆ‘ä»¬å°†ä½¿ç”¨å¦ä¸€ä¸ªåŠŸèƒ½ãƒ¼ãƒ¼æˆ‘ä»¬æ¯å¤©éƒ½ä¼šå¢åŠ é«˜ç››è‚¡ç¥¨90å¤©çœ‹æ¶¨æœŸæƒçš„ä»·æ ¼ã€‚ æœŸæƒå®šä»·æœ¬èº«ç»“åˆäº†å¤§é‡çš„æ•°æ®ã€‚ æœŸæƒåˆçº¦çš„ä»·æ ¼å–å†³äºè‚¡ç¥¨çš„æœªæ¥ä»·å€¼(åˆ†æå¸ˆä¹Ÿè¯•å›¾é¢„æµ‹ä»·æ ¼ï¼Œä»¥ä¾¿ä¸ºçœ‹æ¶¨æœŸæƒæä¾›æœ€å‡†ç¡®çš„ä»·æ ¼)ã€‚ ä½¿ç”¨æ·±åº¦éç›‘ç£å¼å­¦ä¹ (è‡ªç»„ç»‡åœ°å›¾) ï¼Œæˆ‘ä»¬å°†å°è¯•åœ¨æ¯å¤©çš„å®šä»·ä¸­å‘ç°å¼‚å¸¸ã€‚ å¼‚å¸¸ç°è±¡(ä¾‹å¦‚å®šä»·çš„å‰§çƒˆå˜åŒ–)å¯èƒ½è¡¨æ˜ä¸€ä¸ªäº‹ä»¶ï¼Œè¿™ä¸ªäº‹ä»¶å¯èƒ½æœ‰åŠ©äº LSTM äº†è§£æ•´ä¸ªè‚¡ç¥¨æ¨¡å¼

Next, having so many features, we need to perform a couple of important steps:

æ¥ä¸‹æ¥ï¼Œæœ‰äº†è¿™ä¹ˆå¤šåŠŸèƒ½ï¼Œæˆ‘ä»¬éœ€è¦æ‰§è¡Œå‡ ä¸ªé‡è¦æ­¥éª¤:

1. Perform statistical checks for the â€˜qualityâ€™ of the data. If the data we create is flawed, then no matter how sophisticated our algorithms are, the results will not be positive. The checks include making sure the data does not suffer from heteroskedasticity, multicollinearity, or serial correlation. å¯¹æ•°æ®çš„"è´¨é‡"è¿›è¡Œç»Ÿè®¡æ£€æŸ¥ã€‚ å¦‚æœæˆ‘ä»¬åˆ›å»ºçš„æ•°æ®æ˜¯æœ‰ç¼ºé™·çš„ï¼Œé‚£ä¹ˆæ— è®ºæˆ‘ä»¬çš„ç®—æ³•å¤šä¹ˆå¤æ‚ï¼Œç»“æœéƒ½ä¸ä¼šæ˜¯æ­£é¢çš„ã€‚ è¿™äº›æ£€æŸ¥åŒ…æ‹¬ç¡®ä¿æ•°æ®ä¸å—å¼‚æ–¹å·®æ€§ã€å¤šé‡å…±çº¿æ€§æˆ–åºåˆ—ç›¸å…³æ€§çš„å½±å“
2. Create feature importance. If a feature (e.g. another stock or a technical indicator) has no explanatory power to the stock we want to predict, then there is no need for us to use it in the training of the neural nets. We will using **XGBoost** (eXtreme Gradient Boosting), a type of boosted tree regression algorithms. åˆ›å»ºç‰¹æ€§çš„é‡è¦æ€§ã€‚ å¦‚æœä¸€ä¸ªç‰¹å¾(ä¾‹å¦‚å¦ä¸€åªè‚¡ç¥¨æˆ–ä¸€ä¸ªæŠ€æœ¯æŒ‡æ ‡)ä¸æˆ‘ä»¬æƒ³è¦é¢„æµ‹çš„è‚¡ç¥¨æ²¡æœ‰è§£é‡ŠåŠ›ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±æ²¡æœ‰å¿…è¦åœ¨ç¥ç»ç½‘ç»œçš„è®­ç»ƒä¸­ä½¿ç”¨å®ƒã€‚ æˆ‘ä»¬å°†ä½¿ç”¨ XGBoost (eXtreme æ¢¯åº¦æå‡) ï¼Œè¿™æ˜¯ä¸€ç§å¢å¼ºçš„æ ‘å›å½’ç®—æ³•

As a final step of our data preparation, we will also create **Eigen portfolios**using Principal Component Analysis (**PCA**) in order to reduce the dimensionality of the features created from the autoencoders.

ä½œä¸ºæˆ‘ä»¬æ•°æ®å‡†å¤‡çš„æœ€åä¸€æ­¥ï¼Œæˆ‘ä»¬è¿˜å°†ä½¿ç”¨ä¸»æˆåˆ†åˆ†æ(PCA)åˆ›å»ºç‰¹å¾æŠ•èµ„ç»„åˆï¼Œä»¥é™ä½ç”±è‡ªåŠ¨ç¼–ç å™¨åˆ›å»ºçš„ç‰¹å¾çš„ç»´æ•°ã€‚

```
print('There are {} number of days in the dataset.'.format(dataset_ex_df.shape[0]))
output >>> There are 2265 number of days in the dataset.
```

Letâ€™s visualize the stock for the last nine years. The dashed vertical line represents the separation between training and test data.

è®©æˆ‘ä»¬æƒ³è±¡ä¸€ä¸‹è¿‡å»ä¹å¹´çš„è‚¡ç¥¨ã€‚ è™šçº¿å‚ç›´çº¿è¡¨ç¤ºè®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®çš„åˆ†å‰²çº¿ã€‚



![img](https://cdn-images-1.medium.com/max/1600/1*eHeqBsFLcfMzDIvyL01-eg.png)

Goldman Sachs stock price (NYSE:GS) é«˜ç››è‚¡ç¥¨ä»·æ ¼(çº½çº¦è¯åˆ¸äº¤æ˜“æ‰€: GS)

## 2.1. Correlated assets


As explained earlier we will use other assets as features, not only GS.

æ­£å¦‚å‰é¢è§£é‡Šçš„ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å…¶ä»–èµ„äº§ä½œä¸ºç‰¹å¾ï¼Œè€Œä¸ä»…ä»…æ˜¯ GSã€‚

So what other assets would affect GSâ€™s stock movements? Good understanding of the company, its lines of businesses, competitive landscape, dependencies, suppliers and client type, etc is very important for picking the right set of correlated assets:

é‚£ä¹ˆï¼Œè¿˜æœ‰å“ªäº›èµ„äº§ä¼šå½±å“ GS çš„è‚¡ä»·èµ°åŠ¿å‘¢ï¼Ÿ å¯¹å…¬å¸ã€ä¸šåŠ¡èŒƒå›´ã€ç«äº‰ç¯å¢ƒã€ä¾èµ–æ€§ã€ä¾›åº”å•†å’Œå®¢æˆ·ç±»å‹ç­‰æœ‰è‰¯å¥½çš„äº†è§£ï¼Œå¯¹äºé€‰æ‹©æ­£ç¡®çš„ç›¸å…³èµ„äº§éå¸¸é‡è¦:

- First are the **companies** similar to GS. We will add JPMorgan Chase and Morgan Stanley, among others, to the dataset. é¦–å…ˆæ˜¯ä¸ GS ç±»ä¼¼çš„å…¬å¸ã€‚ æˆ‘ä»¬å°†æŠŠæ‘©æ ¹å¤§é€šå’Œæ‘©æ ¹å£«ä¸¹åˆ©ç­‰å…¬å¸åŠ å…¥åˆ°æ•°æ®åº“ä¸­
- As an investment bank, Goldman Sachs depends on the **global economy**. Bad or volatile economy means no M&As or IPOs, and possibly limited proprietary trading earnings. That is why we will include global economy indices. Also, we will include LIBOR (USD and GBP denominated) rate, as possibly shocks in the economy might be accounted for by analysts to set these rates, and other **FI** securities. ä½œä¸ºä¸€å®¶æŠ•èµ„é“¶è¡Œï¼Œé«˜ç››ä¾èµ–å…¨çƒç»æµã€‚ ç³Ÿç³•æˆ–åŠ¨è¡çš„ç»æµæ„å‘³ç€æ²¡æœ‰å¹¶è´­æˆ–é¦–æ¬¡å…¬å¼€å‘è¡Œ(ipo) ï¼Œè‡ªè¥äº¤æ˜“æ”¶ç›Šå¯èƒ½å—åˆ°é™åˆ¶ã€‚ è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬å°†åŒ…æ‹¬å…¨çƒç»æµæŒ‡æ•°ã€‚ æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å°†åŒ…æ‹¬ä¼¦æ•¦é“¶è¡ŒåŒä¸šæ‹†å€Ÿåˆ©ç‡(LIBORï¼Œä»¥ç¾å…ƒå’Œè‹±é•‘è®¡ä»·) ï¼Œå› ä¸ºåˆ†æå¸ˆè®¾å®šè¿™äº›åˆ©ç‡å¯èƒ½ä¼šå¯¹ç»æµé€ æˆå†²å‡»ï¼Œä»¥åŠå…¶ä»–é‡‘èå·¥å…·è¯åˆ¸
- Daily volatility index (**VIX**)â€Šâ€”â€Šfor the reason described in the previous point. æ—¥æ³¢åŠ¨ç‡æŒ‡æ•°(VIX)ãƒ¼ãƒ¼åŸå› å¦‚å‰æ‰€è¿°
- **Composite indices**â€Šâ€”â€Šsuch as NASDAQ and NYSE (from USA), FTSE100 (UK), Nikkei225 (Japan), Hang Seng and BSE Sensex (APAC) indices. ç»¼åˆæŒ‡æ•°ãƒ¼ãƒ¼ä¾‹å¦‚çº³æ–¯è¾¾å…‹å’Œçº½çº¦è¯åˆ¸äº¤æ˜“æ‰€(æ¥è‡ªç¾å›½)ã€ FTSE100(è‹±å›½)ã€ Nikkei225(æ—¥æœ¬)ã€æ’ç”ŸæŒ‡æ•°å’Œ BSE Sensex æŒ‡æ•°
- **Currencies**â€Šâ€”â€Šglobal trade is many times reflected into how currencies move, ergo weâ€™ll use a basket of currencies (such as USDJPY, GBPUSD, etc) as features. è´§å¸ãƒ¼ãƒ¼å…¨çƒè´¸æ˜“å¤šæ¬¡åæ˜ åœ¨è´§å¸çš„èµ°åŠ¿ä¸Šï¼Œå› æ­¤æˆ‘ä»¬å°†ä½¿ç”¨ä¸€ç¯®å­è´§å¸(å¦‚ç¾å…ƒå…‘æ—¥å…ƒã€ GBPUSD ç­‰)ä½œä¸ºç‰¹å¾

Overall, we have 72 other assets in the datasetâ€Šâ€”â€Šdaily price for every asset.

æ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬åœ¨æ•°æ®é›†ä¸­è¿˜æœ‰72ç§å…¶ä»–èµ„äº§ãƒ¼ãƒ¼æ¯ç§èµ„äº§çš„æ¯æ—¥ä»·æ ¼

 

## 2.2. æŠ€æœ¯æŒ‡æ ‡

æˆ‘ä»¬å·²ç»è®¨è®ºäº†ä»€ä¹ˆæ˜¯æŠ€æœ¯æŒ‡æ ‡ï¼Œä»¥åŠä¸ºä»€ä¹ˆè¦ä½¿ç”¨å®ƒä»¬ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬ç›´æ¥è·³åˆ°ä»£ç ã€‚ æˆ‘ä»¬å°†ä¸ºGS æ„å»ºæŠ€æœ¯æŒ‡æ ‡ã€‚

```python
""" Function to create the technical indicators """
def get_technical_indicators(dataset):
    # Create 7 and 21 days Moving Average
    dataset['ma7'] = dataset['price'].rolling(window=7).mean()
    dataset['ma21'] = dataset['price'].rolling(window=21).mean()
    
    # Create MACD
    dataset['26ema'] = pd.ewma(dataset['price'], span=26)
    dataset['12ema'] = pd.ewma(dataset['price'], span=12)
    dataset['MACD'] = (dataset['12ema']-dataset['26ema'])
# Create Bollinger Bands
    dataset['20sd'] = pd.stats.moments.rolling_std(dataset['price'],20)
    dataset['upper_band'] = dataset['ma21'] + (dataset['20sd']*2)
    dataset['lower_band'] = dataset['ma21'] - (dataset['20sd']*2)
    
    # Create Exponential moving average
    dataset['ema'] = dataset['price'].ewm(com=0.5).mean()
    
    # Create Momentum
    dataset['momentum'] = dataset['price']-1
    
    return dataset
```

So we have the technical indicators (including MACD, Bollinger bands, etc) for every trading day. We have in total 12 technical indicators.

æ‰€ä»¥æˆ‘ä»¬æœ‰æ¯ä¸ªäº¤æ˜“æ—¥çš„æŠ€æœ¯æŒ‡æ ‡(åŒ…æ‹¬ MACDï¼ŒBollinger æ³¢æ®µï¼Œç­‰ç­‰)ã€‚ æˆ‘ä»¬æ€»å…±æœ‰12ä¸ªæŠ€æœ¯æŒ‡æ ‡ã€‚

Letâ€™s visualise the last 400 days for these indicators.

è®©æˆ‘ä»¬æƒ³è±¡ä¸€ä¸‹è¿™äº›æŒ‡æ ‡è¿‡å»400å¤©çš„æƒ…å†µã€‚



![img](https://cdn-images-1.medium.com/max/1600/1*TQEcFB7KMrM0x6Dp1l-LEQ.png)

Technical indicators for Goldman Sachsâ€Šâ€”â€Šlast 400 days. é«˜ç››çš„æŠ€æœ¯æŒ‡æ ‡ãƒ¼ãƒ¼æŒç»­400å¤©


## 2.3. åŸºæœ¬é¢åˆ†æ

For fundamental analysis we will perform sentiment analysis on all daily news about GS. Using sigmoid at the end, result will be between 0 and 1. The closer the score is to 0â€Šâ€”â€Šthe more negative the news is (closer to 1 indicates positive sentiment). For each day, we will create the average daily score (as a number between 0 and 1) and add it as a feature.

å¯¹äºåŸºæœ¬é¢åˆ†æï¼Œæˆ‘ä»¬å°†å¯¹æ‰€æœ‰å…³äº GS çš„æ—¥å¸¸æ–°é—»è¿›è¡Œæƒ…æ„Ÿåˆ†æã€‚ åœ¨æœ€åä½¿ç”¨ sigmoidï¼Œç»“æœåœ¨0åˆ°1ä¹‹é—´ã€‚ å¾—åˆ†è¶Šæ¥è¿‘0ï¼Œè´Ÿé¢æ¶ˆæ¯å°±è¶Šå¤š(æ¥è¿‘1è¡¨ç¤ºæ­£é¢æƒ…ç»ª)ã€‚å¯¹æ¯ä¸€å¤©æˆ‘ä»¬æ„å»ºä¸€ä¸ªæ—¥å‡å¾—åˆ†(ä»‹äº0å’Œ1ä¹‹é—´) ï¼Œå°†å®ƒä½œä¸ºä¸€ä¸ªç‰¹å¾åŠ å…¥ã€‚


### 2.3.1.  BERT


ä¸ºäº†å°†æ–°é—»åˆ†ä¸ºæ­£é¢æˆ–è´Ÿé¢(æˆ–ä¸­æ€§) ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [BERT](https://arxiv.org/abs/1810.04805)ï¼Œè¿™æ˜¯ä¸€ç§é¢„è®­ç»ƒçš„è¯­è¨€è¡¨å¾ã€‚

Pre-trained BERT models are already available in MXNet/Gluon. We just need to instantiated them and add two (arbitrary number) `Dense` layers, going to softmax - the score is from 0 to 1.

é¢„è®­ç»ƒçš„ BERT æ¨¡å‹åœ¨MXNet/Gluonä¸­å·²ç»å¯ç”¨ã€‚ æˆ‘ä»¬åªéœ€è¦å®ä¾‹åŒ–ä»–ä»¬ï¼Œå¹¶æ·»åŠ ä¸¤ä¸ª(æˆ–ä»»æ„æ•°é‡)`Dense`å±‚ï¼Œæ¥ç€ä½¿ç”¨softmaxè®¡ç®—å‡º1ä¸ªå¾—åˆ†ã€‚

```python
import bert
```



## 2.4. ä½¿ç”¨å‚…é‡Œå¶å˜æ¢åšè¶‹åŠ¿åˆ†æ


**å‚…é‡Œå¶å˜æ¢**ç”¨æ¥å¯¹å‡½æ•°åšä¸€æ¬¡å˜æ¢ï¼Œäº§ç”Ÿä¸€ç³»åˆ—æ­£å¼¦æ³¢(å…·æœ‰ä¸åŒçš„æŒ¯å¹…å’Œå¸§)ã€‚ åˆå¹¶è¿™äº›æ­£å¼¦æ³¢åå¾—åˆ°çš„ä¿¡å·è¿‘ä¼¼äºåŸå‡½æ•°ã€‚ ä»æ•°å­¦çš„è§’åº¦æ¥è¯´ï¼Œå˜æ¢çœ‹èµ·æ¥æ˜¯è¿™æ ·çš„:

![img](https://cdn-images-1.medium.com/max/1600/1*64AWoIDiBdVJLw5KkkqzOw.png)


æˆ‘ä»¬å°†ä½¿ç”¨å‚…ç«‹å¶å˜æ¢æå– GS è‚¡ç¥¨çš„å…¨å±€å’Œå±€éƒ¨è¶‹åŠ¿ï¼ŒåŒæ—¶ä¹Ÿå‡å°‘ä¸€äº›å™ªéŸ³ã€‚ è®©æˆ‘ä»¬æ¥çœ‹çœ‹å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚

```python
""" Code to create the Fuorier trasfrom  """
data_FT = dataset_ex_df[['Date', 'GS']]
close_fft = np.fft.fft(np.asarray(data_FT['GS'].tolist()))
fft_df = pd.DataFrame({'fft':close_fft})
fft_df['absolute'] = fft_df['fft'].apply(lambda x: np.abs(x))
fft_df['angle'] = fft_df['fft'].apply(lambda x: np.angle(x))
plt.figure(figsize=(14, 7), dpi=100)
fft_list = np.asarray(fft_df['fft'].tolist())
for num_ in [3, 6, 9, 100]:
    fft_list_m10= np.copy(fft_list); fft_list_m10[num_:-num_]=0
    plt.plot(np.fft.ifft(fft_list_m10), label='Fourier transform with {} components'.format(num_))
plt.plot(data_FT['GS'],  label='Real')
plt.xlabel('Days')
plt.ylabel('USD')
plt.title('Figure 3: Goldman Sachs (close) stock prices & Fourier transforms')
plt.legend()
plt.show()
```



![img](https://cdn-images-1.medium.com/max/1600/1*UTWq-m6nsWp4NrlP47NGhw.png)

å›¾3: é«˜ç››è‚¡ç¥¨çš„å‚…é‡Œå¶å˜æ¢


æ­£å¦‚å›¾3æ‰€ç¤ºï¼Œæˆ‘ä»¬ä½¿ç”¨çš„å‚…é‡Œå¶å˜æ¢åˆ†é‡è¶Šå¤šï¼Œé€¼è¿‘å‡½æ•°å°±è¶Šæ¥è¿‘çœŸå®çš„è‚¡ç¥¨ä»·æ ¼(100ä¸ªæˆåˆ†çš„è½¬æ¢å‡ ä¹ä¸åŸå§‹å‡½æ•°ç›¸åŒãƒ¼çº¢çº¿å’Œç´«çº¿å‡ ä¹é‡å )ã€‚ æˆ‘ä»¬ä½¿ç”¨å‚…ç«‹å¶å˜æ¢æ¥æå–é•¿æœŸå’ŒçŸ­æœŸè¶‹åŠ¿ï¼Œå› æ­¤æˆ‘ä»¬å°†åˆ†åˆ«ä½¿ç”¨3ã€6å’Œ9ä¸ªæˆåˆ†çš„è½¬æ¢ã€‚ å¯ä»¥æ¨æ–­å‡ºï¼ŒåŒ…å«3ä¸ªæˆåˆ†çš„è½¬æ¢è¡¨ç¤ºé•¿æœŸè¶‹åŠ¿ã€‚


å¦ä¸€ç§ç”¨æ¥å»é™¤æ•°æ®å™ªå£°çš„æŠ€æœ¯å«åš **å°æ³¢**ã€‚ å°æ³¢å’Œå‚…é‡Œå¶å˜æ¢ç»™å‡ºäº†ç±»ä¼¼çš„ç»“æœï¼Œæ‰€ä»¥æˆ‘ä»¬åªä½¿ç”¨å‚…ç«‹å¶å˜æ¢ã€‚


## 2.5. ä½¿ç”¨ARIMAä½œä¸ºç‰¹å¾


**Arima**æ˜¯ä¸€ç§æ—¶é—´åºåˆ—æ•°æ®çš„é¢„æµ‹æŠ€æœ¯ã€‚æˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨å®ƒï¼Œè™½ç„¶æˆ‘ä»¬æœ€ç»ˆä¸ä¼šä½¿ç”¨ARIMAé¢„æµ‹ï¼Œä½†æˆ‘ä»¬å°†ç”¨å®ƒæ¥é™å™ªï¼Œå¹¶(å¯èƒ½)æå–ä¸€äº›æ–°çš„æ¨¡å¼æˆ–ç‰¹å¾ã€‚

![img](https://cdn-images-1.medium.com/max/1600/1*sp4wrN9u3XkMCT5r3oaNQA.png)

åœ¨é«˜ç››è‚¡ç¥¨ä¸Šåº”ç”¨ARIMA

```python
error = mean_squared_error(test, predictions)
print('Test MSE: %.3f' % error)
output >>> Test MSE: 10.151
```



ä»å›¾5ä¸­çœ‹åˆ°çš„ï¼ŒARIMA ç»™å‡ºäº†ä¸€ä¸ªéå¸¸å¥½çš„è‚¡ç¥¨ä»·æ ¼è¿‘ä¼¼å€¼ã€‚ æˆ‘ä»¬å°†ä½¿ç”¨ ARIMA çš„é¢„æµ‹ä»·æ ¼ä½œä¸º LSTM çš„è¾“å…¥ç‰¹å¾ï¼Œå› ä¸ºæ­£å¦‚æˆ‘ä»¬ä¹‹å‰æåˆ°çš„ï¼Œæˆ‘ä»¬å¸Œæœ›æ•æ‰å°½å¯èƒ½å¤šçš„å…³äºé«˜ç››è‚¡ç¥¨çš„ç‰¹å¾å’Œæ¨¡å¼ã€‚ æˆ‘ä»¬å»æµ‹è¯• MSE (å‡æ–¹å·®)çš„10.151ï¼Œè¿™æœ¬èº«æ˜¯ä¸€ä¸ªä¸é”™çš„ç»“æœ(è€ƒè™‘åˆ°æˆ‘ä»¬ç¡®å®æœ‰å¾ˆå¤šæµ‹è¯•æ•°æ®) ï¼Œä½†æ˜¯ï¼Œæˆ‘ä»¬ä»ç„¶åªä½¿ç”¨å®ƒä½œä¸º LSTM çš„ä¸€ä¸ªç‰¹å¾ã€‚

## 2.6. ç»Ÿè®¡æ£€æµ‹



ç¡®ä¿æ•°æ®å…·æœ‰è‰¯å¥½çš„è´¨é‡å¯¹äºæˆ‘ä»¬çš„æ¨¡å‹éå¸¸é‡è¦ã€‚ ä¸ºäº†ç¡®ä¿æˆ‘ä»¬çš„æ•°æ®æ˜¯åˆé€‚çš„ï¼Œæˆ‘ä»¬å°†æ‰§è¡Œä¸€äº›ç®€å•çš„æ£€æŸ¥ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬å®ç°å’Œè§‚å¯Ÿçš„ç»“æœæ˜¯çœŸå®çš„ï¼Œè€Œä¸æ˜¯ç”±äºå‡è®¾æ•°æ®åˆ†å¸ƒé”™è¯¯è€Œå—åˆ°æŸå¤±ã€‚


### 2.6.1. å¼‚æ–¹å·®ï¼Œå¤šé‡å…±çº¿æ€§ï¼Œåºåˆ—ç›¸å…³

- **å¼‚æ–¹å·®ï¼ˆConditional Heteroskedasticityï¼‰**ï¼šå½“è¯¯å·®é¡¹(å›å½’é¢„æµ‹å€¼ä¸å®é™…å€¼ä¹‹å·®)ä¾èµ–äºæ•°æ®æ—¶ï¼Œå°±ä¼šå‘ç”Ÿæ¡ä»¶å¼‚æ–¹å·®æ€§ï¼Œä¾‹å¦‚ï¼Œå½“æ•°æ®ç‚¹(æ²¿ x è½´)å¢é•¿æ—¶ï¼Œè¯¯å·®é¡¹å°±ä¼šå¢é•¿ã€‚
- **å¤šé‡å…±çº¿æ€§ï¼ˆMulticollinearityï¼‰**ï¼šå¤šé‡å…±çº¿æ€§æ˜¯æŒ‡é”™è¯¯é¡¹(ä¹Ÿç§°ä¸ºæ®‹å·®)ç›¸å…³ã€‚
- **åºåˆ—ç›¸å…³ï¼ˆSerial correlationï¼‰**ï¼š  åºåˆ—ç›¸å…³æ˜¯å½“ä¸€ä¸ªæ•°æ®(ç‰¹å¾)æ˜¯å¦ä¸€ä¸ªç‰¹å¾çš„è¡¨è¾¾å¼ï¼Œæˆ–è€…å®Œå…¨ä¾èµ–å¦å¤–ä¸€ä¸ªç‰¹å¾ã€‚

è¿™é‡Œæˆ‘ä»¬ä¸ä¼šæ·±å…¥è®¨è®ºä»£ç ï¼Œå› ä¸ºå®ƒå¾ˆç®€å•ï¼Œè€Œä¸”æˆ‘ä»¬çš„é‡ç‚¹æ›´å¤šåœ°æ”¾åœ¨æ·±åº¦å­¦ä¹ éƒ¨åˆ†ï¼Œä½†æ˜¯æ•°æ®æ˜¯å®šæ€§çš„ã€‚


## 2.7. ç‰¹å¾å·¥ç¨‹

```python
print('Total dataset has {} samples, and {} features.'.format(dataset_total_df.shape[0],                                                          dataset_total_df.shape[1]))
output >>> Total dataset has 2265 samples, and 112 features.
```



å› æ­¤ï¼Œåœ¨æ·»åŠ äº†æ‰€æœ‰ç±»å‹çš„æ•°æ®(ç›¸å…³èµ„äº§ã€æŠ€æœ¯æŒ‡æ ‡ã€åŸºæœ¬é¢åˆ†æã€å‚…ç«‹å¶å’Œ Arima)ä¹‹åï¼Œæˆ‘ä»¬åœ¨2265å¤©å†…æ€»å…±æœ‰112ä¸ªç‰¹å¾(ç„¶è€Œï¼Œæ­£å¦‚å‰é¢æåˆ°çš„ï¼Œåªæœ‰1585å¤©ç”¨äºè®­ç»ƒæ•°æ®)ã€‚



æˆ‘ä»¬è¿˜æœ‰ä¸€äº›è‡ªåŠ¨ç¼–ç å™¨ç”Ÿæˆçš„ç‰¹å¾ã€‚


### 2.7.1. ä½¿ç”¨ XGBoostè®¡ç®—ç‰¹æ€§é‡è¦æ€§



æ‹¥æœ‰å¦‚æ­¤å¤šçš„ç‰¹å¾ä¹‹åï¼Œæˆ‘ä»¬å¿…é¡»è€ƒè™‘æ˜¯å¦æ‰€æœ‰è¿™äº›ç‰¹æ€§éƒ½èƒ½é¢„æµ‹ GSè‚¡ç¥¨çš„èµ°åŠ¿ã€‚ ä¾‹å¦‚ï¼Œæˆ‘ä»¬åœ¨æ•°æ®é›†ä¸­åŒ…æ‹¬äº†ä»¥ç¾å…ƒè®¡ä»·çš„ä¼¦æ•¦é“¶è¡ŒåŒä¸šæ‹†å€Ÿåˆ©ç‡ï¼ˆLIBORï¼‰ï¼Œå› ä¸ºæˆ‘ä»¬è®¤ä¸ºä¼¦æ•¦é“¶è¡ŒåŒä¸šæ‹†å€Ÿåˆ©ç‡çš„å˜åŒ–å¯èƒ½é¢„ç¤ºç€ç»æµçš„å˜åŒ–ï¼Œç›¸åº”çš„ï¼Œå¯èƒ½é¢„ç¤ºç€ GS è‚¡ç¥¨è¡Œä¸ºçš„å˜åŒ–ã€‚ ä½†æ˜¯æˆ‘ä»¬éœ€è¦æµ‹è¯•ã€‚ æœ‰è®¸å¤šæ–¹æ³•å¯ä»¥æµ‹è¯•ç‰¹å¾çš„é‡è¦æ€§ï¼Œä½†æ˜¯æˆ‘ä»¬å°†è¦åº”ç”¨XGBoostï¼Œå› ä¸ºå®ƒåœ¨åˆ†ç±»å’Œå›å½’é—®é¢˜ä¸Šéƒ½æä¾›äº†æœ€å¥½çš„ç»“æœã€‚



ç”±äºç‰¹å¾æ•°æ®éå¸¸å¤§ï¼Œä¸ºäº†åœ¨è¿™é‡Œè¿›è¡Œæ¼”ç¤ºï¼Œæˆ‘ä»¬å°†åªä½¿ç”¨æŠ€æœ¯æŒ‡æ ‡ã€‚ åœ¨çœŸæ­£çš„ç‰¹å¾é‡è¦æ€§æµ‹è¯•æ—¶ï¼Œæ‰€æœ‰ç‰¹å¾éƒ½å¾ˆé‡è¦ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸æ‰”æ‰ä»»ä½•ç‰¹å¾ï¼Œè€Œæ˜¯ç›´æ¥è®­ç»ƒGANã€‚

```python
regressor = xgb.XGBRegressor(gamma=0.0,n_estimators=150,base_score=0.7,colsample_bytree=1,learning_rate=0.05)
xgbModel = regressor.fit(X_train_FI,y_train_FI, eval_set = [(X_train_FI, y_train_FI), (X_test_FI, y_test_FI)], verbose=False)
fig = plt.figure(figsize=(8,8))
plt.xticks(rotation='vertical')
plt.bar([i for i in range(len(xgbModel.feature_importances_))], xgbModel.feature_importances_.tolist(), tick_label=X_test_FI.columns)
plt.title('Figure 6: Feature importance of the technical indicators.')
plt.show()
```



![img](https://cdn-images-1.medium.com/max/1600/1*rWs7xnMkjm7V6R7v5QhstA.png)

ä½¿ç”¨XGBoost çš„ç‰¹æ€§é‡è¦æ€§

æ¯«ä¸å¥‡æ€ª(å¯¹äºé‚£äº›æœ‰è‚¡ç¥¨äº¤æ˜“ç»éªŒçš„äººæ¥è¯´) ï¼ŒMA7ã€ MACD å’Œ BB æ˜¯å…¶ä¸­çš„é‡è¦ç‰¹å¾ã€‚

I followed the same logic for performing feature importance over the whole datasetâ€Šâ€”â€Šjust the training took longer and results were a little more difficult to read, as compared with just a handful of features.

æˆ‘æŒ‰ç…§åŒæ ·çš„é€»è¾‘å¯¹æ•´ä¸ªæ•°æ®é›†æ‰§è¡Œç‰¹å¾é‡è¦æ€§æ“ä½œãƒ¼ãƒ¼è®­ç»ƒèŠ±è´¹äº†æ›´é•¿çš„æ—¶é—´ï¼Œè€Œä¸”ç»“æœæœ‰ç‚¹éš¾ä»¥é˜…è¯»ï¼Œå’Œåªæœ‰å°‘æ•°å‡ ä¸ªç‰¹å¾çš„æƒ…å†µç›¸æ¯”ã€‚


## 2.8. åŸºäºå †å è‡ªç¼–ç å™¨æå–é«˜çº§ç‰¹å¾



åœ¨æˆ‘ä»¬ç»§ç»­ä½¿ç”¨è‡ªç¼–ç å™¨ä¹‹å‰ï¼Œæˆ‘ä»¬å°†æ¢ç´¢ä¸€ç§æ›¿ä»£çš„æ¿€æ´»å‡½æ•°ã€‚


### 2.8.1. æ¿€æ´»å‡½æ•°ãƒ¼ GELU (Gaussian Error)

æœ€è¿‘æå‡ºäº† GELU-â€Š[link](https://arxiv.org/pdf/1606.08415.pdf). ä½œè€…åœ¨è®ºæ–‡ä¸­ç»™å‡ºäº†å‡ ä¸ªå®ä¾‹ï¼Œç»“æœè¡¨æ˜ä½¿ç”¨ GELU ä½œä¸ºæ¿€æ´»å‡½æ•°çš„ç¥ç»ç½‘ç»œä¼˜äºä½¿ç”¨ ReLU ä½œä¸ºæ¿€æ´»å‡½æ•°çš„ç¥ç»ç½‘ç»œã€‚BERTä¸­ä¹Ÿä½¿ç”¨äº†GELUï¼Œè¿™æ˜¯æˆ‘ä»¬ç”¨äºæ–°é—»æƒ…æ„Ÿåˆ†æçš„ NLP æ–¹æ³•ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨ GELU ä½œä¸ºè‡ªåŠ¨ç¼–ç å™¨ã€‚

**æ³¨æ„**: ä¸‹é¢çš„å•å…ƒæ ¼æ˜¾ç¤ºäº† GELU æ•°å­¦èƒŒåçš„é€»è¾‘ã€‚ å®ƒå¹¶ä¸æ˜¯ä¸€ä¸ªæ¿€æ´»å‡½æ•°çš„çœŸå®å®ç°ã€‚ æˆ‘å¿…é¡»åœ¨ MXNet ä¸­å®ç° GELUã€‚ å¦‚æœæ‚¨å°†ä»£ç ä» `act_type='relu'` æ”¹ä¸º `act_type='gelu'`ï¼Œå®ƒä¸èµ·ä½œç”¨ï¼Œé™¤éæ‚¨æ›´æ”¹ MXNet çš„å®ç°ã€‚ å¯¹æ•´ä¸ªé¡¹ç›®å‘å‡ºè¯·æ±‚ï¼Œä»¥è®¿é—® GELU çš„ MXNet å®ç°ã€‚

è®©æˆ‘ä»¬å¯è§†åŒ– GELUã€ ReLU å’Œ LeakyReLU (æœ€åä¸€ä¸ªä¸»è¦ç”¨äº GANs â€”â€”æˆ‘ä»¬ä¹Ÿä½¿ç”¨å®ƒ)ã€‚

```python
def gelu(x):
    return 0.5 * x * (1 + math.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * math.pow(x, 3))))
def relu(x):
    return max(x, 0)
def lrelu(x):
    return max(0.01*x, x)
plt.figure(figsize=(15, 5))
plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=.5, hspace=None)
ranges_ = (-10, 3, .25)
plt.subplot(1, 2, 1)
plt.plot([i for i in np.arange(*ranges_)], [relu(i) for i in np.arange(*ranges_)], label='ReLU', marker='.')
plt.plot([i for i in np.arange(*ranges_)], [gelu(i) for i in np.arange(*ranges_)], label='GELU')
plt.hlines(0, -10, 3, colors='gray', linestyles='--', label='0')
plt.title('Figure 7: GELU as an activation function for autoencoders')
plt.ylabel('f(x) for GELU and ReLU')
plt.xlabel('x')
plt.legend()
plt.subplot(1, 2, 2)
plt.plot([i for i in np.arange(*ranges_)], [lrelu(i) for i in np.arange(*ranges_)], label='Leaky ReLU')
plt.hlines(0, -10, 3, colors='gray', linestyles='--', label='0')
plt.ylabel('f(x) for Leaky ReLU')
plt.xlabel('x')
plt.title('Figure 8: LeakyReLU')
plt.legend()
plt.show()
```



![img](https://cdn-images-1.medium.com/max/1600/1*XAJdlKP_tHY6dWuTnKc6lg.png)

Geluã€ ReLU å’Œ LeakyReLU çš„æ¯”è¾ƒ

**æ³¨æ„**: åœ¨è¿™ä¸ªç¬”è®°æœ¬çš„æœªæ¥ç‰ˆæœ¬ä¸­ï¼Œæˆ‘å°†å°è¯•ä½¿ç”¨ **U-Net** ([link](https://arxiv.org/abs/1505.04597))ï¼Œå¹¶å°è¯•åˆ©ç”¨å·ç§¯å±‚æå–(å’Œåˆ›å»º)æ›´å¤šè‚¡ç¥¨çš„è¿åŠ¨æ¨¡å¼çš„ç‰¹å¾ã€‚ ç°åœ¨ï¼Œæˆ‘ä»¬å°†åªä½¿ç”¨ä¸€ä¸ªç®€å•çš„è‡ªç¼–ç å™¨åªä»`dense`å±‚ã€‚

å¥½äº†ï¼Œå›åˆ°è‡ªåŠ¨ç¼–ç å™¨ï¼Œä¸‹é¢æè¿°(å›¾åƒåªæ˜¯ç¤ºæ„å›¾ï¼Œå®ƒä¸ä»£è¡¨çœŸæ­£çš„layersï¼Œunitsã€‚

**æ³¨æ„**: åœ¨åé¢çš„ç‰ˆæœ¬ä¸­è®¨è®ºçš„ä¸€ä»¶äº‹æƒ…æ˜¯ç§»é™¤decoderçš„æœ€åä¸€å±‚ã€‚ ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œåœ¨autoencodersä¸­encodersçš„æ•°é‡ç­‰äºdecodersçš„æ•°é‡ã€‚ ä½†æ˜¯ï¼Œæˆ‘ä»¬å¸Œæœ›æå–æ›´é«˜çº§åˆ«çš„ç‰¹å¾(è€Œä¸æ˜¯åˆ›å»ºç›¸åŒçš„è¾“å…¥) ï¼Œæ‰€ä»¥æˆ‘ä»¬å°±å¯ä»¥è·³è¿‡decodersçš„æœ€åä¸€å±‚ã€‚ åœ¨è®­ç»ƒæœŸé—´ï¼Œæˆ‘ä»¬ç”¨ç›¸åŒæ•°é‡çš„å±‚æ¥æ„å»ºç¼–ç å™¨å’Œè§£ç å™¨ï¼Œä½†æ˜¯å½“æˆ‘ä»¬åˆ›å»ºè¾“å‡ºæ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å€’æ•°ç¬¬äºŒå±‚ï¼Œå› ä¸ºå®ƒåŒ…å«äº†æ›´é«˜å±‚æ¬¡çš„ç‰¹å¾ã€‚



![img](https://cdn-images-1.medium.com/max/1600/1*-9iJNftM1g9eYksBNNTLyQ.jpeg)





æˆ‘ä»¬ä»autoencoderä¸­æ„å»ºäº†112ä¸ªç‰¹å¾ã€‚ ç”±äºæˆ‘ä»¬åªæƒ³è¦é«˜å±‚æ¬¡çš„ç‰¹å¾(æ•´ä½“æ¨¡å¼) ï¼Œæˆ‘ä»¬å¯¹112ä¸ªç‰¹å¾ä½¿ç”¨ä¸»æˆåˆ†åˆ†æåˆ†æ(PCA)ã€‚ è¿™å°†å‡å°‘æ•°æ®çš„ç»´åº¦(åˆ—æ•°)ã€‚ 

æ³¨æ„: å†ä¸€æ¬¡ï¼Œè¿™æ˜¯çº¯å®éªŒæ€§çš„ã€‚ æˆ‘ä¸èƒ½100% ç¡®å®šæ‰€æè¿°çš„é€»è¾‘æ˜¯å¦æ­£ç¡®ã€‚ å°±åƒäººå·¥æ™ºèƒ½å’Œæ·±åº¦å­¦ä¹ ä¸­çš„å…¶ä»–ä¸œè¥¿ä¸€æ ·ï¼Œè¿™æ˜¯ä¸€é—¨è‰ºæœ¯ï¼Œéœ€è¦å®éªŒã€‚


# 3 ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)

![img](https://cdn-images-1.medium.com/max/1600/1*hN0QKvuY4n07jxQCwRSmpg.jpeg)

GANçš„æ¶æ„å›¾



GANsæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ



æ­£å¦‚å‰é¢æåˆ°çš„ï¼Œè¿™ä¸ªç¬”è®°æœ¬çš„ç›®çš„ä¸æ˜¯è¯¦ç»†è§£é‡Šæ·±åº¦å­¦ä¹ èƒŒåçš„æ•°å­¦ï¼Œè€Œæ˜¯å±•ç¤ºå®ƒçš„åº”ç”¨ã€‚ å½“ç„¶ï¼Œåœ¨æˆ‘çœ‹æ¥ï¼Œå½»åº•å’Œéå¸¸æ‰å®çš„ç†è§£ä»åŸºç¡€åˆ°æœ€å°çš„ç»†èŠ‚ï¼Œæ˜¯éå¸¸å¿…è¦çš„ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬å°†å°è¯•åšä¸€ä¸ªå¹³è¡¡ï¼Œç»™å‡ºä¸€ä¸ªé«˜å±‚æ¬¡çš„GANå¦‚ä½•å·¥ä½œçš„æ¦‚è¿°ï¼Œä»¥ä¾¿è¯»è€…å……åˆ†ç†è§£ä½¿ç”¨GANSåœ¨é¢„æµ‹è‚¡ç¥¨ä»·æ ¼å˜åŠ¨èƒŒåçš„åŸç†ã€‚



ä¸€ä¸ª GAN ç½‘ç»œç”±ä¸¤ä¸ªæ¨¡å‹ç»„æˆ: ä¸€ä¸ªGenerator(G)å’ŒDiscriminator(D)ã€‚ è®­ç»ƒGANSçš„æ­¥éª¤å¦‚ä¸‹:

1. Generatorï¼šä½¿ç”¨éšæœºæ•°æ®(**z**)ç”Ÿæˆæ•°æ®ï¼Œè¯•å›¾ä½¿"ç”Ÿæˆ"çš„æ•°æ®ä¸çœŸå®æ•°æ®éš¾ä»¥åŒºåˆ†ï¼Œæˆ–è€…éå¸¸æ¥è¿‘çœŸå®æ•°æ®ã€‚ å…¶ç›®çš„æ˜¯å­¦ä¹ çœŸå®æ•°æ®çš„åˆ†å¸ƒã€‚
2. Discriminatorå°±æ˜¯ä¸€ä¸ªåˆ†ç±»å™¨ï¼Œé€šè¿‡å­¦ä¹ çœŸå®çš„å’Œç”Ÿæˆçš„æ•°æ®ï¼Œæ¥åˆ¤æ–­æ•°æ®æ˜¯æ¥è‡ªGeneratorè¿˜æ˜¯çœŸå®ä¸–ç•Œçš„ã€‚ Dä¼°è®¡è¾“å…¥æ ·æœ¬åœ¨çœŸå®æ•°æ®é›†åˆ†å¸ƒä¸Šçš„æ¦‚ç‡ã€‚ (ä¸¤ç§åˆ†å¸ƒçš„æ›´å¤šä¿¡æ¯å‚è€ƒ3.2 ).
3. ç„¶åï¼Œå°† G å’Œ D çš„lossesåˆå¹¶ï¼Œå¹¶å‘åä¼ æ’­ç»™generatorã€‚ å› æ­¤ï¼Œgeneratorçš„losså–å†³äºgeneratorå’Œdiscriminatorã€‚ è¿™ä¸€æ­¥èƒ½å¸®åŠ© Generator æ›´å¥½çš„å­¦ä¹ çœŸå®æ•°æ®çš„åˆ†å¸ƒã€‚ å¦‚æœGeneratorä¸èƒ½å¾ˆå¥½åœ°ç”ŸæˆçœŸå®æ•°æ®(å³è·ŸçœŸå®æ•°æ®æœ‰ç›¸åŒçš„åˆ†å¸ƒ) ï¼Œé‚£ä¹ˆDiscriminatorå°±å¾ˆå®¹æ˜“åŒºåˆ†å‡ºçœŸå®çš„å’Œç”Ÿæˆçš„ã€‚ å› æ­¤ï¼ŒDiscriminatorçš„æŸå¤±å°†éå¸¸å°ã€‚ å°çš„DiscriminatoræŸå¤±ä¼šå¯¼è‡´è¾ƒå¤§çš„generatoræŸå¤±ã€‚è¿™ä½¿å¾—æ„å»ºdiscriminatoræœ‰ç‚¹æ£˜æ‰‹ï¼Œå› ä¸ºå¤ªå¥½çš„discriminatoræ€»æ˜¯ä¼šå¯¼è‡´å·¨å¤§çš„generatoræŸå¤±ï¼Œä½¿generatoræ— æ³•å­¦ä¹ ã€‚
4.  è¿™ä¸ªè¿‡ç¨‹ä¸€ç›´æŒç»­ï¼Œç›´åˆ°Discriminatorä¸èƒ½ä»åŒºåˆ†çœŸå®æ•°æ®å’Œç”Ÿæˆæ•°æ®ã€‚

å½“ d å’Œ g ç»„åˆåœ¨ä¸€èµ·æ—¶ï¼Œd å’Œ g å°±åƒåœ¨ç©ä¸€ä¸ªæå°æå¤§çš„æ¸¸æˆ(Generatorè¯•å›¾æ„šå¼„Discriminatorï¼Œä½¿å®ƒå¢åŠ äº†ç”Ÿæˆæ•°æ®çš„æ¦‚ç‡ï¼Œå³æœ€å°åŒ– Ez âˆ¼ pz (z)[ log (1-d (g (z)))]ã€‚ Discriminatorå¸Œæœ›é€šè¿‡æœ€å¤§åŒ– Ex âˆ¼ pr (x)[ logD (x)]æ¥åˆ†ç¦»æ¥è‡ªGeneratorçš„æ•°æ®$$ D(G (z))$$çš„æ•°æ®ã€‚ ç„¶è€Œï¼Œåœ¨åˆ†ç¦»äº†æŸå¤±å‡½æ•°ä¹‹åï¼Œæˆ‘ä»¬è¿˜ä¸æ¸…æ¥šå¦‚ä½•å°†è¿™ä¸¤ä¸ªå‡½æ•°èšåˆåœ¨ä¸€èµ·(è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬ä½¿ç”¨äº†ä¸€äº›è¿›é˜¶ç‰ˆçš„gansï¼Œå¦‚ Wasserstein GAN)ã€‚ æ€»çš„æ¥è¯´ï¼Œç»¼åˆæŸå¤±å‡½æ•°çœ‹èµ·æ¥åƒ:



æ³¨æ„: è®­ç»ƒGANSçš„èµ„æ–™å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°ã€‚ [here](https://github.com/soumith/ganhacks).


## 3.1. ä¸ºä»€ä¹ˆä½¿ç”¨GAN ç”¨äºè‚¡ç¥¨å¸‚åœºé¢„æµ‹

ç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œ(GAN)æœ€è¿‘ä¸»è¦ç”¨äºåˆ›é€ é€¼çœŸçš„å›¾åƒã€ç»˜ç”»å’Œè§†é¢‘å‰ªè¾‘ã€‚GANåœ¨é¢„æµ‹æ—¶é—´åºåˆ—æ•°æ®æ–¹é¢çš„åº”ç”¨å¹¶ä¸å¤šï¼Œå°±åƒæˆ‘ä»¬çš„ä¾‹å­ä¸€æ ·ã€‚ ç„¶è€Œï¼Œä¸»è¦æ€æƒ³åº”è¯¥æ˜¯ç›¸åŒçš„ãƒ¼ãƒ¼æˆ‘ä»¬å¸Œæœ›é¢„æµ‹æœªæ¥çš„è‚¡å¸‚èµ°åŠ¿ã€‚ åœ¨æœªæ¥ï¼ŒGS è‚¡ç¥¨çš„æ¨¡å¼å’Œè¡Œä¸ºåº”è¯¥æˆ–å¤šæˆ–å°‘è·Ÿå†å²æ˜¯ç›¸åŒçš„(é™¤éå®ƒå¼€å§‹ä»¥ä¸€ç§å®Œå…¨ä¸åŒçš„æ–¹å¼è¿ä½œï¼Œæˆ–è€…ç»æµå‘ç”Ÿå·¨å¤§çš„å˜åŒ–)ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬å¸Œæœ›ä¸ºæœªæ¥"ç”Ÿæˆ"æ•°æ®ï¼Œè¿™äº›æ•°æ®çš„åˆ†å¸ƒä¸æˆ‘ä»¬å·²æœ‰çš„æ•°æ®â€”â€”å†å²äº¤æ˜“æ•°æ®â€”â€”ç›¸ä¼¼(å½“ç„¶ä¸æ˜¯å®Œå…¨ç›¸åŒ)ã€‚ å› æ­¤ï¼Œåœ¨ç†è®ºä¸Šï¼Œå®ƒåº”è¯¥å¯è¡Œã€‚

åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ LSTM ä½œä¸ºæ—¶é—´åºåˆ—generatorï¼Œä½¿ç”¨ CNN ä½œä¸ºdiscriminatorã€‚

## 3.2. Metropolis-Hastings GAN å’Œ Wasserstein GAN

æ³¨æ„: æ¥ä¸‹æ¥çš„å‡ èŠ‚å‡è®¾æ‚¨æœ‰ä¸€äº›ä½¿ç”¨ GANs çš„ç»éªŒã€‚

####  I. Metropolis-Hastings GAN

Uberçš„å·¥ç¨‹å›¢é˜Ÿæœ€è¿‘å¯¹ä¼ ç»Ÿçš„ GANs è¿›è¡Œäº†æ”¹è¿›ï¼Œç§°ä¸º Metropolis-Hastings GAN (MHGAN)ã€‚ Uber æ–¹æ³•èƒŒåçš„ç†å¿µ(ä»–ä»¬æ˜¯è¿™ä¹ˆè¯´çš„)æœ‰ç‚¹ç±»ä¼¼äºè°·æ­Œå’ŒåŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡åˆ›é€ çš„å¦ä¸€ç§æ–¹æ³•â€”â€”**Discriminator Rejection Sampling** ([DRS](https://arxiv.org/pdf/1810.06758.pdf))ã€‚ åŸºæœ¬ä¸Šï¼Œå½“æˆ‘ä»¬è®­ç»ƒ GAN æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨Dçš„å”¯ä¸€ç›®çš„æ˜¯æ›´å¥½åœ°è®­ç»ƒGã€‚ é€šå¸¸ï¼Œåœ¨å¯¹ GANè®­ç»ƒå¥½åï¼Œæˆ‘ä»¬ä¸å†ä½¿ç”¨Dã€‚ ç„¶è€Œï¼ŒMHGAN å’Œ DRS è¯•å›¾ä½¿ç”¨Dæ¥é€‰æ‹©Gç”Ÿæˆçš„æ ·æœ¬ä¸­æ¥è¿‘çœŸå®æ•°æ®åˆ†å¸ƒçš„æ•°æ®(MHGAN å’Œ DRSçš„ç»†å¾®å·®åˆ«åœ¨äº MHGAN ä½¿ç”¨é©¬å°”ç§‘å¤«è’™ç‰¹å¡æ´›(MCMC)è¿›è¡ŒæŠ½æ ·)ã€‚

MHGAN ä»Gäº§ç”Ÿ k æ ·æœ¬($$x_0'$$åˆ°$$ x_K'$$) ï¼Œå¹¶ä¾æ¬¡ä¼ å…¥D,è®©Då†³å®šæ˜¯å¦ä¿ç•™ã€‚ 



æ³¨æ„: MHGAN æœ€åˆæ˜¯ç”± Uber åœ¨ pytorch ä¸­å®ç°çš„ã€‚ æˆ‘åªæ˜¯æŠŠå®ƒè½¬ç§»åˆ° mxnet / gluonã€‚

#### 

å›¾10: MHGAN çš„å¯è§†åŒ–è¡¨ç¤º(æ¥è‡ªæœ€åˆçš„ Uber å¸–å­)ã€‚



![img](https://cdn-images-1.medium.com/max/1600/1*0iif-P3BGvCfDlsziH5xcg.png)

#### II. Wasserstein GAN

Training GANs is quite difficult. Models may never converge and mode collapse can easily happen. We will use a modification of GAN called **Wasserstein** GANâ€Šâ€”â€Š[WGAN](https://arxiv.org/pdf/1701.07875.pdf).

è®­ç»ƒGANsæ˜¯ç›¸å½“å›°éš¾çš„ã€‚ æ¨¡å‹å¯èƒ½æ°¸è¿œä¸ä¼šæ”¶æ•›ï¼Œæ¨¡å¼å´©æºƒå¾ˆå®¹æ˜“å‘ç”Ÿã€‚ æˆ‘ä»¬å°†ä½¿ç”¨Wasserstein** GANâ€Šâ€”â€Š[WGAN](https://arxiv.org/pdf/1701.07875.pdf).çš„ GANæ”¹è‰¯ç‰ˆã€‚

Again, we will not go into details, but the most notable points to make are:

åŒæ ·ï¼Œæˆ‘ä»¬ä¸ä¼šè¯¦ç»†è®¨è®ºï¼Œä½†æœ€å€¼å¾—æ³¨æ„çš„æ˜¯:

- As we know the main goal behind GANs is for the Generator to start transforming random noise into some given data that we want to mimic. Ergo, the idea of comparing the similarity between two distributions is very imperative in GANs. The two most widely used such metrics are: æ­£å¦‚æˆ‘ä»¬æ‰€çŸ¥é“çš„ï¼ŒGANs èƒŒåçš„ä¸»è¦ç›®æ ‡æ˜¯è®© Generator å¼€å§‹å°†éšæœºå™ªå£°è½¬æ¢æˆæˆ‘ä»¬æƒ³è¦æ¨¡æ‹Ÿçš„ç»™å®šæ•°æ®ã€‚ å› æ­¤ï¼Œæ¯”è¾ƒä¸¤ä¸ªå‘è¡Œç‰ˆä¹‹é—´çš„ç›¸ä¼¼æ€§åœ¨å¹¿åŸŸç½‘ä¸­æ˜¯éå¸¸å¿…è¦çš„ã€‚ ä½¿ç”¨æœ€å¹¿æ³›çš„ä¸¤ä¸ªæŒ‡æ ‡æ˜¯:
- **KL divergence** (Kullbackâ€“Leibler)â€Šâ€”â€ŠDKL(pâ€–q)=âˆ«xp(x)logp(x)q(x)dx. DKL is zero when p(x) is equal to q(x), Kl æ•£åº¦(Kullback-Leibler)ãƒ¼ DKL (p â€– q)âˆ« xp (x) logp (x) q (x) dxã€‚ å½“ p (x)ç­‰äº q (x)æ—¶ï¼ŒDKL ä¸ºé›¶,
- **JS Divergence** (Jensenâ€“Shannon). JS divergence is bounded by 0 and 1, and, unlike KL divergence, is symmetric and smoother. Significant success in GAN training was achieved when the loss was switched from **KL** to **JS**divergence. Js æ•£åº¦(Jensen-Shannon)ã€‚ Js æ•£åº¦ä»¥0å’Œ1ä¸ºç•Œï¼Œä¸ KL æ•£åº¦ä¸åŒï¼ŒJS æ•£åº¦æ˜¯å¯¹ç§°çš„ã€å¹³æ»‘çš„ã€‚ å½“æŸå¤±ä» KL è½¬æ¢åˆ° JS å‘æ•£æ—¶ï¼ŒGAN åŸ¹è®­å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸ
- WGAN uses **Wasserstein distance**, W(pr,pg)=1Ksupâ€–fâ€–Lâ‰¤Kğ”¼xâˆ¼pr[f(x)]âˆ’ğ”¼xâˆ¼pg[f(x)] (where sup stands for *supremum*), as a loss function (also called Earth Moverâ€™s distance, because it normally is interpreted as moving one pile of, say, sand to another one, both piles having different probability distributions, using minimum energy during the transformation). Compared to KL and JS divergences, Wasserstein metric gives a smooth measure (without sudden jumps in divergence). This makes it much more suitable for creating a stable learning process during the gradient descent. Wgan ä½¿ç”¨ Wasserstein è·ç¦» w (prï¼Œpg)1Ksup â€– f â€– l â‰¤ KEx âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼âˆ¼ã€‚ ä¸ KL å’Œ JS å‘æ•£ç›¸æ¯”ï¼ŒWasserstein åº¦é‡ç»™å‡ºäº†ä¸€ä¸ªå¹³æ»‘çš„åº¦é‡(åœ¨å‘æ•£ä¸­æ²¡æœ‰çªç„¶çš„è·³è·ƒ)ã€‚ è¿™ä½¿å¾—å®ƒæ›´é€‚åˆåœ¨æ¢¯åº¦ä¸‹é™æ³•æœŸé—´åˆ›å»ºä¸€ä¸ªç¨³å®šçš„å­¦ä¹ è¿‡ç¨‹
- Also, compared to **KL** and **JS**, Wasserstein distance is differentiable nearly everywhere. As we know, during backpropagation, we differentiate the loss function in order to create the gradients, which in turn update the weights. Therefore, having a differentiable loss function is quite important. å¦å¤–ï¼Œä¸ KL å’Œ JS ç›¸æ¯”ï¼ŒWasserstein è·ç¦»å‡ ä¹å¤„å¤„å¯å¾®ã€‚ æ­£å¦‚æˆ‘ä»¬æ‰€çŸ¥ï¼Œåœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬åŒºåˆ†æŸå¤±å‡½æ•°ï¼Œä»¥åˆ›å»ºæ¢¯åº¦ï¼Œä»è€Œæ›´æ–°æƒé‡ã€‚ å› æ­¤ï¼Œæœ‰ä¸€ä¸ªå¯å¾®çš„æŸå¤±å‡½æ•°æ˜¯ç›¸å½“é‡è¦çš„

#### Hands down, this was the toughest part of this notebook. Mixing WGAN and MHGAN took me three days.

#### æ¯«æ— ç–‘é—®ï¼Œè¿™æ˜¯è¿™æœ¬ç¬”è®°æœ¬ä¸­æœ€éš¾çš„éƒ¨åˆ†ã€‚ Wgan å’Œ MHGAN çš„æ··åˆèŠ±äº†æˆ‘ä¸‰å¤©æ—¶é—´

### 3.4. The Generatorâ€Šâ€”â€ŠOne layer RNN

### 3.4. ç”Ÿæˆå™¨ãƒ¼å•å±‚é€’å½’ç¥ç»ç½‘ç»œ

#### 3.4.1. LSTM or GRU

#### 3.4.1. Lstm æˆ– GRU

As mentioned before, the generator is a LSTM network a type of Recurrent Neural Network (RNN). RNNs are used for time-series data because they keep track of all previous data points and can capture patterns developing through time. Due to their nature, RNNs many time suffer from *vanishing gradient*â€Šâ€”â€Šthat is, the changes the weights receive during training become so small, that they donâ€™t change, making the network unable to converge to a minimal loss (The opposite problem can also be observed at timesâ€Šâ€”â€Šwhen gradients become too big. This is called *gradient exploding*, but the solution to this is quite simpleâ€Šâ€”â€Šclip gradients if they start exceeding some constant number, i.e. gradient clipping). Two modifications tackle this problemâ€Šâ€”â€ŠGated Recurrent Unit (**GRU**) and Long-Short Term Memory (**LSTM**). The biggest differences between the two are: 1) GRU has 2 gates (update and reset) and LSTM has 4 (update, input, forget, and output), 2) LSTM maintains an internal memory state, while GRU doesnâ€™t, and 3) LSTM applies a nonlinearity (sigmoid) before the output gate, GRU doesnâ€™t.

æ­£å¦‚å‰é¢æåˆ°çš„ï¼Œç”Ÿæˆå™¨æ˜¯ä¸€ä¸ª LSTM ç½‘ç»œï¼Œä¸€ç§ç±»å‹çš„é€’å½’ç¥ç»ç½‘ç»œã€‚ Rnn ç”¨äºæ—¶é—´åºåˆ—æ•°æ®ï¼Œå› ä¸ºå®ƒä»¬è·Ÿè¸ªæ‰€æœ‰ä»¥å‰çš„æ•°æ®ç‚¹ï¼Œå¹¶å¯ä»¥æ•æ‰éšæ—¶é—´å‘å±•çš„æ¨¡å¼ã€‚ ç”±äº RNNs çš„ç‰¹æ€§ï¼Œå®ƒä»¬ç»å¸¸å—åˆ°æ¢¯åº¦æ¶ˆå¤±çš„å›°æ‰°ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æƒå€¼çš„å˜åŒ–å˜å¾—å¾ˆå°ï¼Œä»¥è‡³äºå®ƒä»¬ä¸ä¼šå‘ç”Ÿå˜åŒ–ï¼Œä½¿å¾—ç½‘ç»œä¸èƒ½æ”¶æ•›åˆ°æœ€å°çš„æŸå¤±(å½“æ¢¯åº¦å˜å¾—å¤ªå¤§æ—¶ï¼Œæœ‰æ—¶ä¹Ÿä¼šå‡ºç°ç›¸åçš„é—®é¢˜)ã€‚ è¿™å°±æ˜¯æ‰€è°“çš„æ¢¯åº¦çˆ†ç‚¸ï¼Œä½†è§£å†³è¿™ä¸ªé—®é¢˜ç›¸å½“ç®€å•---- å¦‚æœæ¢¯åº¦å¼€å§‹è¶…è¿‡æŸä¸ªå¸¸æ•°ï¼Œä¾‹å¦‚æ¢¯åº¦å‰ªè¾‘ï¼Œé‚£ä¹ˆå°±ä¼šå‡ºç°å‰ªè¾‘æ¢¯åº¦ã€‚ é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†é—¨æ§å¾ªç¯å•å…ƒ(GRU)å’Œé•¿çŸ­æ—¶è®°å¿†(LSTM)ä¸¤ç§æ”¹è¿›ç®—æ³•ã€‚ ä¸¤è€…æœ€å¤§çš„åŒºåˆ«æ˜¯: 1) GRU æœ‰2ä¸ªé—¨(æ›´æ–°å’Œé‡ç½®) ï¼ŒLSTM æœ‰4ä¸ªé—¨(æ›´æ–°ã€è¾“å…¥ã€å¿˜è®°å’Œè¾“å‡º) ï¼Œ2) LSTM ä¿æŒå†…å­˜çŠ¶æ€ï¼Œè€Œ GRU æ²¡æœ‰ï¼Œ3) LSTM åœ¨è¾“å‡ºé—¨ä¹‹å‰ä½¿ç”¨éçº¿æ€§(sigmoid) ï¼Œè€Œ GRU æ²¡æœ‰ã€‚

In most cases, LSTM and GRU give similar results in terms of accuracy but GRU is much less computational intensive, as GRU has much fewer trainable params. LSTMs, however, and much more used.

åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼ŒLSTM å’Œ GRU åœ¨å‡†ç¡®æ€§æ–¹é¢ç»™å‡ºäº†ç±»ä¼¼çš„ç»“æœï¼Œä½†æ˜¯ GRU çš„è®¡ç®—å¼ºåº¦è¦å°å¾—å¤šï¼Œå› ä¸º GRU çš„å¯è®­ç»ƒæ¯”å–»è¦å°‘å¾—å¤šã€‚ ç„¶è€Œï¼Œlstmï¼Œä»¥åŠæ›´å¤šçš„åº”ç”¨ã€‚

Strictly speaking, the math behind the LSTM cell (the gates) is:

ä¸¥æ ¼åœ°è¯´ï¼ŒLSTM å•å…ƒ(é—¨)èƒŒåçš„æ•°å­¦æ˜¯:



![img](https://cdn-images-1.medium.com/max/1600/1*DUeR85B1raizYc_heyeRRA.png)

The math behind the LSTM cell Lstm å•å…ƒæ ¼èƒŒåçš„æ•°å­¦

where âŠ™is an element-wise multiplication operator, and, for all x=[x1,x2,â€¦,xk]âŠ¤âˆˆR^k the two activation functions:,

å…¶ä¸­âŠ™æ˜¯å…ƒç´ ç›¸ä¹˜è¿ç®—ç¬¦ï¼Œå¯¹äºæ‰€æœ‰çš„ x [ x1ï¼Œx2ï¼Œ... ï¼Œxk ] something âˆˆ r ^ k è¿™ä¸¤ä¸ªæ¿€æ´»å‡½æ•°: ,



![img](https://cdn-images-1.medium.com/max/1600/1*nyZL1-UP-AZQ6vNXRi34kQ.png)

#### 3.4.2. The LSTM architecture

#### 3.4.2. Lstm ä½“ç³»ç»“æ„

The LSTM architecture is very simpleâ€Šâ€”â€Šone `LSTM` layer with 112 input units (as we have 112 features in the dataset) and 500 hidden units, and one `Dense`layer with 1 output - the price for every day. The initializer is Xavier and we will use L1 loss (which is mean absolute error loss with **L1** regularization - see section 3.4.5. for more info on regularization).

Lstm çš„ä½“ç³»ç»“æ„éå¸¸ç®€å•: ä¸€ä¸ª LSTM å±‚æœ‰112ä¸ªè¾“å…¥å•å…ƒ(å› ä¸ºæˆ‘ä»¬åœ¨æ•°æ®é›†ä¸­æœ‰112ä¸ªç‰¹å¾)å’Œ500ä¸ªéšè—å•å…ƒï¼Œä¸€ä¸ªç¨ å¯†å±‚æœ‰1ä¸ªè¾“å‡ºâ€”â€”æ¯å¤©çš„ä»·æ ¼ã€‚ åˆå§‹åŒ–å¼æ˜¯ Xavierï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ L1æŸå¤±(å³ L1æ­£åˆ™åŒ–æ—¶çš„å¹³å‡ç»å¯¹è¯¯å·®æŸå¤±â€”â€”å‚è§ç¬¬3.4.5èŠ‚ã€‚ æ›´å¤šå…³äºæ­£è§„åŒ–çš„ä¿¡æ¯)ã€‚

**Note**â€Šâ€”â€ŠIn the code you can see we use `Adam` (with `learning rate` of .01) as an optimizer. Don't pay too much attention on that now - there is a section specially dedicated to explain what hyperparameters we use (learning rate is excluded as we have learning rate scheduler - section 3.4.3.) and how we optimize these hyperparameters - section 3.6.

æ³¨æ„: åœ¨ä»£ç ä¸­ä½ å¯ä»¥çœ‹åˆ°æˆ‘ä»¬ä½¿ç”¨ Adam (å­¦ä¹ ç‡ä¸º. 01)ä½œä¸ºä¼˜åŒ–å™¨ã€‚ ç°åœ¨ä¸è¦å¤ªåœ¨æ„è¿™ä¸€ç‚¹â€”â€”æœ‰ä¸€èŠ‚ä¸“é—¨è§£é‡Šæˆ‘ä»¬ä½¿ç”¨çš„è¶…å‚æ•°(å­¦ä¹ é€Ÿç‡è¢«æ’é™¤åœ¨å¤–ï¼Œå› ä¸ºæˆ‘ä»¬æœ‰å­¦ä¹ é€Ÿç‡è°ƒåº¦å™¨â€”â€”3.4.3èŠ‚) ä»¥åŠæˆ‘ä»¬å¦‚ä½•ä¼˜åŒ–è¿™äº›è¶…å‚æ•°-ç¬¬3.6èŠ‚ã€‚

```
gan_num_features = dataset_total_df.shape[1]
sequence_length = 17
class RNNModel(gluon.Block):
    def __init__(self, num_embed, num_hidden, num_layers, bidirectional=False, sequence_length=sequence_length, **kwargs):
        super(RNNModel, self).__init__(**kwargs)
        self.num_hidden = num_hidden
        with self.name_scope():
            self.rnn = rnn.LSTM(num_hidden, num_layers, input_size=num_embed, bidirectional=bidirectional, layout='TNC')
            self.decoder = nn.Dense(1, in_units=num_hidden)
    
    def forward(self, inputs, hidden):
        output, hidden = self.rnn(inputs, hidden)
        decoded = self.decoder(output.reshape((-1,self.num_hidden)))
        return decoded, hidden
    
    def begin_state(self, *args, **kwargs):
        return self.rnn.begin_state(*args, **kwargs)
    
lstm_model = RNNModel(num_embed=gan_num_features, num_hidden=500, num_layers=1)
lstm_model.collect_params().initialize(mx.init.Xavier(), ctx=mx.cpu())
trainer = gluon.Trainer(lstm_model.collect_params(), 'adam', {'learning_rate': .01})
loss = gluon.loss.L1Loss()
```

We will use 500 neurons in the LSTM layer and use Xavier initialization. For regularization weâ€™ll use L1. Letâ€™s see whatâ€™s inside the `LSTM` as printed by MXNet.

æˆ‘ä»¬å°†åœ¨ LSTM å±‚ä½¿ç”¨500ä¸ªç¥ç»å…ƒï¼Œå¹¶ä½¿ç”¨ Xavier åˆå§‹åŒ–ã€‚ ä¸ºäº†æ­£è§„åŒ–ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ L1ã€‚ è®©æˆ‘ä»¬çœ‹çœ‹ç”± MXNet æ‰“å°çš„ LSTM ä¸­æœ‰ä»€ä¹ˆã€‚

```
print(lstm_model)
output >>>
RNNModel(
   (rnn): LSTM(112 -> 500, TNC)
   (decoder): Dense(500 -> 1, linear)
)
```

As we can see, the input of the LSTM are the 112 features (`dataset_total_df.shape[1]`) which then go into 500 neurons in the LSTM layer, and then transformed to a single output - the stock price value.

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒLSTM çš„è¾“å…¥æ˜¯112ä¸ªç‰¹æ€§(dataset total df)ã€‚ å½¢çŠ¶[1]) ï¼Œç„¶åè¿›å…¥ LSTM å±‚çš„500ä¸ªç¥ç»å…ƒï¼Œç„¶åè½¬æ¢æˆä¸€ä¸ªå•ä¸€çš„è¾“å‡º-è‚¡ç¥¨ä»·å€¼ã€‚

The logic behind the LSTM is: we take 17 (`sequence_length`) days of data (again, the data being the stock price for GS stock every day + all the other feature for that day - correlated assets, sentiment, etc.) and try to predict the 18th day. Then we move the 17 days window with one day and again predict the 18th. We iterate like this over the whole dataset (of course in batches).

Lstm èƒŒåçš„é€»è¾‘æ˜¯: æˆ‘ä»¬ç”¨17å¤©(åºåˆ—é•¿åº¦)çš„æ•°æ®(åŒæ ·ï¼Œè¿™äº›æ•°æ®æ˜¯ GS è‚¡ç¥¨æ¯å¤©çš„è‚¡ç¥¨ä»·æ ¼ + è¯¥æ—¥ç›¸å…³èµ„äº§çš„æ‰€æœ‰å…¶ä»–ç‰¹å¾ï¼Œæƒ…ç»ªç­‰) ï¼Œå¹¶è¯•å›¾é¢„æµ‹ç¬¬18å¤©ã€‚ ç„¶åæˆ‘ä»¬æŠŠ17å¤©çª—å£æ”¹ä¸º1å¤©ï¼Œå†æ¬¡é¢„æµ‹18å¤©ã€‚ æˆ‘ä»¬åƒè¿™æ ·è¿­ä»£æ•´ä¸ªæ•°æ®é›†(å½“ç„¶æ˜¯æ‰¹å¤„ç†)ã€‚

In another post I will explore whether modification over the vanilla LSTM would be more beneficial, such as:

åœ¨å¦ä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å°†æ¢è®¨ä¿®æ”¹æ™®é€šçš„ LSTM æ˜¯å¦ä¼šæ›´æœ‰ç›Šï¼Œä¾‹å¦‚:

- using **bidirectional** LSTM layerâ€Šâ€”â€Šin theory, going backwards (from end of the data set towards the beginning) might somehow help the LSTM figure out the pattern of the stock movement. ä½¿ç”¨åŒå‘ LSTM å±‚ãƒ¼åœ¨ç†è®ºä¸Šï¼Œå‘å(ä»æ•°æ®é›†çš„æœ«ç«¯åˆ°å¼€å§‹)å¯èƒ½æœ‰åŠ©äº LSTM æ‰¾å‡ºè‚¡ç¥¨çš„è¿åŠ¨æ¨¡å¼
- using **stacked** RNN architectureâ€Šâ€”â€Šhaving not only one LSTM layer but 2 or more. This, however, might be dangerous, as we might end up overfitting the model, as we donâ€™t have a lot of data (we have just 1,585 day worth of data). ä½¿ç”¨å †å  RNN ç»“æ„ãƒ¼ãƒ¼ä¸ä»…æœ‰ä¸€ä¸ª LSTM å±‚ï¼Œè€Œä¸”æœ‰2ä¸ªæˆ–æ›´å¤šå±‚ã€‚ ç„¶è€Œï¼Œè¿™å¯èƒ½æ˜¯å±é™©çš„ï¼Œå› ä¸ºæˆ‘ä»¬å¯èƒ½æœ€ç»ˆä¼šè¿‡åº¦æ‹Ÿåˆæ¨¡å‹ï¼Œå› ä¸ºæˆ‘ä»¬æ²¡æœ‰å¤ªå¤šçš„æ•°æ®(æˆ‘ä»¬åªæœ‰1585å¤©çš„æ•°æ®)
- Exploring **GRU**â€Šâ€”â€Šas already explained, GRUsâ€™ cells are much simpler. æ¢ç´¢ GRU ãƒ¼ãƒ¼æ­£å¦‚å·²ç»è§£é‡Šè¿‡çš„ï¼ŒGRUs çš„ç»†èƒè¦ç®€å•å¾—å¤š
- Adding **attention** vectors to the RNN. å‘ç¥ç»ç½‘ç»œæ·»åŠ æ³¨æ„å‘é‡

#### 3.4.3. Learning rate scheduler

#### 3.4.3. å­¦ä¹ é€Ÿç‡è°ƒåº¦ç¨‹åº

One of the most important hyperparameters is the learning rate. Setting the learning rate for almost every optimizer (such as **SGD**, **Adam**, or **RMSProp**) is crucially important when training neural networks because it controls both the speed of convergence and the ultimate performance of the network. One of the simplest learning rate strategies is to have a fixed learning rate throughout the training process. Choosing a small learning rate allows the optimizer find good solutions, but this comes at the expense of limiting the initial speed of convergence. Changing the learning rate over time can overcome this tradeoff.

æœ€é‡è¦çš„è¶…å‚æ•°ä¹‹ä¸€æ˜¯å­¦ä¹ ç‡ã€‚ åœ¨è®­ç»ƒç¥ç»ç½‘ç»œæ—¶ï¼Œè®¾ç½®å‡ ä¹æ¯ä¸ªä¼˜åŒ–å™¨(å¦‚ SGDã€ Adam æˆ– RMSProp)çš„å­¦ä¹ é€Ÿç‡è‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒæ§åˆ¶ç€ç½‘ç»œçš„æ”¶æ•›é€Ÿåº¦å’Œæœ€ç»ˆæ€§èƒ½ã€‚ æœ€ç®€å•çš„å­¦ä¹ ç‡ç­–ç•¥ä¹‹ä¸€æ˜¯åœ¨æ•´ä¸ªåŸ¹è®­è¿‡ç¨‹ä¸­æœ‰ä¸€ä¸ªå›ºå®šçš„å­¦ä¹ ç‡ã€‚ é€‰æ‹©ä¸€ä¸ªå°çš„å­¦ä¹ é€Ÿç‡å¯ä»¥è®©ä¼˜åŒ–å™¨æ‰¾åˆ°å¥½çš„è§£å†³æ–¹æ¡ˆï¼Œä½†æ˜¯è¿™æ˜¯ä»¥é™åˆ¶åˆå§‹æ”¶æ•›é€Ÿåº¦ä¸ºä»£ä»·çš„ã€‚ éšç€æ—¶é—´çš„æ¨ç§»ï¼Œæ”¹å˜å­¦ä¹ é€Ÿç‡å¯ä»¥å…‹æœè¿™ç§æƒè¡¡ã€‚

Recent papers, such as [this](https://arxiv.org/pdf/1806.01593.pdf) one, show the benefits of changing the global learning rate during training, in terms of both convergence and time. Letâ€™s plot the learning rates weâ€™ll be using for each epoch.

æœ€è¿‘çš„ä¸€äº›è®ºæ–‡ï¼Œæ¯”å¦‚è¿™ç¯‡è®ºæ–‡ï¼Œå±•ç¤ºäº†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ”¹å˜å…¨å±€å­¦ä¹ é€Ÿåº¦çš„å¥½å¤„ï¼ŒåŒ…æ‹¬æ”¶æ•›æ€§å’Œæ—¶é—´ã€‚ è®©æˆ‘ä»¬ç”»å‡ºæ¯ä¸ªæ—¶ä»£çš„å­¦ä¹ é€Ÿç‡ã€‚

```
schedule = CyclicalSchedule(TriangularSchedule, min_lr=0.5, max_lr=2, cycle_length=500)
iterations=1500
plt.plot([i+1 for i in range(iterations)],[schedule(i) for i in range(iterations)])
plt.title('Learning rate for each epoch')
plt.xlabel("Epoch")
plt.ylabel("Learning Rate")
plt.show()
```



![img](https://cdn-images-1.medium.com/max/1600/1*kY6bUOtF9AlyUBwei8Noug.png)

#### 3.4.4. How to prevent overfitting and the bias-variance trade-off

#### 3.4.4. å¦‚ä½•é˜²æ­¢è¿‡æ‹Ÿåˆå’Œåå·®-æ–¹å·®æƒè¡¡

Having a lot of features and neural networks we need to make sure we prevent overfitting and be mindful of the total loss.

æœ‰å¾ˆå¤šçš„ç‰¹ç‚¹å’Œç¥ç»ç½‘ç»œï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿æˆ‘ä»¬é˜²æ­¢è¿‡åº¦è£…ä¿®å’Œç•™æ„çš„æ€»æŸå¤±ã€‚

We use several techniques for preventing overfitting (not only in the LSTM, but also in the CNN and the auto-encoders):

æˆ‘ä»¬ä½¿ç”¨äº†å‡ ç§æŠ€æœ¯æ¥é˜²æ­¢è¿‡æ‹Ÿåˆ(ä¸ä»…åœ¨ LSTM ä¸­ï¼Œè€Œä¸”åœ¨ CNN å’Œè‡ªåŠ¨ç¼–ç å™¨ä¸­) :

- **Ensuring data quality**. We already performed statistical checks and made sure the data doesnâ€™t suffer from multicollinearity or serial autocorrelation. Further we performed feature importance check on each feature. Finally, the initial feature selection (e.g. selecting correlated assets, technical indicators, etc.) was done with some domain knowledge about the mechanics behind the way stock markets work. ç¡®ä¿æ•°æ®è´¨é‡ã€‚ æˆ‘ä»¬å·²ç»è¿›è¡Œäº†ç»Ÿè®¡æ£€æŸ¥ï¼Œç¡®ä¿æ•°æ®ä¸ä¼šå—åˆ°å¤šé‡å…±çº¿æ€§æˆ–åºåˆ—è‡ªç›¸å…³çš„å½±å“ã€‚ è¿›ä¸€æ­¥ï¼Œæˆ‘ä»¬å¯¹æ¯ä¸ªç‰¹æ€§è¿›è¡Œäº†ç‰¹æ€§é‡è¦æ€§æ£€æŸ¥ã€‚ æœ€åï¼Œåˆå§‹ç‰¹å¾é€‰æ‹©(ä¾‹å¦‚é€‰æ‹©ç›¸å…³èµ„äº§ã€æŠ€æœ¯æŒ‡æ ‡ç­‰)æ˜¯åˆ©ç”¨è‚¡ç¥¨å¸‚åœºè¿è¡Œæœºåˆ¶çš„ä¸€äº›é¢†åŸŸçŸ¥è¯†å®Œæˆçš„
- **Regularization** (or weights penalty). The two most widely used regularization techniques are LASSO (**L1**) and Ridge (**L2**). L1 adds the mean absolute error and L2 adds mean squared error to the loss. Without going into too many mathematical details, the basic differences are: lasso regression (L1) does both variable selection and parameter shrinkage, whereas Ridge regression only does parameter shrinkage and end up including all the coefficients in the model. In presence of correlated variables, ridge regression might be the preferred choice. Also, ridge regression works best in situations where the least square estimates have higher variance. Therefore, it depends on our model objective. The impact of the two types of regularizations is quite different. While they both penalize large weights, L1 regularization leads to a non-differentiable function at zero. L2 regularization favors smaller weights, but L1 regularization favors weights that go to zero. So, with L1 regularization you can end up with a sparse modelâ€Šâ€”â€Šone with fewer parameters. In both cases the parameters of the L1 and L2 regularized models â€œshrinkâ€, but in the case of L1 regularization the shrinkage directly impacts the complexity (the number of parameters) of the model. Precisely, ridge regression works best in situations where the least square estimates have higher variance. L1 is more robust to outliers, is used when data is sparse, and creates feature importance. We will use L1. æ­£è§„åŒ–(æˆ–åŠ æƒæƒ©ç½š)ã€‚ æœ€å¸¸ç”¨çš„ä¸¤ç§æ­£åˆ™åŒ–æŠ€æœ¯æ˜¯ LASSO (L1)å’Œ Ridge (L2)ã€‚ 1åŠ ä¸Šå¹³å‡ç»å¯¹è¯¯å·®ï¼Œl 2åŠ ä¸Šå‡æ–¹å·®ã€‚ åœ¨ä¸æ¶‰åŠå¤ªå¤šæ•°å­¦ç»†èŠ‚çš„æƒ…å†µä¸‹ï¼Œå®ƒä»¬çš„åŸºæœ¬åŒºåˆ«æ˜¯: L1åŒæ—¶è¿›è¡Œå˜é‡é€‰æ‹©å’Œå‚æ•°æ”¶ç¼©ï¼Œè€Œå²­å›å½’åªè¿›è¡Œå‚æ•°æ”¶ç¼©ï¼Œæœ€ç»ˆåŒ…æ‹¬æ¨¡å‹ä¸­çš„æ‰€æœ‰ç³»æ•°ã€‚ åœ¨å­˜åœ¨ç›¸å…³å˜é‡çš„æƒ…å†µä¸‹ï¼Œå²­å›å½’å¯èƒ½æ˜¯é¦–é€‰ã€‚ æ­¤å¤–ï¼Œå²­å›å½’å·¥ä½œæœ€å¥½çš„æƒ…å†µä¸‹ï¼Œæœ€å°äºŒä¹˜ä¼°è®¡æœ‰è¾ƒé«˜çš„æ–¹å·®ã€‚ å› æ­¤ï¼Œè¿™å–å†³äºæˆ‘ä»¬çš„æ¨¡å‹ç›®æ ‡ã€‚ è¿™ä¸¤ç§è°ƒæ•´çš„å½±å“æ˜¯å®Œå…¨ä¸åŒçš„ã€‚ L1æ­£åˆ™åŒ–ä½¿å¾— L1æ­£åˆ™åŒ–å‡½æ•°åœ¨é›¶ç‚¹å¤„æ˜¯ä¸å¯å¾®çš„ã€‚ L2æ­£åˆ™åŒ–å€¾å‘äºæ›´å°çš„æƒé‡ï¼Œä½† L1æ­£åˆ™åŒ–å€¾å‘äºæƒé‡è¶‹äºé›¶ã€‚ å› æ­¤ï¼Œä½¿ç”¨ L1æ­£åˆ™åŒ–ï¼Œæ‚¨å¯ä»¥å¾—åˆ°ä¸€ä¸ªç¨€ç–æ¨¡å‹ãƒ¼ä¸€ä¸ªå‚æ•°è¾ƒå°‘çš„æ¨¡å‹ã€‚ åœ¨è¿™ä¸¤ç§æƒ…å†µä¸‹ï¼ŒL1å’Œ L2æ­£åˆ™åŒ–æ¨¡å‹çš„å‚æ•°"æ”¶ç¼©"ï¼Œä½†åœ¨ L1æ­£åˆ™åŒ–æƒ…å†µä¸‹ï¼Œæ”¶ç¼©ç›´æ¥å½±å“æ¨¡å‹çš„å¤æ‚æ€§(å‚æ•°æ•°ç›®)ã€‚ ç¡®åˆ‡åœ°è¯´ï¼Œå²­å›å½’åœ¨æœ€å°äºŒä¹˜ä¼°è®¡æ–¹å·®è¾ƒå¤§çš„æƒ…å†µä¸‹æ•ˆæœæœ€å¥½ã€‚ L1å¯¹å¼‚å¸¸å€¼æ›´å…·é²æ£’æ€§ï¼Œåœ¨æ•°æ®ç¨€ç–æ—¶ä½¿ç”¨ï¼Œå¹¶åˆ›å»ºç‰¹å¾çš„é‡è¦æ€§ã€‚ æˆ‘ä»¬å°†ä½¿ç”¨ L1
- **Dropout**. Dropout layers randomly remove nodes in the hidden layers. é€€å­¦ã€‚ è¾å­¦å±‚éšæœºåˆ é™¤éšè—å±‚ä¸­çš„èŠ‚ç‚¹
- **Dense-sparse-dense training**.â€Šâ€”â€Š[link](https://arxiv.org/pdf/1607.04381v1.pdf) ç¨ ç–ç¨ å¯†è®­ç»ƒã€‚ é“¾æ¥
- **Early stopping**. æå‰åœè½¦

Another important consideration when building complex neural networks is the bias-variance trade-off. Basically, the error we get when training nets is a function of the bias, the variance, and irreducible errorâ€Šâ€”â€ŠÏƒ (error due to noise and randomness). The simplest formula of the trade-off is: Error=bias^2+variance+Ïƒ.

å»ºç«‹å¤æ‚ç¥ç»ç½‘ç»œçš„å¦ä¸€ä¸ªé‡è¦è€ƒè™‘å› ç´ æ˜¯åå·®-æ–¹å·®æƒè¡¡ã€‚ åŸºæœ¬ä¸Šï¼Œè®­ç»ƒç½‘ç»œçš„è¯¯å·®æ˜¯åå·®ã€æ–¹å·®å’Œä¸å¯çº¦è¯¯å·®(å™ªå£°å’Œéšæœºæ€§é€ æˆçš„è¯¯å·®)çš„å‡½æ•°ã€‚ æœ€ç®€å•çš„æŠ˜è¡·å…¬å¼æ˜¯: è¯¯å·®åå·® ^ 2 + æ–¹å·® + ã€‚

- **Bias**. Bias measures how well a trained (on training dataset) algorithm can generalize on unseen data. High bias (underfitting) meaning the model cannot work well on unseen data. åè§ã€‚ åå·®è¡¡é‡ä¸€ä¸ªç»è¿‡è®­ç»ƒçš„(è®­ç»ƒæ•°æ®é›†ä¸Šçš„)ç®—æ³•åœ¨çœ‹ä¸è§çš„æ•°æ®ä¸Šçš„æ¦‚æ‹¬èƒ½åŠ›ã€‚ é«˜åå·®(æ¬ æ‹Ÿåˆ)æ„å‘³ç€è¯¥æ¨¡å‹ä¸èƒ½å¾ˆå¥½åœ°å¤„ç†çœ‹ä¸è§çš„æ•°æ®
- **Variance**. Variance measures the sensitivity of the model to changes in the dataset. High variance is the overfitting. æ–¹å·®ã€‚ æ–¹å·®åº¦é‡æ¨¡å‹å¯¹æ•°æ®é›†å˜åŒ–çš„æ•æ„Ÿæ€§ã€‚ é«˜æ–¹å·®æ˜¯è¿‡åº¦æ‹Ÿåˆ

### 3.5. The Discriminatorâ€Šâ€”â€ŠOne Dimentional CNN

### 3.5. ä¸€ç»´ç»†èƒç¥ç»ç½‘ç»œé‰´åˆ«å™¨

#### 4.5.1. Why CNN as a discriminator?

#### 4.5.1. ä¸ºä»€ä¹ˆ CNN æ˜¯ä¸€ä¸ªæ­§è§†è€…ï¼Ÿ

We usually use CNNs for work related to images (classification, context extraction, etc). They are very powerful at extracting features from features from features, etc. For example, in an image of a dog, the first convolutional layer will detect edges, the second will start detecting circles, and the third will detect a nose. In our case, data points form small trends, small trends form bigger, trends in turn form patterns. CNNsâ€™ ability to detect features can be used for extracting information about patterns in GSâ€™s stock price movements.

æˆ‘ä»¬é€šå¸¸ä½¿ç”¨ cnn å¤„ç†ä¸å›¾åƒç›¸å…³çš„å·¥ä½œ(åˆ†ç±»ã€ä¸Šä¸‹æ–‡æå–ç­‰)ã€‚ å®ƒä»¬åœ¨ä»ç‰¹å¾ä¸­æå–ç‰¹å¾æ–¹é¢éå¸¸å¼ºå¤§ã€‚ ä¾‹å¦‚ï¼Œåœ¨ç‹—çš„å›¾åƒä¸­ï¼Œç¬¬ä¸€å·ç§¯å±‚å°†æ£€æµ‹è¾¹ç¼˜ï¼Œç¬¬äºŒå±‚å°†å¼€å§‹æ£€æµ‹åœ†åœˆï¼Œç¬¬ä¸‰å±‚å°†æ£€æµ‹é¼»å­ã€‚ åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œæ•°æ®ç‚¹å½¢æˆå°è¶‹åŠ¿ï¼Œå°è¶‹åŠ¿å½¢æˆå¤§è¶‹åŠ¿ï¼Œè¶‹åŠ¿åè¿‡æ¥å½¢æˆæ¨¡å¼ã€‚ Cnn æ£€æµ‹ç‰¹å¾çš„èƒ½åŠ›å¯ç”¨äºæå– GS è‚¡ç¥¨ä»·æ ¼æ³¢åŠ¨æ¨¡å¼çš„ä¿¡æ¯ã€‚

Another reason for using CNN is that CNNs work well on spatial dataâ€Šâ€”â€Šmeaning data points that are closer to each other are more related to each other, than data points spread across. This should hold true for time series data. In our case each data point (for each feature) is for each consecutive day. It is natural to assume that the closer two days are to each other, the more related they are to each other. One thing to consider (although not covered in this work) is seasonality and how it might change (if at all) the work of the CNN.

ä½¿ç”¨ CNN çš„å¦ä¸€ä¸ªåŸå› æ˜¯ CNN èƒ½å¾ˆå¥½åœ°å¤„ç†ç©ºé—´æ•°æ®ãƒ¼ãƒ¼ä¹Ÿå°±æ˜¯è¯´ï¼Œç›¸äº’é è¿‘çš„æ•°æ®ç‚¹å½¼æ­¤ä¹‹é—´çš„è”ç³»è¦æ¯”æ•£å¸ƒåœ¨å„å¤„çš„æ•°æ®ç‚¹ä¹‹é—´çš„è”ç³»æ›´åŠ ç´§å¯†ã€‚ è¿™å¯¹äºæ—¶é—´åºåˆ—æ•°æ®æ¥è¯´æ˜¯æ­£ç¡®çš„ã€‚ åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæ¯ä¸ªæ•°æ®ç‚¹(å¯¹äºæ¯ä¸ªç‰¹æ€§)éƒ½æ˜¯è¿ç»­çš„æ¯ä¸€å¤©ã€‚ äººä»¬è‡ªç„¶è€Œç„¶åœ°è®¤ä¸ºï¼Œä¸¤å¤©çš„æ—¶é—´è¶Šæ¥è¿‘ï¼Œå½¼æ­¤ä¹‹é—´çš„å…³ç³»å°±è¶Šå¯†åˆ‡ã€‚ éœ€è¦è€ƒè™‘çš„ä¸€ä»¶äº‹(å°½ç®¡æœ¬æ–‡æ²¡æœ‰æ¶‰åŠ)æ˜¯å­£èŠ‚æ€§ä»¥åŠå®ƒå¯èƒ½å¦‚ä½•æ”¹å˜(å¦‚æœæœ‰çš„è¯) CNN çš„å·¥ä½œã€‚

**Note**: As many other parts in this notebook, using CNN for time series data is experimental. We will inspect the results, without providing mathematical or other proofs. And results might vary using different data, activation functions, etc.

æ³¨æ„: å’Œè¿™ä¸ªç¬”è®°æœ¬çš„å…¶ä»–éƒ¨åˆ†ä¸€æ ·ï¼Œä½¿ç”¨ CNN è·å–æ—¶é—´åºåˆ—æ•°æ®æ˜¯å®éªŒæ€§çš„ã€‚ æˆ‘ä»¬å°†æ£€æŸ¥ç»“æœï¼Œè€Œä¸æä¾›æ•°å­¦æˆ–å…¶ä»–è¯æ˜ã€‚ ä½¿ç”¨ä¸åŒçš„æ•°æ®ã€æ¿€æ´»å‡½æ•°ç­‰ï¼Œç»“æœå¯èƒ½ä¼šæœ‰æ‰€ä¸åŒã€‚

#### 3.5.1. The CNN Architecture

#### 3.5.1. çš„æ¶æ„



![img](https://cdn-images-1.medium.com/max/1600/1*My1hiYMJeYWIBbuUQJfqKg.jpeg)

The architecture of the proposed CNN model. æå‡ºçš„ CNN æ¨¡å‹çš„ä½“ç³»ç»“æ„

Without going through the full code, weâ€™ll just show the CNN as printed by MXNet.

æ²¡æœ‰é€šè¿‡å®Œæ•´çš„ä»£ç ï¼Œæˆ‘ä»¬å°†åªæ˜¾ç¤ºç”± MXNet æ‰“å°çš„ CNNã€‚

```
Sequential(
   (0): Conv1D(None -> 32, kernel_size=(5,), stride=(2,)) 
   (1): LeakyReLU(0.01) 
   (2): Conv1D(None -> 64, kernel_size=(5,), stride=(2,)) 
   (3): LeakyReLU(0.01) 
   (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None) 
   (5): Conv1D(None -> 128, kernel_size=(5,), stride=(2,)) 
   (6): LeakyReLU(0.01) 
   (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None) 
   (8): Dense(None -> 220, linear) 
   (9): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None) 
   (10): LeakyReLU(0.01) 
   (11): Dense(None -> 220, linear) 
   (12): Activation(relu) 
   (13): Dense(None -> 1, linear) 
)
```

### 3.6. Hyperparameters

### 3.6. è¶…å‚æ•°

The hyperparameters that we will track and optimize are:

æˆ‘ä»¬å°†è·Ÿè¸ªå’Œä¼˜åŒ–çš„è¶…å‚æ•°æ˜¯:

- `batch_size` : batch size of the LSTM and CNN : LSTM å’Œ CNN çš„æ‰¹é‡å¤§å°
- `cnn_lr`: the learningrate of the CNN : CNN çš„å­¦ä¹ é€Ÿåº¦
- `strides`: the number of strides in the CNN : ç¾å›½æœ‰çº¿ç”µè§†æ–°é—»ç½‘çš„è¿›æ­¥æ•°å­—
- `lrelu_alpha`: the alpha for the LeakyReLU in the GAN : äº’è”ç½‘ç»„ç»‡é‡Œçš„ LeakyReLU çš„ alpha
- `batchnorm_momentum`: momentum for the batch normalisation in the CNN ç¾å›½æœ‰çº¿ç”µè§†æ–°é—»ç½‘æ­£å¸¸åŒ–çš„åŠ¿å¤´
- `padding`: the padding in the CNN : ç¾å›½æœ‰çº¿ç”µè§†æ–°é—»ç½‘çš„å¡«å……
- `kernel_size':1`: kernel size in the CNN : å†…æ ¸å¤§å°åœ¨ CNN
- `dropout`: dropout in the LSTM : ä¼¦æ•¦ç§‘å­¦æŠ€æœ¯å­¦é™¢è¾å­¦
- `filters`: the initial number of filters : è¿‡æ»¤å™¨çš„åˆå§‹æ•°ç›®

We will train over 200 `epochs`.

æˆ‘ä»¬å°†è®­ç»ƒ200å¤šä¸ªæ—¶ä»£ã€‚

------

### 4. Hyperparameters optimisation

### å›¾4ã€‚ è¶…å‚æ•°ä¼˜åŒ–

After the GAN trains on the 200 epochs it will record the MAE (which is the error function in the LSTM, the GG) and pass it as a reward value to the Reinforcement learning that will decide whether to change the hyperparameters of keep training with the same set of hyperparameters. As described later, this approach is strictly for experimenting with RL.

å½“ GAN åœ¨200ä¸ªæ—¶ä»£è®­ç»ƒåï¼Œå®ƒå°†è®°å½• MAE (è¿™æ˜¯ LSTMï¼ŒGG ä¸­çš„é”™è¯¯å‡½æ•°) ï¼Œå¹¶å°†å…¶ä½œä¸ºå¥–åŠ±å€¼ä¼ é€’ç»™å¼ºåŒ–å­¦ä¹ ï¼Œåè€…å°†å†³å®šæ˜¯å¦æ”¹å˜ç›¸åŒè¶…å‚æ•°é›†ç»§ç»­è®­ç»ƒçš„è¶…å‚æ•°ã€‚ æ­£å¦‚åé¢æ‰€æè¿°çš„ï¼Œè¿™ç§æ–¹æ³•ä¸¥æ ¼åœ°ç”¨äº RL çš„å®éªŒã€‚

If the RL decides it will update the hyperparameters it will call Bayesian optimisation (discussed below) library that will give the next best expected set of the hyperparams

å¦‚æœ RL å†³å®šæ›´æ–°è¶…å‚æ•°ï¼Œå®ƒå°†ç§°ä¸ºè´å¶æ–¯ä¼˜åŒ–(ä¸‹é¢è®¨è®º)åº“ï¼Œå®ƒå°†æä¾›è¶…å‚æ•°çš„ä¸‹ä¸€ä¸ªæœ€ä½³é¢„æœŸé›†

### 4.1. Reinforcement learning for hyperparameters optimization

### 4.1. è¶…å‚æ•°ä¼˜åŒ–å¼ºåŒ–å­¦ä¹ 

Why do we use reinforcement learning in the hyperparameters optimization? Stock markets change all the time. Even if we manage to train our GAN and LSTM to create extremely accurate results, the results might only be valid for a certain period. Meaning, we need to constantly optimise the whole process. To optimize the process we can:

ä¸ºä»€ä¹ˆæˆ‘ä»¬è¦åœ¨è¶…å‚æ•°ä¼˜åŒ–ä¸­ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ï¼Ÿ è‚¡ç¥¨å¸‚åœºä¸€ç›´åœ¨å˜åŒ–ã€‚ å³ä½¿æˆ‘ä»¬è®¾æ³•è®­ç»ƒæˆ‘ä»¬çš„ GAN å’Œ LSTM æ¥åˆ›å»ºæå…¶ç²¾ç¡®çš„ç»“æœï¼Œç»“æœå¯èƒ½åªåœ¨ä¸€å®šæ—¶æœŸå†…æœ‰æ•ˆã€‚ ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬éœ€è¦ä¸æ–­ä¼˜åŒ–æ•´ä¸ªè¿‡ç¨‹ã€‚ ä¸ºäº†ä¼˜åŒ–è¿‡ç¨‹ï¼Œæˆ‘ä»¬å¯ä»¥:

- Add or remove features (e.g. add new stocks or currencies that might be correlated) æ·»åŠ æˆ–åˆ é™¤åŠŸèƒ½(ä¾‹å¦‚æ·»åŠ å¯èƒ½ç›¸å…³çš„æ–°è‚¡ç¥¨æˆ–è´§å¸)
- Improve our deep learning models. One of the most important ways to improve the models is through the hyper parameters (listed in Section 5). Once having found a certain set of hyperparameters we need to decide when to change them and when to use the already known set (exploration vs. exploitation). Also, stock market represents a continuous space that depends on millions parameters. æ”¹è¿›æˆ‘ä»¬çš„æ·±åº¦å­¦ä¹ æ¨¡å¼ã€‚ æ”¹è¿›æ¨¡å‹çš„æœ€é‡è¦çš„æ–¹æ³•ä¹‹ä¸€æ˜¯é€šè¿‡è¶…å‚æ•°(åœ¨ç¬¬5èŠ‚ä¸­åˆ—å‡º)ã€‚ ä¸€æ—¦æ‰¾åˆ°äº†ä¸€ç»„ç‰¹å®šçš„è¶…å‚æ•°ï¼Œæˆ‘ä»¬å°±éœ€è¦å†³å®šä»€ä¹ˆæ—¶å€™æ›´æ”¹å®ƒä»¬ï¼Œä»€ä¹ˆæ—¶å€™ä½¿ç”¨å·²çŸ¥çš„è¶…å‚æ•°é›†(æ¢ç´¢ä¸å¼€å‘)ã€‚ åŒæ—¶ï¼Œè‚¡ç¥¨å¸‚åœºæ˜¯ä¸€ä¸ªä¾èµ–äºæ•°ç™¾ä¸‡ä¸ªå‚æ•°çš„è¿ç»­ç©ºé—´

**Note**: The purpose of the whole reinforcement learning part of this notebook is more research oriented. We will explore different RL approaches using the GAN as an environment. There are many ways in which we can successfully perform hyperparameter optimization on our deep learning models without using RL. Butâ€¦ why not.

æ³¨æ„: è¿™æœ¬ç¬”è®°æœ¬çš„æ•´ä¸ªå¼ºåŒ–å­¦ä¹ éƒ¨åˆ†çš„ç›®çš„æ˜¯æ›´å¤šçš„ç ”ç©¶å¯¼å‘ã€‚ æˆ‘ä»¬å°†æ¢ç´¢ä½¿ç”¨æ°®åŒ–é•“ä½œä¸ºç¯å¢ƒçš„ä¸åŒ RL æ–¹æ³•ã€‚ æœ‰è®¸å¤šæ–¹æ³•å¯ä»¥æˆåŠŸåœ°å¯¹æˆ‘ä»¬çš„æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–ï¼Œè€Œæ— éœ€ä½¿ç”¨ RLã€‚ ä½†æ˜¯... ä¸ºä»€ä¹ˆä¸å‘¢ã€‚

**Note**: The next several sections assume you have some knowledge about RLâ€Šâ€”â€Šespecially policy methods and Q-learning.

æ³¨: æ¥ä¸‹æ¥çš„å‡ èŠ‚å‡è®¾ä½ æœ‰ä¸€äº› RL çš„çŸ¥è¯†ï¼Œç‰¹åˆ«æ˜¯æ”¿ç­–æ–¹æ³•å’Œ q å­¦ä¹ ã€‚

#### 4.1.1. Reinforcement Learning Theory

#### 4.1.1. å¼ºåŒ–å­¦ä¹ ç†è®º

Without explaining the basics of RL we will jump into the details of the specific approaches we implement here. We will use model-free RL algorithms for the obvious reason that we do not know the whole environment, hence there is no defined model for how the environment worksâ€Šâ€”â€Šif there was we wouldnâ€™t need to predict stock prices movementsâ€Šâ€”â€Šthey will just follow the model. We will use the two subdivisions of model-free RLâ€Šâ€”â€ŠPolicy optimization and Q-learning.

åœ¨æ²¡æœ‰è§£é‡Š RL çš„åŸºç¡€çŸ¥è¯†çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†è·³è½¬åˆ°æˆ‘ä»¬åœ¨è¿™é‡Œå®ç°çš„å…·ä½“æ–¹æ³•çš„ç»†èŠ‚ã€‚ æˆ‘ä»¬å°†ä½¿ç”¨æ— æ¨¡å‹ RL ç®—æ³•ï¼Œæ˜¾ç„¶æ˜¯å› ä¸ºæˆ‘ä»¬ä¸äº†è§£æ•´ä¸ªç¯å¢ƒï¼Œå› æ­¤æ²¡æœ‰å…³äºç¯å¢ƒå¦‚ä½•è¿ä½œçš„å®šä¹‰æ¨¡å‹ãƒ¼ãƒ¼å¦‚æœæœ‰çš„è¯ï¼Œæˆ‘ä»¬å°±ä¸éœ€è¦é¢„æµ‹è‚¡ç¥¨ä»·æ ¼çš„èµ°åŠ¿ãƒ¼ãƒ¼ä»–ä»¬åªä¼šéµå¾ªè¿™ä¸ªæ¨¡å‹ã€‚ æˆ‘ä»¬å°†ä½¿ç”¨æ— æ¨¡å‹ RL çš„ä¸¤ä¸ªå­é›†: ç­–ç•¥ä¼˜åŒ–å’Œ q å­¦ä¹ ã€‚

- **Q-learning**â€Šâ€”â€Šin Q-learning we learn the **value** of taking an action from a given state. **Q-value** is the expected return after taking the action. We will use **Rainbow** which is a combination of seven Q learning algorithms. Q å­¦ä¹ â€”â€”åœ¨ q å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ ä»ç»™å®šçŠ¶æ€é‡‡å–è¡ŒåŠ¨çš„ä»·å€¼ã€‚ Q å€¼æ˜¯é‡‡å–è¡ŒåŠ¨åçš„é¢„æœŸæ”¶ç›Šã€‚ æˆ‘ä»¬å°†ä½¿ç”¨å½©è™¹ï¼Œå®ƒæ˜¯ä¸ƒä¸ª q å­¦ä¹ ç®—æ³•çš„ç»„åˆ
- **Policy Optimization**â€Šâ€”â€Šin policy optimization we learn the action to take from a given state. (if we use methods like Actor/Critic) we also learn the value of being in a given state. We will use **Proximal Policy Optimization**. æ”¿ç­–ä¼˜åŒ–ãƒ¼ãƒ¼åœ¨æ”¿ç­–ä¼˜åŒ–ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ ä»ç»™å®šçŠ¶æ€é‡‡å–çš„è¡ŒåŠ¨ã€‚ (å¦‚æœæˆ‘ä»¬ä½¿ç”¨åƒ actor / critic è¿™æ ·çš„æ–¹æ³•)æˆ‘ä»¬è¿˜å¯ä»¥äº†è§£å¤„äºç»™å®šçŠ¶æ€çš„ä»·å€¼ã€‚ æˆ‘ä»¬å°†ä½¿ç”¨æœ€è¿‘ç­–ç•¥ä¼˜åŒ–

One crucial aspect of building a RL algorithm is accurately setting the reward. It has to capture all aspects of the environment and the agentâ€™s interaction with the environment. We define the reward, **R**, as:

å»ºç«‹ RL ç®—æ³•çš„ä¸€ä¸ªå…³é”®æ–¹é¢æ˜¯å‡†ç¡®åœ°è®¾ç½®å¥–åŠ±ã€‚ å®ƒå¿…é¡»æ•è·ç¯å¢ƒçš„æ‰€æœ‰æ–¹é¢ä»¥åŠä»£ç†ä¸ç¯å¢ƒçš„äº¤äº’ã€‚ æˆ‘ä»¬å°†å¥–åŠ±å®šä¹‰ä¸º r:

Reward=2âˆ—lossG+lossD+accuracyG,

å¥–åŠ±2æ¬¡ / æ¬¡ lossG + lossD + accuracyG,

where lossG, accuracyG, and lossD are the Generatorâ€™s loss and accuracy, and Discriminatorâ€™s loss, respectively. The environment is the **GAN** and the results of the **LSTM** training. The action the different agents can take is how to change the hyperparameters of the GANâ€™s D and G nets.

å…¶ä¸­ï¼Œlosgã€ accuracyG å’Œ lossD åˆ†åˆ«æ˜¯ç”Ÿæˆå™¨çš„æŸå¤±å’Œå‡†ç¡®æ€§ï¼Œä»¥åŠé‰´åˆ«å™¨çš„æŸå¤±ã€‚ ç¯å¢ƒæ˜¯æ°®åŒ–é•“å’Œ LSTM åŸ¹è®­çš„ç»“æœã€‚ ä¸åŒçš„ä»£ç†äººå¯ä»¥é‡‡å–çš„è¡ŒåŠ¨æ˜¯å¦‚ä½•æ”¹å˜æ°®åŒ–é•“çš„ d å’Œ g ç½‘çš„è¶…å‚æ•°ã€‚

#### 4.1.1.1. Rainbow

#### 4.1.1.1. å½©è™¹

**What is Rainbow?**

ä»€ä¹ˆæ˜¯å½©è™¹ï¼Ÿ

**Rainbow** ([link](https://arxiv.org/pdf/1710.02298.pdf)) is a Q learning based off-policy deep reinforcement learning algorithm combining seven algorithm together:

å½©è™¹(é“¾æ¥)æ˜¯ä¸€ç§åŸºäº q å­¦ä¹ çš„éç­–ç•¥æ·±åº¦å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œå®ƒå°†7ç§ç®—æ³•ç»“åˆåœ¨ä¸€èµ·:

- **DQN**. DQN is an extension of Q learning algorithm that uses a neural network to represent the Q value. Similar to supervised (deep) learning, in DQN we train a neural network and try to minimize a loss function. We train the network by randomly sampling transitions (state, action, reward). The layers can be not only fully connected ones, but also convolutional, for example. Dqn. Dqn æ˜¯ q å­¦ä¹ ç®—æ³•çš„ä¸€ä¸ªæ‰©å±•ï¼Œå®ƒä½¿ç”¨ç¥ç»ç½‘ç»œæ¥è¡¨ç¤º q å€¼ã€‚ ç±»ä¼¼äºæœ‰ç›‘ç£(æ·±åº¦)å­¦ä¹ ï¼Œåœ¨ DQN æˆ‘ä»¬è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œå¹¶è¯•å›¾å‡å°‘æŸå¤±å‡½æ•°ã€‚ æˆ‘ä»¬é€šè¿‡éšæœºé‡‡æ ·è½¬æ¢(çŠ¶æ€ã€åŠ¨ä½œã€å¥–åŠ±)æ¥è®­ç»ƒç½‘ç»œã€‚ ä¾‹å¦‚ï¼Œè¿™äº›å±‚ä¸ä»…å¯ä»¥æ˜¯å®Œå…¨è¿æ¥çš„ï¼Œè¿˜å¯ä»¥æ˜¯å·ç§¯çš„
- **Double Q Learning**. Double QL handles a big problem in Q learning, namely the overestimation bias. åŒ q å­¦ä¹ ã€‚ åŒ QL å¤„ç† q å­¦ä¹ ä¸­çš„ä¸€ä¸ªå¤§é—®é¢˜ï¼Œå³é«˜ä¼°åå·®
- **Prioritized replay**. In the vanilla DQN, all transitions are stored in a replay buffer and it uniformly samples this buffer. However, not all transitions are equally beneficial during the learning phase (which also makes learning inefficient as more episodes are required). Prioritized experience replay doesnâ€™t sample uniformly, rather it uses a distribution that gives higher probability to samples that have had higher Q loss in previous iterations. ä¼˜å…ˆé‡æ”¾ã€‚ åœ¨æ™®é€š DQN ä¸­ï¼Œæ‰€æœ‰è½¬æ¢éƒ½å­˜å‚¨åœ¨é‡æ’­ç¼“å†²åŒºä¸­ï¼Œå®ƒç»Ÿä¸€é‡‡æ ·è¿™ä¸ªç¼“å†²åŒºã€‚ ç„¶è€Œï¼Œå¹¶ä¸æ˜¯æ‰€æœ‰çš„è½¬æ¢åœ¨å­¦ä¹ é˜¶æ®µéƒ½åŒæ ·æœ‰ç›Š(è¿™ä¹Ÿä½¿å¾—å­¦ä¹ æ•ˆç‡ä½ä¸‹ï¼Œå› ä¸ºéœ€è¦æ›´å¤šçš„ç‰‡æ®µ)ã€‚ ä¼˜å…ˆçº§ç»éªŒé‡æ”¾ä¸æ˜¯ç»Ÿä¸€çš„æ ·æœ¬ï¼Œè€Œæ˜¯ä½¿ç”¨ä¸€ä¸ªåˆ†å¸ƒï¼Œç»™äºˆæ›´é«˜çš„æ¦‚ç‡æ ·æœ¬æœ‰æ›´é«˜çš„ q æŸå¤±åœ¨å‰ä¸€æ¬¡è¿­ä»£
- **Dueling networks.** Dueling networks change the Q learning architecture a little by using two separate streams (i.e. having two different mini-neural networks). One stream is for the value and one for the *advantage*. Both of them share a convolutional encoder. The tricky part is the merging of the streamsâ€Šâ€”â€Šit uses a special aggregator (*Wang et al. 2016*). å†³æ–—ç½‘ç»œã€‚ å†³æ–—ç½‘ç»œé€šè¿‡ä½¿ç”¨ä¸¤ä¸ªç‹¬ç«‹çš„æµ(å³æ‹¥æœ‰ä¸¤ä¸ªä¸åŒçš„å¾®å‹ç¥ç»ç½‘ç»œ)ç¨å¾®æ”¹å˜äº† q å­¦ä¹ ç»“æ„ã€‚ ä¸€ä¸ªæµæ˜¯ä¸ºäº†ä»·å€¼ï¼Œä¸€ä¸ªæµæ˜¯ä¸ºäº†ä¼˜åŠ¿ã€‚ å®ƒä»¬éƒ½å…±äº«ä¸€ä¸ªå·ç§¯ç¼–ç å™¨ã€‚ æ£˜æ‰‹çš„éƒ¨åˆ†æ˜¯æµçš„åˆå¹¶ãƒ¼å®ƒä½¿ç”¨äº†ä¸€ä¸ªç‰¹æ®Šçš„èšåˆå™¨(Wang ç­‰äººï¼Œ2016)

*(Advantage*, formula is A(s,a)=Q(s,a)âˆ’V(s), generally speaking is a comparison of how good an action is compared to the average action for a specific state. Advantages are sometimes used when a â€˜wrongâ€™ action cannot be penalized with negative reward. So *advantage* will try to further reward good actions from the average actions.)

(ä¼˜ç‚¹ï¼Œå…¬å¼æ˜¯ a (sï¼Œa) q (sï¼Œa)-v (s) ï¼Œä¸€èˆ¬æ¥è¯´æ˜¯ä¸€ä¸ªåŠ¨ä½œä¸ä¸€ä¸ªç‰¹å®šçŠ¶æ€ä¸‹çš„å¹³å‡åŠ¨ä½œçš„æ¯”è¾ƒã€‚ å½“ä¸€ä¸ª"é”™è¯¯"çš„è¡Œä¸ºä¸èƒ½ç”¨è´Ÿé¢çš„å¥–åŠ±æ¥æƒ©ç½šæ—¶ï¼Œä¼˜åŠ¿æœ‰æ—¶ä¼šè¢«ä½¿ç”¨ã€‚ æ‰€ä»¥ä¼˜åŠ¿ä¼šè¿›ä¸€æ­¥å¥–åŠ±å¹³å‡è¡Œä¸ºçš„å¥½è¡Œä¸ºã€‚)

- **Multi-step learning.** The big difference behind Multi-step learning is that it calculates the Q-values using N-step returns (not only the return from the next step), which naturally should be more accurate. å¤šæ­¥å­¦ä¹ ã€‚ å¤šæ­¥å­¦ä¹ èƒŒåæœ€å¤§çš„åŒºåˆ«æ˜¯å®ƒä½¿ç”¨ n æ­¥è¿”å›å€¼(ä¸ä»…ä»…æ˜¯ä¸‹ä¸€æ­¥è¿”å›å€¼)æ¥è®¡ç®— q å€¼ï¼Œè¿™è‡ªç„¶åº”è¯¥æ›´å‡†ç¡®
- **Distributional RL**. Q learning uses average estimated Q-value as target value. However, in many cases the Q-values might not be the same in different situations. Distributional RL can directly learn (or approximate) the distribution of Q-values rather than averaging them. Again, the math is much more complicated than that, but for us the benefit is more accurate sampling of the Q-values. åˆ†å¸ƒå¼ç”µè·¯ã€‚ Q å­¦ä¹ é‡‡ç”¨å¹³å‡ä¼°è®¡ q å€¼ä½œä¸ºç›®æ ‡å€¼ã€‚ ç„¶è€Œï¼Œåœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œq å€¼åœ¨ä¸åŒæƒ…å†µä¸‹å¯èƒ½æ˜¯ä¸ä¸€æ ·çš„ã€‚ åˆ†å¸ƒå¼ RL å¯ä»¥ç›´æ¥å­¦ä¹ (æˆ–è¿‘ä¼¼) q å€¼çš„åˆ†å¸ƒï¼Œè€Œä¸æ˜¯æ±‚å¹³å‡å€¼ã€‚ åŒæ ·ï¼Œæ•°å­¦è¦æ¯”è¿™å¤æ‚å¾—å¤šï¼Œä½†å¯¹æˆ‘ä»¬æ¥è¯´ï¼Œå¥½å¤„æ˜¯ q å€¼çš„é‡‡æ ·æ›´å‡†ç¡®
- **Noisy Nets**. Basic DQN implements a simple ğœ€-greedy mechanism to do exploration. This approach to exploration inefficient at times. The way Noisy Nets approach this issue is by adding a noisy linear layer. Over time, the network will learn how to ignore the noise (added as a noisy stream). But this learning comes at different rates in different parts of the space, allowing for state exploration. åµé—¹çš„èšŠå¸ã€‚ åŸºæœ¬ DQN å®ç°äº†ä¸€ä¸ªç®€å•çš„è´ªå©ªæœºåˆ¶æ¥è¿›è¡Œæ¢ç´¢ã€‚ è¿™ç§å‹˜æ¢æ–¹æ³•æœ‰æ—¶æ•ˆç‡ä¸é«˜ã€‚ å™ªå£°ç½‘ç»œå¤„ç†è¿™ä¸ªé—®é¢˜çš„æ–¹æ³•æ˜¯é€šè¿‡æ·»åŠ ä¸€ä¸ªå™ªå£°çº¿æ€§å±‚ã€‚ éšç€æ—¶é—´çš„æ¨ç§»ï¼Œç½‘ç»œå°†å­¦ä¼šå¦‚ä½•å¿½ç•¥å™ªéŸ³(ä½œä¸ºä¸€ä¸ªå˜ˆæ‚çš„æµ)ã€‚ ä½†æ˜¯è¿™ç§å­¦ä¹ åœ¨ç©ºé—´çš„ä¸åŒéƒ¨åˆ†ä»¥ä¸åŒçš„é€Ÿåº¦è¿›è¡Œï¼Œå…è®¸çŠ¶æ€æ¢ç´¢

**Note: Stay tunedâ€Šâ€”â€ŠI will upload a MXNet/Gluon implementation on Rainbow to Github in early February 2019.**

æ³¨æ„: è¯·ç»§ç»­å…³æ³¨-æˆ‘å°†åœ¨2019å¹´2æœˆåˆå‘ Github ä¸Šä¼ ä¸€ä¸ªå…³äº Rainbow çš„ mxnet / gluon å®ç°ã€‚

#### 4.1.1.2. PPO

#### 4.1.1.2. å¤šé…šæ°§åŒ–é…¶

**Proximal Policy Optimization** ([PPO](https://arxiv.org/pdf/1707.06347.pdf)) is a policy optimization model-free type of reinforcement learning. It is much simpler to implement that other algorithms and gives very good results.

æœ€è¿‘ç­–ç•¥ä¼˜åŒ–æ˜¯ä¸€ç§æ— æ¨¡å‹çš„ç­–ç•¥ä¼˜åŒ–å¼ºåŒ–å­¦ä¹ ã€‚ å®ƒæ¯”å…¶ä»–ç®—æ³•çš„å®ç°ç®€å•å¾—å¤šï¼Œå¹¶ä¸”å¾—åˆ°äº†å¾ˆå¥½çš„ç»“æœã€‚

Why do we use PPO? One of the advantages of PPO is that it directly learns the policy, rather than indirectly via the values (the way Q Learning uses Q-values to learn the policy). It can work well in continuous action spaces, which is suitable in our use case and can learn (through mean and standard deviation) the distribution probabilities (if softmax is added as an output).

æˆ‘ä»¬ä¸ºä»€ä¹ˆè¦ä½¿ç”¨ PPOï¼Ÿ Ppo çš„ä¼˜ç‚¹ä¹‹ä¸€æ˜¯å®ƒå¯ä»¥ç›´æ¥å­¦ä¹ ç­–ç•¥ï¼Œè€Œä¸æ˜¯é€šè¿‡å€¼é—´æ¥å­¦ä¹ (q å­¦ä¹ ä½¿ç”¨ q å€¼å­¦ä¹ ç­–ç•¥çš„æ–¹å¼)ã€‚ å®ƒå¯ä»¥å¾ˆå¥½åœ°å·¥ä½œåœ¨è¿ç»­çš„åŠ¨ä½œç©ºé—´ï¼Œè¿™æ˜¯é€‚åˆæˆ‘ä»¬çš„ç”¨ä¾‹å’Œå¯ä»¥å­¦ä¹ (é€šè¿‡å‡å€¼å’Œæ ‡å‡†å·®)çš„åˆ†å¸ƒæ¦‚ç‡(å¦‚æœè½¯æœ€å¤§ä½œä¸ºä¸€ä¸ªè¾“å‡º)ã€‚

The problem of policy gradient methods is that they are extremely sensitive to the step size choiceâ€Šâ€”â€Šif it is small the progress takes too long (most probably mainly due to the need of a second-order derivatives matrix); if it is large, there is a lot noise which significantly reduces the performance. Input data is nonstationary due to the changes in the policy (also the distributions of the reward and observations change). As compared to supervised learning, poorly chosen step can be much more devastating as it affects the whole distribution of next visits. PPO can solve these issues. What is more, compared to some other approaches, PPO:

ç­–ç•¥æ¢¯åº¦æ–¹æ³•çš„é—®é¢˜åœ¨äºï¼Œå®ƒä»¬å¯¹æ­¥é•¿çš„é€‰æ‹©æä¸ºæ•æ„Ÿãƒ¼ãƒ¼å¦‚æœæ­¥é•¿è¾ƒå°ï¼Œåˆ™è¿›å±•æ—¶é—´è¿‡é•¿(å¾ˆå¯èƒ½ä¸»è¦æ˜¯ç”±äºéœ€è¦ä¸€ä¸ªäºŒé˜¶å¯¼æ•°çŸ©é˜µ) ; å¦‚æœæ­¥é•¿è¾ƒå¤§ï¼Œåˆ™å­˜åœ¨å¤§é‡å™ªå£°ï¼Œä»è€Œæ˜¾è‘—é™ä½äº†æ€§èƒ½ã€‚ è¾“å…¥æ•°æ®æ˜¯éå¹³ç¨³çš„ï¼Œè¿™æ˜¯ç”±äºç­–ç•¥çš„å˜åŒ–(ä¹Ÿæ˜¯å¥–åŠ±å’Œè§‚å¯Ÿå€¼åˆ†å¸ƒçš„å˜åŒ–)ã€‚ ä¸ç›‘ç£å¼å­¦ä¹ ç›¸æ¯”ï¼Œé€‰æ‹©ä¸å½“çš„æ­¥éª¤å¯èƒ½æ›´å…·ç ´åæ€§ï¼Œå› ä¸ºå®ƒå½±å“åˆ°ä¸‹ä¸€æ¬¡è®¿é—®çš„æ•´ä¸ªåˆ†å¸ƒã€‚ Ppo å¯ä»¥è§£å†³è¿™äº›é—®é¢˜ã€‚ æ›´é‡è¦çš„æ˜¯ï¼Œä¸å…¶ä»–ä¸€äº›æ–¹æ³•ç›¸æ¯”ï¼ŒPPO:

- is much less complicated, for example compared to **ACER**, which requires additional code for keeping the off-policy correlations and also a replay buffer, or **TRPO** which has a constraint imposed on the surrogate objective function (the KL divergence between the old and the new policy). This constraint is used to control the policy of changing too muchâ€Šâ€”â€Šwhich might create instability. PPO reduces the computation (created by the constraint) by utilizing a *clipped (between [1- ğœ–, 1+ğœ–]) surrogate objective function* and modifying the objective function with a penalty for having too big of an update. ä¾‹å¦‚ï¼Œä¸ ACER ç›¸æ¯”ï¼Œå®ƒéœ€è¦é¢å¤–çš„ä»£ç æ¥ä¿æŒéç­–ç•¥å…³è”æ€§ï¼Œè¿˜éœ€è¦ä¸€ä¸ªé‡æ”¾ç¼“å†²åŒºï¼Œæˆ–è€… TRPO å¯¹æ›¿ä»£ç›®æ ‡å‡½æ•°(æ–°æ—§ç­–ç•¥ä¹‹é—´çš„ KL å·®å¼‚)æ–½åŠ çº¦æŸã€‚ è¿™ç§çº¦æŸè¢«ç”¨æ¥æ§åˆ¶è¿‡åº¦æ”¹å˜çš„æ”¿ç­–ãƒ¼ãƒ¼è¿™å¯èƒ½ä¼šé€ æˆä¸ç¨³å®šã€‚ Ppo é€šè¿‡åˆ©ç”¨[1-ï¼Œ1 + ]ä»£ç†ç›®æ ‡å‡½æ•°çš„æˆªæ–­å’Œä¿®æ”¹ç›®æ ‡å‡½æ•°æ¥å‡å°‘è®¡ç®—é‡(ç”±çº¦æŸåˆ›å»º) ï¼Œä¿®æ”¹åçš„ç›®æ ‡å‡½æ•°ä¼šå› æ›´æ–°è¿‡å¤§è€Œå—åˆ°æƒ©ç½š
- gives compatibility with algos that share parameters between value and policy function or auxiliary losses, as compared to TRPO (although PPO also have the gain of trust region PO). ä¸ TRPO ç›¸æ¯”ï¼Œç»™å‡ºäº†ä¸å…±äº«ä»·å€¼å’Œæ”¿ç­–åŠŸèƒ½æˆ–è¾…åŠ©æŸå¤±ä¹‹é—´çš„å‚æ•°çš„ algos çš„å…¼å®¹æ€§(è™½ç„¶ PPO ä¹Ÿæœ‰ä¿¡èµ–åŸŸ PO çš„å¢ç›Š)

**Note**: For the purpose of our exercise we wonâ€™t go too much into the research and optimization of RL approaches, PPO and the others included. Rather, we will take what is available and try to fit into our process for hyperparameter optimization for our **GAN**, **LSTM**, and **CNN** models. The code we will reuse and customize is created by OpenAI and is available [here](https://github.com/openai/baselines).

æ³¨æ„: åœ¨æˆ‘ä»¬çš„ç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬ä¸ä¼šå¯¹åŒ…æ‹¬ PPO åœ¨å†…çš„ RL æ–¹æ³•è¿›è¡Œè¿‡å¤šçš„ç ”ç©¶å’Œä¼˜åŒ–ã€‚ ç›¸åï¼Œæˆ‘ä»¬å°†åˆ©ç”¨ç°æœ‰èµ„æºï¼Œå¹¶å°è¯•é€‚åº”æˆ‘ä»¬çš„ GANã€ LSTM å’Œ CNN æ¨¡å‹çš„è¶…å‚æ•°ä¼˜åŒ–è¿‡ç¨‹ã€‚ æˆ‘ä»¬å°†é‡ç”¨å’Œå®šåˆ¶çš„ä»£ç æ˜¯ç”± OpenAI åˆ›å»ºçš„ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°ã€‚

#### 4.1.2. Further work on Reinforcement learning

#### 4.1.2. å…³äºå¼ºåŒ–å­¦ä¹ çš„è¿›ä¸€æ­¥å·¥ä½œ

Some ideas for further exploring reinforcement learning:

å…³äºè¿›ä¸€æ­¥æ¢ç´¢å¼ºåŒ–å­¦ä¹ çš„ä¸€äº›æƒ³æ³•:

- One of the first things I will introduce next is using **Augmented Random Search** ([link](https://arxiv.org/pdf/1803.07055.pdf)) as an alternative algorithm. The authors of the algorithm (out of UC, Berkeley) have managed to achieve similar rewards results as other state of the art approaches, such as PPO, but on average 15 times faster. æˆ‘æ¥ä¸‹æ¥è¦ä»‹ç»çš„ç¬¬ä¸€ä»¶äº‹æ˜¯ä½¿ç”¨å¢å¼ºéšæœºæœç´¢(é“¾æ¥)ä½œä¸ºæ›¿ä»£ç®—æ³•ã€‚ è¯¥ç®—æ³•çš„ä½œè€…(æ¥è‡ªåŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡)å·²ç»è®¾æ³•å®ç°äº†ä¸å…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•(å¦‚ PPO)ç±»ä¼¼çš„å¥–åŠ±ç»“æœï¼Œä½†å¹³å‡è¦å¿«15å€
- Choosing a reward function is very important. I stated the currently used reward function above, but I will try to play with different functions as an alternative. é€‰æ‹©å¥–åŠ±å‡½æ•°æ˜¯éå¸¸é‡è¦çš„ã€‚ æˆ‘åœ¨ä¸Šé¢æåˆ°äº†å½“å‰ä½¿ç”¨çš„å¥–åŠ±åŠŸèƒ½ï¼Œä½†æ˜¯æˆ‘ä¼šå°è¯•ä½¿ç”¨ä¸åŒçš„åŠŸèƒ½ä½œä¸ºæ›¿ä»£
- Using **Curiosity** as an exploration policy. ä½¿ç”¨å¥½å¥‡å·ä½œä¸ºä¸€ç§æ¢ç´¢ç­–ç•¥
- Create **multi-agent** architecture as proposed by Berkeleyâ€™s AI Research team (BAIR)â€Šâ€”â€Š[link](https://bair.berkeley.edu/blog/2018/12/12/rllib/). æŒ‰ç…§ä¼¯å…‹åˆ©äººå·¥æ™ºèƒ½ç ”ç©¶å›¢é˜Ÿ(BAIR)ãƒ¼ link çš„æè®®ï¼Œåˆ›å»ºå¤š agent ä½“ç³»ç»“æ„

### 4.2. Bayesian optimization

### 4.2. è´å¶æ–¯ä¼˜åŒ–

Instead of the grid search, that can take a lot of time to find the best combination of hyperparameters, we will use **Bayesian optimization**. The library that weâ€™ll use is already implementedâ€Šâ€”â€Š[link](https://github.com/fmfn/BayesianOptimization).

æˆ‘ä»¬å°†ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–ï¼Œè€Œä¸æ˜¯ç½‘æ ¼æœç´¢ï¼Œè¿™éœ€è¦èŠ±è´¹å¤§é‡çš„æ—¶é—´æ¥å¯»æ‰¾è¶…å‚æ•°çš„æœ€ä½³ç»„åˆã€‚ æˆ‘ä»¬å°†è¦ä½¿ç”¨çš„åº“å·²ç»å®ç°äº†ãƒ¼ linkã€‚

#### 4.2.1. Gaussian process

#### 4.2.1. é«˜æ–¯è¿‡ç¨‹



![img](https://cdn-images-1.medium.com/max/1600/1*JCO5-noInHvLHeZaqU5Saw.png)

Gaussian process for Bayesian hyperparameter optimisation è´å¶æ–¯è¶…å‚æ•°ä¼˜åŒ–çš„é«˜æ–¯è¿‡ç¨‹

------

### 5. The Result

### 5. ç»“æœ

Finally we will compare the output of the LSTM when the unseen (test) data is used as an input after different phases of the process.

æœ€åï¼Œæˆ‘ä»¬å°†æ¯”è¾ƒ LSTM çš„è¾“å‡ºæ—¶ï¼Œçœ‹ä¸è§çš„(æµ‹è¯•)æ•°æ®ç”¨ä½œè¾“å…¥åï¼Œä¸åŒé˜¶æ®µçš„è¿‡ç¨‹ã€‚

1. Plot after the first epoch. ç¬¬ä¸€è½®epochåç”»å›¾

```
from utils import plot_prediction
plot_prediction('Predicted and Real price - after first epoch.')
```



![img](https://cdn-images-1.medium.com/max/1600/1*uKkExoSy4o6zo3dwfPoPwg.png)

\2. Plot after 50 epochs.

50è½®epochåç”»å›¾

```
plot_prediction('Predicted and Real price - after first 50 epochs.')
```



![img](https://cdn-images-1.medium.com/max/1600/1*cqfAntAtxKMw-eo8s1b3MA.png)

```
plot_prediction('Predicted and Real price - after first 200 epochs.')
```



![img](https://cdn-images-1.medium.com/max/1600/1*-VuHm3t1eGQMziCU7xjcVA.png)

The RL run for ten episodes (we define an eposide to be one full GAN training on the 200 epochs.)

åœ¨ RL è¿è¡Œ10é›†(æˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªå®Œæ•´çš„æ°®åŒ–ç‰©è®­ç»ƒçš„200ä¸ªæ—¶ä»£çš„ä¸€ä¸ªæ—¶ä»£ã€‚)

```
plot_prediction('Final result.')
```



![img](https://cdn-images-1.medium.com/max/1600/1*FeWF_24neEhH9Gpra1DGmA.png)

#### As a next step, I will try to take everything separately and provide some analysis on what worked and why. Why did we receive these results and is it just by coinscidence? So stay tuned.

#### ä½œä¸ºä¸‹ä¸€æ­¥ï¼Œæˆ‘å°†å°è¯•å°†æ‰€æœ‰äº‹æƒ…åˆ†å¼€ï¼Œå¹¶æä¾›ä¸€äº›å…³äºä»€ä¹ˆèµ·ä½œç”¨ä»¥åŠä¸ºä»€ä¹ˆèµ·ä½œç”¨çš„åˆ†æã€‚ ä¸ºä»€ä¹ˆæˆ‘ä»¬ä¼šå¾—åˆ°è¿™æ ·çš„ç»“æœï¼Œä»…ä»…æ˜¯å·§åˆå—ï¼Ÿ æ‰€ä»¥è¯·ç»§ç»­å…³æ³¨

------


### 6 å±•æœ›

- Next, I will try to create a RL environment for testing trading algorithms that decide when and how to trade. The output from the GAN will be one of the parameters in the environment. æ¥ä¸‹æ¥ï¼Œæˆ‘å°†å°è¯•åˆ›å»ºä¸€ä¸ª RL ç¯å¢ƒï¼Œç”¨äºæµ‹è¯•å†³å®šä½•æ—¶ä»¥åŠå¦‚ä½•è¿›è¡Œäº¤æ˜“çš„äº¤æ˜“ç®—æ³•ã€‚ æ°®åŒ–é•“çš„è¾“å‡ºå°†æ˜¯ç¯å¢ƒä¸­çš„ä¸€ä¸ªå‚æ•°

------

### 7 å…è´£å£°æ˜

**This notebook is entirely informative. None of the content presented in this notebook constitutes a recommendation that any particular security, portfolio of securities, transaction or investment strategy is suitable for any specific person. Futures, stocks and options trading involves substantial risk of loss and is not suitable for every investor. The valuation of futures, stocks and options may fluctuate, and, as a result, clients may lose more than their original investment.**

è¿™æœ¬ç¬”è®°æœ¬ä¿¡æ¯é‡å¾ˆå¤§ã€‚ æœ¬ç¬”è®°æœ¬ä¸­çš„ä»»ä½•å†…å®¹éƒ½ä¸æ„æˆå»ºè®®ï¼Œå³ä»»ä½•ç‰¹å®šè¯åˆ¸ã€è¯åˆ¸ç»„åˆã€äº¤æ˜“æˆ–æŠ•èµ„ç­–ç•¥é€‚åˆäºä»»ä½•ç‰¹å®šçš„äººã€‚ æœŸè´§ã€è‚¡ç¥¨å’ŒæœŸæƒäº¤æ˜“æ¶‰åŠå·¨å¤§çš„äºæŸé£é™©ï¼Œå¹¶ä¸é€‚åˆæ¯ä¸ªæŠ•èµ„è€…ã€‚ æœŸè´§ã€è‚¡ç¥¨å’ŒæœŸæƒçš„ä¼°å€¼å¯èƒ½ä¼šæ³¢åŠ¨ï¼Œå› æ­¤ï¼Œå®¢æˆ·æŸå¤±çš„å¯èƒ½ä¼šè¶…è¿‡ä»–ä»¬æœ€åˆçš„æŠ•èµ„ã€‚

**All trading strategies are used at your own risk.**

æ‰€æœ‰çš„äº¤æ˜“ç­–ç•¥éƒ½æ˜¯ä½ è‡ªå·±æ‰¿æ‹…é£é™©ã€‚

åœ¨é€‰æ‹©æ•°æ®ç‰¹å¾ã€é€‰æ‹©ç®—æ³•ã€è°ƒä¼˜ç®—æ³•ç­‰æ–¹é¢ï¼Œè¿˜æœ‰è®¸å¤šç»†èŠ‚éœ€è¦æ¢ç´¢ã€‚ è¿™ä¸ªç‰ˆæœ¬çš„ç¬”è®°æœ¬èŠ±äº†æˆ‘ä¸¤ä¸ªæ˜ŸæœŸçš„æ—¶é—´æ‰å®Œæˆã€‚ æˆ‘ç›¸ä¿¡è¿™ä¸ªè¿‡ç¨‹ä¸­è¿˜æœ‰è®¸å¤šæœªç»ä¿®é¥°çš„éƒ¨åˆ†ã€‚ å› æ­¤ï¼Œä»»ä½•æ„è§å’Œå»ºè®®ãƒ¼è¯·åˆ†äº«ã€‚ æˆ‘å¾ˆä¹æ„åœ¨å½“å‰çš„è¿‡ç¨‹ä¸­æ·»åŠ å’Œæµ‹è¯•ä»»ä½•æƒ³æ³•ã€‚

