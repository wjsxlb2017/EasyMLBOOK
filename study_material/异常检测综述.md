[TOC]



# [shubhomoydas](https://github.com/shubhomoydas)



 一系列的异常检测方法(iid/ 点-based，图和时间序列) ，包括主动学习异常检测 / 发现，贝叶斯规则挖掘，描述多样性 / 解释 / 可解释性。 结合标记反馈和集成检测器和树模型的检测器进行分析。

这个仓库包括，除了其他例子，我自己在主动学习和数据漂移检测方面的原创研究:

- [AAD: Active Anomaly Discovery 主动异常发现](https://github.com/shubhomoydas/ad_examples#active-anomaly-discovery-aad) (Das, Wong, et al. 2016)
- [GLAD: GLocalized Anomaly Detection ](https://github.com/shubhomoydas/ad_examples#glocalized-anomaly-detection) (Das and Doppa 2018) )
- [Data drift detection 数据漂移检测](https://github.com/shubhomoydas/ad_examples/blob/master/DriftDetection.md#data-drift-detection) Das, Islam, et al. 2019) )

# 异常检测的例子


这是一个在学术文献和实践中流行的检测方法的异常检测的例子集合

- 数据服从iid
  
  - [Standard unsupervised anomaly detectors 标准无监督异常检测器](https://github.com/shubhomoydas/ad_examples/blob/master/ad_examples/ad/ad_outlier.py) (Isolation Forest, LODA, One-class SVM, LOF) (隔离森林，LODA，单类 SVM，LOF)
  - [Clustering and density-based 基于聚类和密度的](https://github.com/shubhomoydas/ad_examples/blob/master/ad_examples/ad/gmm_outlier.py)
  - [Density estimation based 基于密度估计](https://github.com/shubhomoydas/ad_examples/blob/master/ad_examples/ad/kde_outlier.py)
  - [PCA Reconstruction-based 基于主成分分析的重构算法](https://github.com/shubhomoydas/ad_examples/blob/master/ad_examples/ad/pca_reconstruct.py)
  - [Autoencoder Reconstruction-based 基于自动编码器重构的](https://github.com/shubhomoydas/ad_examples/blob/master/ad_examples/dnn/autoencoder.py)
  - [Classifier and pseudo-anomaly based 基于分类器和伪异常的方法](https://github.com/shubhomoydas/ad_examples/blob/master/ad_examples/ad/pseudo_anom_outlier.py)
  - [Ensemble/Projection-based 集成/ 基于投影的](https://github.com/shubhomoydas/ad_examples/blob/master/ad_examples/loda/loda.py)
  - [A demonstration of outlier influence 异常值影响的证明](https://github.com/shubhomoydas/ad_examples/blob/master/ad_examples/ad/outlier_effect.py)
  - [Spectral-based 基于光谱的](https://github.com/shubhomoydas/ad_examples/blob/master/SpectralMethods.md) [code 代码](https://github.com/shubhomoydas/ad_examples/blob/master/ad_examples/ad/spectral_outlier.py)

- 时间序列 
  - 基于预测的
    - [探索分析](https://github.com/shubhomoydas/ad_examples/blob/master/TimeSeries.md#exploratory-analysis)
    - [ARIMA](https://github.com/shubhomoydas/ad_examples/blob/master/TimeSeries.md#arima-forecasting)
    - [Regression](https://github.com/shubhomoydas/ad_examples/blob/master/TimeSeries.md#regression-forecasting) (SVM, Random Forest, Neural Network)
    - [Recurrent Neural Networks](https://github.com/shubhomoydas/ad_examples/blob/master/TimeSeries.md#timeseries-modeling-with-rnnslstms) (RNN/LSTM)
  - iid
    - [Windows/Shingle based](https://github.com/shubhomoydas/ad_examples/blob/master/TimeSeries.md#timeseries-outliers-with-shingles) (Isolation Forest, One-class SVM, LOF, Autoencoder)

  基于预测的探索性分析，ARIMA， 回归(SVM，Random Forest，Neural Network)，递归神经网络(rnn / lstm) ，即基于 windows / shingle 的(孤立森林，单类 SVM，LOF，自动编码器)

- human-in-the-loop 
  - 主动的异常发现 
    - 批量检测
    - 实时检测
    
     包括图和插图(见下文部分)

    - [High-level 的总结](https://github.com/shubhomoydas/ad_examples#active-anomaly-discovery-aad)

    -  [运行 AAD 的一般说明](https://github.com/shubhomoydas/ad_examples#running-aad) 直接进入: 

    - **描述和可解释性** [用基于树的集成模型生成异常描述](https://github.com/shubhomoydas/ad_examples#generating-compact-descriptions-with-aad) 

    - [ AAD 的贝叶斯规则集](https://github.com/shubhomoydas/ad_examples#bayesian-rulesets-with-aad)

    - **查询策略:** [使用描述使查询实例多样化](https://github.com/shubhomoydas/ad_examples#query-diversity-with-compact-descriptions) 和 [评估](https://github.com/shubhomoydas/ad_examples#does-query-diversity-with-compact-descriptions-help) : 

    - GLAD: GLocalized Anomaly Detection 
      - [方法和架构](https://github.com/shubhomoydas/ad_examples#glocalized-anomaly-detection)

    - **另外:** [当我们有很多标记数据(包括异常数据和正名数据)时，我们是否应该使用分类器而不是异常检测器](https://github.com/shubhomoydas/ad_examples#anomaly-detector-vs-classifier) 旁白: ？

    - [ 不同树型检测器的若干性质](https://github.com/shubhomoydas/ad_examples/blob/master/TreeProperties.md)

    - [利用预计算的集成得分运行 AAD](https://github.com/shubhomoydas/ad_examples#running-aad-with-precomputed-anomaly-scores)

    - [Api 用法: 如何在您自己的应用程序中使用 AAD](https://github.com/shubhomoydas/ad_examples#how-to-employ-aad-in-your-own-application) 

    - [Aad 与相关工作的比较](https://github.com/shubhomoydas/ad_examples/blob/master/CompareRelated.md#comparison-with-related-work)

    - [数据漂移检测和 基于流数据的模型更新](https://github.com/shubhomoydas/ad_examples/blob/master/DriftDetection.md#data-drift-detection)

    - **Aside:** [将漂移检测应用于基于树的分类器](https://github.com/shubhomoydas/ad_examples/blob/master/DriftDetection.md#applying-drift-detection-to-tree-based-classifiers) 

    - [一点理论上的intuition](https://github.com/shubhomoydas/ad_examples/blob/master/Motivations.md#motivation-for-ensemble-based-active-anomaly-discovery)

- 基于生成对抗性网络的异常检测

  - [AnoGAN ](https://github.com/shubhomoydas/ad_examples#anogan)

- 利用对抗行为和图卷积网络进行异常注入

  - [Ensembles](https://github.com/shubhomoydas/ad_examples#robustness-with-ensembles)
  - [对抗训练](https://github.com/shubhomoydas/ad_examples#robustness-with-adversarial-training)

- [Reducing activity sequences to i.i.d ](https://github.com/shubhomoydas/ad_examples/blob/master/ActivitySequences.md#activity-modeling) -- This illustrates an approach that is becoming increasingly popular as a starting-point for anomaly detection on activity sequences and transfer learning. 


支持多个数据集(合成的 / 真实的)。 更改代码以使用所需的数据集或算法。

Auc 是用来报告异常检测业绩的最常用的指标。 点击这里查看标准数据集的[完整示例](https://github.com/shubhomoydas/ad_examples/blob/master/ad_examples/dnn/autoencoder.py)




## Active Anomaly Discovery (AAD) 


这个代码库取代了旧的'pyaad'项目( https://github.com/shubhomoydas/pyaad 项目)。 它实现了一种主动探索异常的算法(AAD)。

### 动机和直觉

我们探索具有集成功能的活动异常检测的动机在 [Motivations.md](https://github.com/shubhomoydas/ad_examples/blob/master/Motivations.md#motivation-for-ensemble-based-active-anomaly-discovery).



### 方法

T该方法更详细的解释 [(Das, S., Islam, R., et al. 2019)](https://arxiv.org/pdf/1901.08930.pdf).



图表说明了数据是如何被主动标记的。

[![Simplified AAD illustration](https://github.com/shubhomoydas/ad_examples/raw/master/figures/percept.png)](https://github.com/shubhomoydas/ad_examples/blob/master/figures/percept.png)



参考:

- Das, S., Islam, R., Jayakodi, N.K. and Doppa, J.R. (2019). *Active Anomaly Detection via Ensembles: Insights, Algorithms, and Interpretability*. [(pdf)](https://arxiv.org/pdf/1901.08930.pdf) (**This is the most comprehensive version.**)

- Das, S. and Doppa, J.R. (2018). *GLAD: GLocalized Anomaly Detection via Active Feature Space Suppression*. [(pdf)](https://arxiv.org/pdf/1810.01403.pdf)

- Das, S., Islam, R., Jayakodi, N.K. and Doppa, J.R. (2018). *Active Anomaly Detection via Ensembles*. [(pdf)](https://arxiv.org/pdf/1809.06477.pdf)

- Das, S., Wong, W-K., Fern, A., Dietterich, T. and Siddiqui, A. (2017). *Incorporating Feedback into Tree-based Anomaly Detection*, KDD Interactive Data Exploration and Analytics (IDEA) Workshop. [(pdf)](https://arxiv.org/pdf/1708.09441)[(presentation)](https://github.com/shubhomoydas/pyaad/blob/master/presentations/IDEA17_slides.pptx)

- Das, S., Wong, W-K., Dietterich, T., Fern, A. and Emmott, A. (2016). *Incorporating Expert Feedback into Active Anomaly Discovery* in the Proceedings of the IEEE International Conference on Data Mining. [(pdf)](http://web.engr.oregonstate.edu/~wongwe/papers/pdf/ICDM2016.AAD.pdf)[(presentation)](https://github.com/shubhomoydas/aad/blob/master/overview/ICDM2016-AAD.pptx)

- Das, S. (2017). *Incorporating User Feedback into Machine Learning Systems*, [PhD Thesis](http://ir.library.oregonstate.edu/concern/graduate_thesis_or_dissertations/9019s7533) [(pdf)](https://ir.library.oregonstate.edu/downloads/m900p057t) -- The work on AAD in this repository was developed during my PhD and Post-doctoral research.

  

## 运行 AAD

This codebase is my **research** platform. The main `bash` script `aad.sh` makes it easier to run all AAD experiments multiple times (in the spirit of scientific inquiry) so that final results can be averaged. I try to output results for different parameter settings into different folders (under `temp/aad`) so that results can be easily compared without conflicts. I also output to files the instance indexes (as 1-indexed and **not** 0-indexed) in the order they were queried for fine-grained analysis and visualization. If you want to introduce a new dataset with the least effort, then put its files under `ad_examples/datasets/anomaly` folder in the same format and structure as those of the `toy2` dataset and follow the same naming conventions. Else, a little effort would be needed to invoke the necessary data load APIs. You might also want to have a look at the [simplified API usage example](https://github.com/shubhomoydas/ad_examples#how-to-employ-aad-in-your-own-application) (`ad_examples/aad/demo_aad.py`) below.

这个代码库是我的研究平台。 主 bash 脚本 AAD.sh 使得多次运行所有 AAD 实验变得更加容易(本着科学探索的精神) ，从而可以求取最终结果的平均值。 我尝试将不同参数设置的结果输出到不同的文件夹(在 temp / aad 下面) ，这样可以很容易地比较结果而不会发生冲突。 我还按照查询实例索引以便进行细粒度分析和可视化的顺序将其输出到文件中(作为1索引而不是0索引)。 如果您想以最少的工作量引入一个新的数据集，那么将其文件放在广告示例 / 数据集 / 异常文件夹下，使用与 toy2数据集相同的格式和结构，并遵循相同的命名约定。 否则，调用必要的数据加载 api 将需要一些工作。 您可能还想看看下面的简化的 API 用法示例(ad examples / aad / demo aad.py)。

**Note:** It might seem that the script `aad.sh` requires an intimidating number of parameters, but bear in mind that the simplest settings (or automatic configuration from cross-validation etc.) are preferred for any formal publication. **The reason we allow so many parameters to be configurable is to support ablation studies and general curiosity.**

注意: 看起来脚本 aad.sh 需要大量的参数，但是请记住，对于任何正式的发布来说，最简单的设置(或者来自交叉验证的自动配置等)都是首选的。 我们之所以允许这么多的参数是可配置的，是为了支持烧蚀研究和普遍的好奇心。

This codebase supports the following five different anomaly detection algorithms. If pre-computed anomaly scores are available from another ensemble-based algorithm, then jump to the [below section on pre-computed scores](https://github.com/shubhomoydas/ad_examples#running-aad-with-precomputed-anomaly-scores).

这个代码库支持以下5种不同的异常检测算法。 如果可以从另一个基于集成的算法中获得预先计算的异常值，那么跳转到下面关于预先计算的值的部分。

- The 这个[LODA based AAD 基于 LODA 的 AAD](https://github.com/shubhomoydas/ad_examples/blob/master/ad_examples/aad/loda_aad.py) (**works with streaming data, but does not support incremental update to model after building the model with the first window of data 可以处理流数据，但不支持在使用第一个数据窗口构建模型之后对模型进行增量更新**)

- The

   

  这个

  Isolation Forest based AAD 基于隔离森林的 AAD

   

  (

  streaming support with model update 模型更新的流式支持

  )

  - For streaming update, we support two modes:

     

    对于流更新，我们支持两种模式:

    - **Mode 0 模式0**: Replace the oldest 20% trees (configurable) with new trees trained on the latest window of data. The previously learned weights of the nodes of the retained (80%) trees are retained, and the weights of nodes of new trees are set to a default value (see code) before normalizing the entire weight vector to unit length. For this mode, set * 用根据最新数据窗口训练的新树替换最老的20% 树(可配置)。 保留保留的(80%)树节点的先前学习的权重，并将新树节点的权重设置为默认值(见代码) ，然后将整个权重向量归一化为单位长度。 对于此模式，设置`CHECK_KL_IND=0` in 在`aad.sh`.
    - **Mode 1 模式1** (Default): Replace trees based on KL-divergence. Further details are (默认值) : 替换基于 kl- 散度的树。 详情请参阅[below 下面](https://github.com/shubhomoydas/ad_examples#data-drift-detection). For this mode, set . 对于此模式，设置`CHECK_KL_IND=1` in 在`aad.sh`.

- HS Trees based AAD 基于树的 AAD

   

  (

  streaming support with model update 模型更新的流式支持

  )

  - For streaming update, the option 对于流式更新，选项`--tree_update_type=0` replaces the previous node-level sample counts with counts from the new window of data. This is as per the original published algorithm. The option 将以前的节点级示例计数替换为来自新数据窗口的计数。 这是根据原始发布的算法。 选择`--tree_update_type=1` updates the node-level counts as a linear combination of previous and current counts -- this is an experimental feature. 将节点级计数更新为先前计数和当前计数的线性组合——这是一个实验特性

- 基于 AAD森林的RS Forest

   

  (

  streaming support with model update 模型更新的流式支持

  )

  - See the previous HS Trees streaming update options above. 请参阅上面的 HS 树流更新选项

- The

   

  这个

  Isolation Forest based AAD with Multiview 基于多视图隔离森林的 AAD

   

  (

  streaming support with model update 模型更新的流式支持

  )

  - This is useful if (say) there are groups of features that represent coherent groups and we want to create trees only with the features in a particular group. For instance, in a malware detection application, we might have 100 features computed with static program features and 120 computed with dynamic program features. Then we want 50 isolation trees with only the 100 static features and 50 trees with the 120 dynamic features for a total of 100 trees. In a streaming situation, we would want the tree replacement to take into account the grouping as well, for example, if there has been no drift in the static features while there is a significant drift in dynamic features, we should not replace the trees of static features and only replace the trees of dynamic features. 如果(比方说)有一组特征代表一致的组，并且我们希望只使用特定组中的特征创建树，那么这是有用的。 例如，在恶意软件检测应用程序中，我们可能用静态程序特征计算100个特征，用动态程序特征计算120个特征。 然后我们需要50棵具有100个静态特征的隔离树和50棵具有120个动态特征的树，共计100棵树。 在分流的情况下，我们希望树的替换也考虑到分组，例如，如果静态特征没有漂移，而动态特征有明显漂移，我们不应该替换静态特征树，而只是替换动态特征树

To run the Isolation Forest / HS-Trees / RS-Forest / LODA based algorithms, the command has the following format (**remember to run the commands from the 'python' folder, and monitor progress in logs under 'temp' folder**):

要运行基于 Isolation Forest / HS-Trees / rs-Forest / LODA 的算法，该命令具有以下格式(记住从'python'文件夹运行命令，并监视'temp'文件夹下日志的进度) :

```
bash ./aad.sh <dataset> <budget> <reruns> <tau> <detector_type> <query_type[1|2|8|9]> <query_confident[0|1]> <streaming[0|1]> <streaming_window> <retention_type[0|1]> <with_prior[0|1]> <init_type[0|1|2]>

for Isolation Forest, set <detector_type>=7; 
for HSTrees, set <detector_type>=11;
for RSForest, set <detector_type>=12;
for LODA, set <detector_type>=13;
for Isolation Forest Multiview, set <detector_type>=15;
```



示例(使用隔离林，非流) :

```
bash ./aad.sh toy2 35 1 0.03 7 1 0 0 512 0 1 1
```



注意: 由于 toy2是一个2D 数据集，上面的代码将在临时文件夹下生成2D 图(树分区和得分轮廓)。



示例(带有 HSTrees 流) :

```
bash ./aad.sh toy2 35 1 0.03 11 1 0 1 256 0 1 1
```



注意: 我建议使用隔离森林而不是 HSTrees 和 RSForest，即使数据中存在漂移:

```
bash ./aad.sh toy2 35 1 0.03 7 1 0 1 512 1 1 1
```



流数据注释:

流目前支持两种数据retention策略:

- retention类型0: 这里来自流的新实例完全覆盖了旧的实例*unlabeled instances 未标记实例* 
- retention类型1: 在这里，新实例首先与旧的未标记实例合并，然后按距离边距的降序排列完整的实例集。 顶部实例被保留; 其余的被丢弃。 这是强烈推荐的



查询策略注释:

See [below](https://github.com/shubhomoydas/ad_examples#does-query-diversity-with-compact-descriptions-help) for query strategies currently supported. `QUERY_TYPE` variable in `aad.sh` determines the query strategy. One of the strategies discussed in detail below is to diversify queries using [descriptions](https://github.com/shubhomoydas/ad_examples#query-diversity-with-compact-descriptions). This is invoked by `QUERY_TYPE=8`option. To actually see the benefits of this option, set the query batch size to greater than 1 (e.g., 3) (variable `N_BATCH` in `aad.sh`).

有关当前支持的查询策略，请参见下文。 Sh 中的 QUERY type 变量决定查询策略。 下面详细讨论的策略之一是使用描述使查询多样化。 这是由 QUERY type 8选项调用的。 要真正看到这个选项的好处，请将查询批量大小设置为大于1(例如，3)(aad.sh 中的变量 n batch)。



关于使用一组标记实例的预训练 AAD 的注意事项:



假设在启动活动学习循环之前，已经有了 `m` 个预先标记好的实例。 然后，建议在获得更多反馈之前，使用预先标记的实例运行 Aad.update weights ()的`min(20, m)`迭代。 这是因为 AAD 需要推断权重参数 w 和 tau-th 分位数分值 q-tau。 这些都不能通过优化一下子推断出来。 通过运行几次更新，w 和 q-tau 都会稳定下来。 在active学习的过程中，w 和 q-tau 通过调用 Aad.update weights ()对每个新标签只进行一次更新，并允许参数在整个预算中通过对 Aad.update weights ()的所有(多个)调用保持稳定。

## 用 AAD 生成compact描述

AAD, when used with a forest-based detector such as Isolation Forest, can output a compact set of subspaces that contain all labeled anomalies. The idea is explained in [(Das, Islam, et al. 2019)](https://github.com/shubhomoydas/ad_examples#cite-this-work). Following illustrations show the results of this approach.

Aad 与基于森林的检测器(如隔离森林)一起使用时，可以输出包含所有标记异常的紧凑子空间集。 这个观点在《 Das，Islam，et al. 2019》中得到了解释。 下面的例子显示了这种方法的结果。

**Note:** The algorithm to compute compact descriptions (as illustrated here) might also be considered to be a non-parametric clustering algorithm where each 'description' is a cluster.

注意: 计算紧凑描述的算法(如图所示)也可以被认为是一种非参数聚类算法，其中每个"描述"都是一个聚类。

To generate the below, use the command:

要生成以下命令:

```
bash ./aad.sh toy2 35 1 0.03 7 1 0 0 512 0 1 1
```

[![Contours](https://github.com/shubhomoydas/ad_examples/raw/master/figures/aad/contours.png)](https://github.com/shubhomoydas/ad_examples/blob/master/figures/aad/contours.png)

[![Descriptions](https://github.com/shubhomoydas/ad_examples/raw/master/figures/aad/description.png)](https://github.com/shubhomoydas/ad_examples/blob/master/figures/aad/description.png)

## Bayesian Rulesets with AAD 与 AAD 的贝叶斯规则集

As we saw above, AAD helped infer the true relevance of subspaces and the most relevant subspaces were then employed as candidates for compact descriptions. This approach can be applied with other rule-mining algorithms such as (Wang, Rudin, et al. 2016) as well. (Wang, Rudin, et al. 2016) is a supervised algorithm that is first initialized with a [modestly] large set of classification rules. It then infers a much smaller subset of interpretable rules from the initial set of rules using a Bayesian framework. We will refer to these rules as **Bayesian Rulesets** (in contrast with our *Compact Descriptions*). The following command generates the plots below and illustrates both *Compact Descriptions* and *Bayesian Rulesets*. Here, we first run AAD with a budget of 30 and retrieve the top subspaces which cover all *discovered*anomalies. These subspaces (top left plot) are used as candidates for both *Compact Descriptions* (top right plot) as well as *Bayesian Rulesets* (bottom left plot). The discovered rules which imply **Anomaly** are shown in the bottom right plot. Since *Bayesian Rulesets* is supervised, we take the set of queried instances, and another set of randomly sampled unlabeled instances (having same size as queried) as the training set. The sampled unlabeled instances selected for training are assumed to be **nominal**.

正如我们上面看到的，AAD 有助于推断子空间的真实相关性，然后将最相关的子空间用作紧致描述的候选子空间。 这种方法也可以应用于其他规则挖掘算法，如(Wang，Rudin，et al. 2016)。 (Wang，Rudin，et al. 2016)是一个有监督的算法，它首先由一个[适度的]大型分类规则集初始化。 然后，它使用贝叶斯框架从最初的规则集推导出更小的可解释规则子集。 我们将这些规则称为贝叶斯规则集(与我们的紧凑描述形成对比)。 下面的命令生成下面的图形，并说明了 Compact Descriptions 和 Bayesian ruleset。 在这里，我们首先运行预算为30的 AAD，并检索覆盖所有已发现异常的顶级子空间。 这些子空间(左上图)用作紧凑描述(右上图)和贝叶斯规则集(左下图)的候选对象。 右下角的图表显示了已发现的异常现象规律。 由于贝叶斯规则集是有监督的，我们采用查询实例集和另一组随机抽样的未标记实例(具有与查询相同的大小)作为训练集。 选择用于训练的未标记样本被假定为标称样本。

```
pythonw -m ad_examples.aad.test_rulesets
```

[![Bayesian Rulesets](https://github.com/shubhomoydas/ad_examples/raw/master/figures/aad/rulesets.png)](https://github.com/shubhomoydas/ad_examples/blob/master/figures/aad/rulesets.png)

A comparison of **interpretable** rules found by *Compact Descriptions (CD)* and *Bayesian Rulesets (BR)* is shown below for the *toy2* dataset. Interpretability implies that the rules will be simple-enough for an analyst to understand. Such rules generally have shorter lengths (fewer predicates). The application of compact descriptions in the case of diversity only involved a set-covering problem without any regard to interpretability. Now, we modify the ILP (integer linear programming) objective in the following manner (see [CompactDescriber.describe()](https://github.com/shubhomoydas/ad_examples/blob/master/ad_examples/aad/forest_description.py)):

紧凑描述(CD)和贝叶斯规则集(BR)发现的可解释规则的比较显示在 toy2数据集的下面。 可解释性意味着规则将是简单的 -- 足以让分析人员理解。 这些规则通常具有较短的长度(较少的谓词)。 在多样性的情况下，紧凑描述的应用只涉及集合覆盖问题，而不考虑可解释性。 现在，我们以下面的方式修改 ILP (整数 / 线性规划)目标(参见 CompactDescriber.describe ()) :

1. We add a **complexity** penalty to each region. A region is defined by its feature ranges, i.e., the max and min values of each feature within the region. A feature range that does not have either a minimum or a maximum value (i.e., they are `-inf` or `inf`) makes the corresponding region definition simpler because it implies that fewer predicates will be required to define the region. Our complexity definition encourages selection of regions which have fewer feature range values in their definition. 我们对每个区域增加了一个复杂度惩罚。 区域是由其特征范围定义的，即区域内每个特征的最大值和最小值。 没有最小值或最大值的特征范围(即，它们是 -inf 或 inf)使相应的区域定义更简单，因为它意味着定义区域需要更少的谓词。 我们的复杂性定义鼓励选择定义中特征范围值较少的区域
2. We set a minimum precision threshold (defaults to 0.4) for the rules selected. This removes noisy rules. 我们为选择的规则设置了最小精度阈值(默认值为0.4)。 这消除了嘈杂的规则
3. Whenever a negative (nominal) example gets included within a region, we penalize it by the volume of the corresponding region. This encourages selection of regions with fewer false positives. 每当一个负的(名义上的)例子包含在一个区域中时，我们就用相应区域的体积来惩罚它。 这鼓励选择假阳性较少的区域

We generate the rules by both techniques (*CD* and *BR*) at regular points in the feedback cycle and compute the F1 score on the entire dataset (top left plot below). These results were averaged over 10 independent runs. *CD* and *BR* are generally competitive. A decomposition of the F1 score shows that *CD* usually has a lower precision, but higher recall than *BR*. The bottom row shows that *CD* usually selects **simpler** rules (i.e., smaller length) than *BR* in order to describe the anomalies. The grey curve (bottom row middle, labeled 'Candidate Rules') is the total number of rules available in a feedback cycle. Both *CD* and *BR* use the same set of candidate rules. A slightly smaller subset of the candidate rules were selected by *BR* than *CD* to describe most anomalies.

我们在反馈周期的规则点上用两种技术(CD 和 BR)生成规则，并计算整个数据集的 F1得分(左上角的图)。 这些结果平均超过10个独立的运行。 Cd 和 BR 通常是有竞争力的。 对 F1分数的分解表明，CD 通常具有较低的准确率，但比 BR 具有更高的查全率。 下面一行显示，CD 通常选择比 BR 更简单的规则(例如，更小的长度)来描述异常。 灰色曲线(下排中间，标记为"候选规则")是反馈循环中可用规则的总数。 Cd 和 BR 使用相同的候选规则集。 Br 比 CD 选择的候选规则的一个稍小的子集来描述大多数异常。

**Important:** The results have been presented here only for the *toy2* dataset because we have used this as the running example. The results differ by the dataset, but the general patterns pointed out above seem to hold on the real-world datasets as shown in the document [all-rule_analysis.pdf](https://github.com/shubhomoydas/ad_examples/blob/master/documentation/rules/all-rule_analysis.pdf).

重要提示: 这里只显示 toy2数据集的结果，因为我们使用它作为运行示例。 结果因数据集的不同而不同，但是上面指出的一般模式似乎适用于真实世界的数据集，如文档 all-rule analysis.pdf 所示。

In order to generate the plots below, first set `RULES_IND=1` and `RULE_OUTPUT_INTERVAL="--rule_output_interval=5"` in `aad.sh`, and then execute the following commands:

为了生成下面的图形，首先在 aad.sh 中设置 RULES ind 1和 RULE output interval"-- RULE output interval 5"，然后执行以下命令:

```
bash ./aad.sh toy2 40 10 0.03 7 1 0 0 512 0 1 1
bash ./aad.sh toy2 40 10 0.03 7 1 0 3 512 0 1 1
```

[![Compare Rulesets](https://github.com/shubhomoydas/ad_examples/raw/master/figures/aad/rulesets_compare.png)](https://github.com/shubhomoydas/ad_examples/blob/master/figures/aad/rulesets_compare.png)

**Rule expressions**

规则表达式

The codebase uses a very light-weight rule/predicate framework. The conjunctive rules (used by the description algorithms) are composed of a series of `Predicate` objects and operations on these are encapsulated in `ConjunctiveRule`. In order to understand and debug these data structures, please see `test_rule_apis()` in [expressions.py](https://github.com/shubhomoydas/ad_examples/blob/master/ad_examples/common/expressions.py) and the [tutorial](https://github.com/shubhomoydas/ad_examples/blob/master/ad_examples/common/expressions_tutorial.py). The rule framework has been introduced primarily to provide a higher-level abstraction for rulesets so that programming bugs may be avoided.

代码库使用一个非常轻量级的规则 / 谓词框架。 连接规则(描述算法使用)由一系列谓语对象组成，并对这些谓语对象进行操作封装在结膜规则中。 为了理解和调试这些数据结构，请参阅表达式和教程中的测试规则 api ()。 引入规则框架的主要目的是为规则集提供更高层次的抽象，以避免编程错误。

参考文件:

- Wang, T., Rudin, C., Velez-Doshi, F., Liu, Y., Klampfl, E., MacNeille, P. (2016). 王，t，Rudin，c. ，Velez-Doshi，f. ，Liu，y. ，Klampfl，e. ，MacNeille，p. (2016)*Bayesian Rule Sets for Interpretable Classification 

## compact描述的应用



compact描述(或者贝叶斯规则集)有多种用途，包括:

- 通过查询描述中不同子空间的实例，可以非常快速地发现不同类别的异常
- 提高异常实例的可解释性

We assume that in a practical setting, the analyst(s) will be presented with instances along with their corresponding description(s). Additional information can be derived from the descriptions and shown to the analyst such as the number of instances in each description, which can help prioritize the analysis. Unfortunately, most uses of descriptions are subjective or application dependent, and therefore, hard to evaluate. However, we can evaluate the improvement in query [diversity](https://github.com/shubhomoydas/ad_examples#query-diversity-with-compact-descriptions) objectively as we do [below](https://github.com/shubhomoydas/ad_examples#does-query-diversity-with-compact-descriptions-help).

我们假设在实际的环境中，分析师将会看到实例及其相应的描述。 额外的信息可以从描述中得到，并显示给分析师，比如每个描述中的数量，这有助于分析的优先级。 不幸的是，描述的大多数使用是主观的或应用程序依赖的，因此，很难评估。 然而，我们可以客观地评估查询多样性的改进，如下所示。

## 使用compact描述的查询多样性

在不显著影响异常检测效率的情况下查询一组不同的实例在 [(Das, Islam, et al. 2019)](https://github.com/shubhomoydas/ad_examples#cite-this-work).



要生成以下命令:

```
bash ./aad.sh toy2 10 1 0.03 7 1 0 0 512 0 1 1
```

[![Query Diversity](https://github.com/shubhomoydas/ad_examples/raw/master/figures/aad/query_diversity.png)](https://github.com/shubhomoydas/ad_examples/blob/master/figures/aad/query_diversity.png)



## 使用compact描述的多样性查询是否有用？



我们比较以下查询策略(变量 QUERY type、 n batch 和 n explore 在 aad.sh 中设置) :

- **Select the single-most anomalous instance per feedback iteration:** (`QUERY_TYPE=1, N_BATCH=1`) [Select](https://github.com/shubhomoydas/ad_examples/blob/master/ad_examples/aad/query_model.py) the top-most instance ordered by anomaly score. (**BAL (Adaptive Prior)** in the plots below.) 选择每次反馈迭代中最异常的实例: (QUERY type 1，n batch 1)选择按异常值排序的最顶级实例。 (BAL (适应性优先)在下面的图。)
- **Select a set of the top-most anomalous instances per feedback iteration:** (`QUERY_TYPE=1, N_BATCH=3`) [Select](https://github.com/shubhomoydas/ad_examples/blob/master/ad_examples/aad/query_model.py) a batch of three top-most instances ordered by anomaly score. (**ifor_q1b3** in the plots below.) 选择一组每次反馈迭代中最不寻常的实例: (QUERY type 1，n batch 3)选择一批由异常得分排序的最不寻常的三个实例。 (ifor q1b3 in the plot below.)
- **Select a random subset of the most anomalous instances per feedback iteration:** (`QUERY_TYPE=2, N_BATCH=3, N_EXPLORE=10`) [Select](https://github.com/shubhomoydas/ad_examples/blob/master/ad_examples/aad/query_model.py) a random batch of three instances among top 10 anomalous instances. (**ifor_top_random** in the plots below.)
- **Select a subset of most anomalous instances whose descriptions are diverse within a feedback iteration:**(`QUERY_TYPE=8, N_BATCH=3, N_EXPLORE=10`) [Select](https://github.com/shubhomoydas/ad_examples/blob/master/ad_examples/aad/query_model_other.py) three instances among top 10 anomalous instances which have most diverse descriptions (explained in [previous section](https://github.com/shubhomoydas/ad_examples#query-diversity-with-compact-descriptions)). (**BAL-D** in the plots below.)
- **Select a subset of most anomalous instances which are farthest from each other within a feedback iteration:**(`QUERY_TYPE=9, N_BATCH=3, N_EXPLORE=10`) [Select](https://github.com/shubhomoydas/ad_examples/blob/master/ad_examples/aad/query_model_euclidean.py) three instances among the top 10 anomalous instances which have the highest average euclidean distance between them. First short-list the top 10 anomalous instances as candidates. Now, to select a batch of (three) instances, first add the most anomalous instance from these candidates to the selected list. Then iterate (two more times); in each iteration, add that instance (from the candidates) to the selected list which has the maximum average distance from the instances currently in the selected list. This is a diversity strategy common in existing literature. (**BAL-E** in the plots below.)

The plots below show that the description-based diversity strategy `BAL-D` indeed helps. While selecting the top-most anomalous instances is highly label-efficient for discovering anomalies [(Das, Islam, et al. 2019)](https://github.com/shubhomoydas/ad_examples#cite-this-work), we can also improve the diversity in each query-batch through descriptions without loss in efficiency. Employing descriptions for diversity (`BAL-D`) also has similar query diversity on the *toy2* dataset as that which maximizes the euclidean distance (`BAL-E`); however, the description based strategy `BAL-D` has the advantage of being more user-friendly because it can characterize multiple anomalies through the descriptions.

To generate the below plots, perform the following steps (**remember to run the commands from the 'python' folder, and monitor progress in logs under 'temp' folder**):

```
- set N_BATCH=1 in aad.sh and then run the command:

    bash ./aad.sh toy2 45 10 0.03 7 1 0 0 512 0 1 1
    
- set N_BATCH=3 in aad.sh, and run the following commands:

    bash ./aad.sh toy2 45 10 0.03 7 1 0 0 512 0 1 1
    bash ./aad.sh toy2 45 10 0.03 7 2 0 0 512 0 1 1
    bash ./aad.sh toy2 45 10 0.03 7 8 0 0 512 0 1 1
    bash ./aad.sh toy2 45 10 0.03 7 9 0 0 512 0 1 1

- Next, generate anomaly discovery curves:
    
    pythonw -m ad_examples.aad.plot_aad_results
    
- Finally, generate class diversity plot:

    pythonw -m ad_examples.aad.plot_class_diversity
```

[![Diversity Effect](https://github.com/shubhomoydas/ad_examples/raw/master/figures/aad/diversity_effect.png)](https://github.com/shubhomoydas/ad_examples/blob/master/figures/aad/diversity_effect.png)

## GLocalized 异常检测

**Glocal** ([according to Wikipedia](https://en.wikipedia.org/wiki/Glocal)): 同时考虑全局和局部情况下的异常

End-users find it easier to trust algorithms they understand and are familiar with. Such algorithms are typically built on broadly general and simplifying assumptions over the entire feature space (i.e., *global* behavior), which might not be applicable universally (i.e., not relevant *locally* in some parts of the feature space) in an application domain. This observation is true of most machine learning algorithms including those for anomaly detection. **GL**ocalized **A**nomaly **D**etection (GLAD) was designed to allow a human analyst to continue using anomaly detection ensembles with global behavior by learning their local relevance in different parts of the feature space via label feedback.

While the approach (outlined below) uses dynamic weighted ensembles, the key idea behind GLAD is to place a **uniform prior over the input space**. This is in contrast with other algorithms which place priors on the *parameter space* (e.g., using an L1 or L2 regularizer for the parameters). We can potentially apply similar priors in other algorithms, especially in explore-exploit situations, and is open for research.

[![GLAD Approach](https://github.com/shubhomoydas/ad_examples/raw/master/figures/glad/approach.png)](https://github.com/shubhomoydas/ad_examples/blob/master/figures/glad/approach.png)

**The usage of priors cannot be overstated in human-in-the-loop algorithms.** Any person who has to inspect the data one-by-one, usually does so (or **wants to do so**) in a *systematic* manner. It is therefore an imperative for the machine learning algorithms that they be predictable and let the user follow their system. **Priors** help setup this system in a principled manner. GLAD places a prior on the input space such that analysts can expect that they will be presented instances (somewhat) in accordance with the baseline anomaly scores while also providing feedback. Without the prior, the order in which instances are presented could vary a lot.

We might consider GLAD as very similar to the tree-based AAD we saw above. Tree-based AAD chops up the feature space into discrete subspaces and then places an uniform prior over the subspaces (i.e., the uniform weight vector). Now, if we take this view to an extreme and imagine that each point represents a subspace, we can see the connection to GLAD. While the tree-based AAD assigned the discrete subspace scores to the instances (e.g., it was the node depth for Isolation Forest), the scores assigned by GLAD are continuous, defined by the ensemble members. The *relevance* in GLAD is analogous to the *learned weights* in the tree-based AAD.

The architecture of GLAD is shown below.

[![GLAD Architecture](https://github.com/shubhomoydas/ad_examples/raw/master/figures/glad/architecture.png)](https://github.com/shubhomoydas/ad_examples/blob/master/figures/glad/architecture.png)

The results on the *Toy2* dataset are shown below. In order to generate these figures, run the following commands (replace `python` with `pythonw` if facing problems with python 2.7):

```
python -m ad_examples.glad.test_glad --log_file=temp/glad/test_glad.log --debug --dataset=toy2 --n_anoms=60 --loda_debug --plot --op=unit

python -m ad_examples.glad.glad_batch --log_file=temp/glad/glad_batch.log --debug --dataset=toy2 --n_epochs=200 --budget=60 --loda_debug --plot
```

[![GLAD Toy2](https://github.com/shubhomoydas/ad_examples/raw/master/figures/glad/glad_toy2.png)](https://github.com/shubhomoydas/ad_examples/blob/master/figures/glad/glad_toy2.png)

**GLAD Explanations**

To help the analyst understand the anomaly detector result, we have used the concept of '*descriptions*' for the tree-based algorithms above. We now introduce the concept of '*explanations*'. While both seem similar, they are actually quite different:

1. **Description:** A description generates a compact representation for a group of instances. The main application is to reduce the cognitive burden on the analysts.
2. **Explanation:** An explanation outputs a reason why an instance was assigned a high score. Usually, we limit the scope of an explanation to one instance. The main application is to diagnose the model: whether the detector(s) are working as expected.

GLAD assumes that the anomaly detectors in the ensemble can be arbitrary. The best it can offer as an explanation is the member which is most relevant for a test instance. With this in mind, we can employ the following strategy:

1. Employ the AFSS network to predict the relevance of individual ensemble members on the complete dataset.
2. Find the instances for each ensemble member for which that member is the **most** relevant. Mark these instances as *positive* and the rest as *negative*.
3. Train a separate decision tree for each member to separate the corresponding positives and negatives.

**Important**: The approach we now present assumes that the explanation library LIME (Ribeiro et al. 2016) is installed. If not, install it with `pip install lime`.

The above strategy is intended to provide a set of interpretable rules for the relevance of a specific ensemble member (detector) in the feature space. This is illustrated in the figure below. These plots were generated by running the following with python 3.6.

```
python -m ad_examples.glad.glad_batch --log_file=temp/glad/glad_batch.log --debug --dataset=toy2 --n_epochs=200 --budget=30 --loda_debug --plot --explain
```

There are four members (i.e., LODA projections) in our current example. The region where a member is ranked as the top-most relevant detector is shown in red. The last member (member 3) did not rank as the top-most relevant for any instance; hence, it does not have any region marked in red. It is important to note that the **relevance of a detector is different from the anomaly score(s) it assigns**. A detector which is *relevant* in a particular subspace predicts the labels of instances in that subspace correctly irrespective of whether those instances are anomalies or nominals. For example, ensemble members 0 and 1 are relevant (in the figure below) in subspaces which have mostly nominal instances, i.e., they correctly predicted that instances in those subspaces are *nominal*. Members, which incorrectly predicted that instances in these subspaces were anomalies, lost relevance there.

In order to dig deeper into the explanation for a test instance, we may take the following approach:

1. Use AFSS to identify the most relevant ensemble member for the test instance.
2. Employ a model agnostic explanation technique such as LIME (Ribeiro et al. 2016) to generate the explanation using the most relevant ensemble member.

We illustrate this approach with a test point *(6.17921313, 3.04212317)* circled in green in the figure below. The generated explanation (output in the log file) is also shown below. Here, the ensemble member with index 2 has the highest relevance (0.86733496) for this test point. The explanation `2.16 < y <= 3.31` has the highest absolute weight (0.4253860500153764).

```
Explain inst: 164 [6.17921313 3.04212317] (anomaly); best: 2 [[0.72648823 0.6642795  0.86733496 0.6068334 ]]
[('2.16 < y <= 3.31', -0.4253860500153764), ('x > 2.65', 0.3406543313093905)]
```

[![GLAD Explain](https://github.com/shubhomoydas/ad_examples/raw/master/figures/glad/glad_explain.png)](https://github.com/shubhomoydas/ad_examples/blob/master/figures/glad/glad_explain.png)

**Reference(s)**:

- Das, S. and Doppa, J.R. (2018). *GLAD: GLocalized Anomaly Detection via Active Feature Space Suppression*. [(pdf)](https://arxiv.org/pdf/1810.01403.pdf)
- Ribeiro, M.T., Singh, S. and Guestrin, C. (2016). *"Why Should I Trust You?" Explaining the Predictions of Any Classifier*, KDD. [(code)](https://marcotcr.github.io/lime)

## 异常检测器 vs 分类器？

The answer is: **it depends on the dataset and the application**. 

```
pythonw -m ad_examples.aad.anomaly_vs_classifier --dataset=5 --algo=explain
```

[![Anomaly Detector vs Classifier](https://github.com/shubhomoydas/ad_examples/raw/master/figures/aad/anomaly_vs_classifier.png)](https://github.com/shubhomoydas/ad_examples/blob/master/figures/aad/anomaly_vs_classifier.png)

## 使用预计算的异常分值运行AAD 

In case scores from anomaly detector ensembles are available in a CSV file, then AAD can be run with the following command.

```
pythonw -m ad_examples.aad.precomputed_aad --startcol=2 --labelindex=1 --header --randseed=42 --dataset=toy --datafile=./ad_examples/datasets/toy.csv --scoresfile=./ad_examples/datasets/toy_scores.csv --querytype=1 --detector_type=14 --constrainttype=4 --sigma2=0.5 --budget=35 --tau=0.03 --Ca=1 --Cn=1 --Cx=1 --withprior --unifprior --init=1 --runtype=simple --log_file=./temp/precomputed_aad.log --debug
```

**Note: The detector_type is 14** for precomputed scores. The input file and scores should have the same format as in the example files (toy.csv, toy_scores.csv). Also, make sure the initialization is at uniform (`--init=1`) for good label efficiency (maximum reduction in false positives with minimum labeling effort). If the weights are initialized to zero or random, the results will be poor. *Ensembles enable us to get a good starting point for active learning in this case.*

## 怎样在实际中应用AAD

The [demo_aad.py](https://github.com/shubhomoydas/ad_examples/blob/master/ad_examples/aad/demo_aad.py) shows the simpest AAD implementation that can be used as a template by other developers. To load a different dataset, replace `get_synthetic_samples(stype=2)` (in the code) with the appropriate function(s). The following command executes the code; check the generated log file `temp/demo_aad.log` for details such as anomaly descriptions.

```
pythonw -m ad_examples.aad.demo_aad
```

# GAN-based异常检测

Generative Adversarial Networks (GAN) (Goodfellow et al., 2014) are increasingly popular for anomaly detection and a few general approaches have emerged. The strength of GANs seems to be that they can exploit the latent representations in structured data such as images. One specific technique that we will investigate is AnoGAN (Schlegl et al. 2017). While AnoGAN was applied to medical image data, we will try to demonstrate its working in the simplest possible way with our *Toy* datasets.

**Reference(s)**:

- Ian J. Goodfellow, Jean Pouget-Abadi, et al., Generative Adversarial Nets, NIPS 2014 [(pdf)](https://arxiv.org/pdf/1406.2661.pdf)
- Mehdi Mirza and Simon Osindero, Conditional Generative Adversarial Nets, 2014 [(pdf)](https://arxiv.org/pdf/1411.1784.pdf)
- Ian Goodfellow, *NIPS 2016 Tutorial: Generative Adversarial Networks*, NIPS 2016 [(pdf)](https://arxiv.org/pdf/1701.00160.pdf)
- Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, Pieter Abbeel, *InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets*, NIPS 2016 [(pdf)](https://arxiv.org/pdf/1606.03657.pdf)
- Thomas Schlegl, Philipp Seebock, Sebastian M. Waldstein, Ursula Schmidt-Erfurth, Georg Langs, *Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery*, IPMI 2017 [(pdf)](https://arxiv.org/pdf/1703.05921.pdf)

## GAN Training

We first need to train a robust GAN model in order to achieve a decent anomaly detection accuracy. Training GANs is not easy and, among other things, a few tricks need to be employed to avoid *mode collapse* (Goodfellow, 2016).

The following options are available in this codebase which can be tried to improve the GAN training (other options might be added later):

1. One-sided label-smoothing (Goodfellow, 2016)
2. Conditional GAN (Mirza and Osindero, 2014) -- we infer labels by unsupervised clustering. Hence the GAN training is fully unsupervised.
3. InfoGAN (Chen et al, 2016) -- we perform unsupervised clustering by Gaussian mixtures and select the number of classes by BIC model selection criteria. This is then set as the number of labels for InfoGAN.

*Mode collapse* might occur when just a few modes suck in the entire data distribution of GAN. One option is to first cluster the data with a less expensive algorithm (such as a mixture of Gaussians), then apply the cluster labels as class labels and train a Conditional GAN. On 1D-data, this approach shows visibly good results. See the figure below. The following commands generate the images plotted:

```
bash ./gan.sh 2 gan 0 1000
bash ./gan.sh 2 cond 0 1000
bash ./gan.sh 3 gan 0 1000
bash ./gan.sh 3 cond 0 1000
bash ./gan.sh 4 gan 0 1000
bash ./gan.sh 4 cond 0 1000
```

In order to see the results for InfoGAN, replace `cond/gan` by `info` in the above commands (e.g., `bash ./gan.sh 2 info 0 1000`). InfoGAN did not yield very good generative models for the sample data.

[![Simple vs Conditional GAN](https://github.com/shubhomoydas/ad_examples/raw/master/figures/gan/simple_vs_conditional.png)](https://github.com/shubhomoydas/ad_examples/blob/master/figures/gan/simple_vs_conditional.png)

## AnoGAN

We will apply AnoGAN (Schlegl et al., 2017) on a 2D Toy data here and illustrate how it works -- most implementations jump to image data and make it harder to figure out the innards of the algorithm in a straightforward manner. Since the results are encouraging with the 1D-data, we might apply the clustering strategy to the Toy data as well when we train a GAN for AnoGAN. However, it is unclear from the results (below) whether the unsupervised conditional GAN approach is any better than the simple GAN. The following commands generate the images plotted:

```
bash ./gan.sh toy2 gan 1 2000
bash ./gan.sh toy2 cond 1 2000
```

AnoGAN has multiple sources of uncertainty, of which some are:

1. The GAN training
2. The AnoGAN loss (proportion in which the reconstruction loss is combined with the discriminative loss)
3. The stochasticity in computing the reconstructed images of test points

These uncertainties might increase the number of false positives. Still, data such as images which have good low-dimensional latent representations might benefit from the GAN just enough to outperform the other i.i.d. point-based algorithms for that type of data.

[![AnoGAN](https://github.com/shubhomoydas/ad_examples/raw/master/figures/gan/ano_gan.png)](https://github.com/shubhomoydas/ad_examples/blob/master/figures/gan/ano_gan.png)

# 卷积神经网路

This section is a slightly different take on the anomaly detection problem. Instead of trying to detect anomalies, we try to inject them.

The context here is graph data. See the figures below. Figure **(a)** shows a synthetic semi-supervised dataset. We prepare a graph by connecting each node to approx. 4 of its nearest neighbors. The resulting graph is shown in Figure **(b)**. We assume that the nodes marked '*attacker*' (circled in pink) are **within our control**. The node(s) marked '*target*' (circled in green) are **not in our control directly**; however, we would like to influence prediction on the target nodes by modifying just the attacker nodes (if possible).

The figures presented below were generated by the following command:

```
pythonw -m ad_examples.graph.test_gcn --debug --plot --results_dir=./temp/gcn --log_file=temp/test_gcn.log --dataset=face_top
```

GCNs (Kipf and Welling, 2017) are a neural network based technique for learning on graph-structured data. Here, we will employ GCNs to predict the node labels in a partially-labeled graph (i.e., semi-supervised learning). As shown in Figure **(b)**, the nodes are either unlabeled (grey), or they are labeled (blue or red). Within this context, we have two tasks:

1. Train a GCN transductively to predict the missing labels.
2. After the GCN is trained, we change the GCN's prediction on a *target* node by modifying the features of only the *attacker* nodes. *We will assume that the GCN will not be retrained* after we update the attacker nodes.

**Prediction:** Figure **(c)** shows labels for all nodes in the graph as predicted by the GCN after training.

**Attack:** We will employ a simple form of node feature-modification based attack as proposed in *Nettack* (Zugner et al., 2018). Here, the goal is to change the label of the target node from its current most likely label (c_old) to its second-most likely label (c_new). For this, we first compute the gradient of the difference in target node logits between c_new and c_old w.r.t the attacker node(s). Next, we find the attacker node which has the highest absolute gradient for any feature. We then find the minimum change required for the corresponding attacker node and feature such that the target node's label prediction changes. Finally, we add this minimum required change to the attacker node.

Figure **(c)** shows the gradients for the two attack nodes. In this example setup, our GCN has two layers which implies a maximum of two hops for the information/gradient flow during forward-backward propagation. Since the right-most attacker node is more than two-hop distance away from the target node, it has *immediate* gradient=[0, 0] (in reality, computing exact gradient on nodes farther away is tricky). The left attacker node's first feature has the highest absolute gradient (3.870). Therefore, we move the left attacker along the first feature axis in the direction suggested by the gradient -- in this case we move the attacker node to left. We see in Figure **(d)** that the target node's predicted label changes from red to blue by moving the attacker node as explained. We could, alternatively, search along the full gradient direction instead of just the highest-gradient feature. Moreover, we could limit the search for the best attack node to only those attack nodes which are within as many hops from the target as there are layers in the GCN.

**Implementation:** (Zugner et al., 2018) have proposed a very simple network for the GCN (nettack). This simplifies computation of the derivative of logit difference w.r.t input features. It also helps scale the network better in the transductive setting. However, since our intent here is to understand GCNs and experiment with them in a minimally restricted manner, we have implemented the GCN in this codebase so that we can employ any arbitrarily complex network with arbitrary number of layers. *Also, (Zugner et al., 2018) supports updates to the adjacency matrix, but we currently do not.*

**Lesson(s) for anomaly detection:** This example demonstrates one approach adversaries will employ to exploit a system. Sometimes this behavior might be easily detected. For example, in Figure **(d)**, the modified attacker seems more isolated from the other nodes and might be detected by anomaly detection algorithms. While the attacker might try to achieve an objective through minimal changes, other statistics might reveal their presence or intent.

[![GCN](https://github.com/shubhomoydas/ad_examples/raw/master/figures/gcn/gcn_face_top.png)](https://github.com/shubhomoydas/ad_examples/blob/master/figures/gcn/gcn_face_top.png)

## Increasing the number of layers

**Increasing the number of GCN layers**

The following command builds a model with **6** GCN layers. Each *GCN layer* involves one graph convolution operation. Therefore, the 6 GCN layer model implies a 6-hop neighborhood. As a result, the target node (in the figure below) is now within the neighborhood of the right-most attack node; this makes the attack nodes's gradients non-zero. *Note that having more than two layers has not been found to be very useful (Kipf and Welling, 2017).* The implications of having more layers on properties such as robustness are probably worth exploring. Having more layers probably increases the **attack surface** for a target node for the specific type of attack described above since more neighbors can now be used for attack. While increasing complexity of deep networks (e.g., by adding layers) sometimes adds more robustness, the situation for GCNs is a bit different because adding GCN layers implies a different model assumption (neighborhood distance) rather than just a different feature representation.

```
pythonw -m ad_examples.graph.test_gcn --debug --plot --results_dir=./temp/gcn --log_file=temp/test_gcn.log --dataset=face_top --n_layers=6
```

[![GCN](https://github.com/shubhomoydas/ad_examples/raw/master/figures/gcn/face_top_gcn_l6_n10_leaky_relu_r0100_p00010_nn5.png)](https://github.com/shubhomoydas/ad_examples/blob/master/figures/gcn/face_top_gcn_l6_n10_leaky_relu_r0100_p00010_nn5.png)

**Increasing the number of neural network layers within each GCN layer**

Within a GCN layer we first add one graph convolution. Next, we might stack zero or more neural network layers on top if it. Thus, each *GCN layer* is composed of one or more neural network layers -- of which the first layer is always a graph convolution. This increases the complexity of each GCN layer without increasing the hop-distance, and might help in identifying better hidden states. Its effect on robustness, as in the previous case, is worth exploring. Robustness of the target node in the illustrated toy dataset actually degraded in our preliminary experiments when we added extra layers to each GCN layer -- but again, more exhaustive experiments will be required before we make any conclusions. We do not show the plots here; however, they can be generated by running the following command. Here, the option `--n_sub_layers=2` adds an additional *leaky_relu* layer on top of the graph convolution in each GCN layer. The default strategy of adding additional layers is rather simplistic (see `simple_gcn.create_gcn_default()`) and should be customized for each dataset.

```
pythonw -m ad_examples.graph.test_gcn --debug --plot --results_dir=./temp/gcn --log_file=temp/test_gcn.log --dataset=face_top --n_layers=2 --n_sub_layers=2 --activation_type=leaky_relu
```

## Robustness with ensembles

One commonly suggested technique to improve robustness of deep networks is to use *ensembles*. For GCNs, we can train multiple GCN models with subsampled edges. This means that although the nodes of the graph remain the same across all models, the adjacency matrices differ. The below command creates such a model with 10 members. The corresponding results are shown below. Here, we see that in Figure **(c)** the gradients are now smaller in magnitude. This implies that the attacker node's influence is somewhat diminished. As a result, the attribute(s) of the attacker need to change more (Figure **(d)**) to flip the target's label. Of course, this is just one data point and hence not scientific. **A more rigorous analysis would look at the results averaged across multiple nodes.**

```
pythonw -m ad_examples.graph.test_gcn --debug --plot --results_dir=./temp/gcn --log_file=temp/test_gcn.log --dataset=face_top --ensemble --n_estimators=10 --edge_sample_prob=0.6
```

[![GCN](https://github.com/shubhomoydas/ad_examples/raw/master/figures/gcn/gcn_face_top_ensemble_m10_e060.png)](https://github.com/shubhomoydas/ad_examples/blob/master/figures/gcn/gcn_face_top_ensemble_m10_e060.png)

## Robustness with adversarial training

Most adversarial attacks assume that the model will not be retrained soon (whether or not this is true, is anyone's guess). The attacks are then carried out with the model parameters kept fixed after initial training. The effect of the attack modification might be nullified when the model is retrained even after the attack modifications. To make the model robust, we could then try introducing the adversarial perturbations during training.

For this, one approach might be to train the GCN in the following manner in each epoch: with probability `1 - perturb_prob` train as usual; and with `perturb_prob` perform the following:

1. Select the most uncertain instances as targets
2. Treat a subset of their neighboring nodes as attackers
3. Find the best attack node for each target and compute the corresponding attack node gradient (i.e., gradient of difference between logits of the best and second-best target node labels)
4. Move the best attack node along the direction of the gradient
5. Train the model for the epoch

The below command executes this approach and the corresponding results are plotted below.

```
pythonw -m ad_examples.graph.test_gcn --debug --plot --results_dir=./temp/gcn --log_file=temp/test_gcn.log --dataset=face_top --adversarial_train --n_vulnerable=25 --n_sample_neighbors=3 --perturb_prob=0.1 --perturb_epsilon=0.2
```

**Important:** The approach mentioned here is **EXPERIMENTAL**. There are possibly many other principled ways to implement robustness. The objective here is to make APIs available in order to try out various techniques. Other techniques include:

1. Random perturbations to the uncertain nodes/edges
2. Random perturbations on completely random instances/edges
3. etc.

Observe that in the figure below, even though the gradient is smaller in magnitude than in the previous figures (Single/Ensemble GCNs), the change required to flip the label is (quite counterintuitively) smaller as well. Recall that this is just one data point and we should not be drawing any conclusions from these results apart from getting a general feel for how the techniques work and what options to explore.

[![GCN](https://github.com/shubhomoydas/ad_examples/raw/master/figures/gcn/face_top_gcn_l2_n10_leaky_relu_r0100_p00010_nn5_adv_v25_s3_pe020.png)](https://github.com/shubhomoydas/ad_examples/blob/master/figures/gcn/face_top_gcn_l2_n10_leaky_relu_r0100_p00010_nn5_adv_v25_s3_pe020.png)

**Reference(s)**:

- Thomas N. Kipf and Max Welling, Semi-Supervised Classification with Graph Convolutional Networks, ICLR 2017 [(pdf)](https://arxiv.org/pdf/1609.02907)
- Daniel Zugner, Amir Akbarnejad, and Stephan Gunnemann, Adversarial Attacks on Neural Networks for Graph Data, KDD 2018 [(pdf)](https://arxiv.org/pdf/1805.07984)


