[TOC]

## 建立一个时间序列预测pipeline来预测每周的销量

## 基础知识

### 针对时间序列的机器学习方法



![img](https://cdn-images-1.medium.com/max/800/1*ScwIEwLmXPFhBP46QMpy_A.png)

图2)在时间序列预测中，我们使用历史数据来预测未来。 乔治·桑塔亚那: 不学历史的人注定要重蹈覆辙。 正确的数字取自<https://www.kdnuggets.com/2018/02/cartoon-valentine-machine-learning.html>

时间序列是按时间顺序进行的一系列观察。 时间序列预测包括先建立模型，然后根据历史数据对模型进行拟合，再用它们来预测未来的观测结果。 因此，例如，将观测值的 min (s)、 day (s)、 month (s)作为输入来预测



![img](https://cdn-images-1.medium.com/max/800/1*VBdDmb7p5sZokWmAvgVrCw.png)

图3)将时间序列转换为监督式学习

按照时间(顺序)将数据向后移动的步骤，称为滞后时间或滞后。 因此，时间序列问题可以通过增加测量滞后作为有监督的机器学习的输入而转化为有监督的机器学习。 见图3右边。 一般来说，将滞后的数量作为一个超参数来研究。



![img](https://cdn-images-1.medium.com/max/800/1*j895yH6Twy6PYK7vy6YJGQ.png)图4)通过增加时滞将时间序列转换为监督式学习时间序列。 滞后是指数据在时间上向后移动一步或更多

### 时间序列的交叉验证方法

时间序列的交叉验证不同于不涉及时间或序列的问题的机器学习问题。 在没有时间的情况下，我们选择一个随机的数据子集作为验证集来估计测量的准确性。 在时间序列中，我们经常预测一个未来值。 因此，验证数据必须始终在训练数据之后进行。 时间序列交叉验证有滑动窗口（sliding-window）验证和正向链接（Forward Chaining）验证两种验证方法。



![image-20190513202522678](/Users/stellazhao/EasyML_BOOK/_image/ts-cv.png)

 图5)基本上，时间序列滑动窗口和正向链接有两种交叉验证。 在这篇文章中，我们将考虑forward chaining / 交叉验证方法

图5上面示出了滑动窗口法。 对于这种方法，我们对 n 个数据点进行训练，并验证对下一个 n 个数据点的预测，及时滑动2n 个训练 / 验证窗口为下一步做准备。

图5底部示出正向链接法。 对于这种方法，我们训练最后的 n 个数据点，并验证对下一个 m 个数据点的预测，及时滑动 n + m 长度的训练 / 验证窗口。 这样，我们可以估计我们的模型参数。 为了测试模型的有效性，我们可以在时间序列的末尾保留一个数据块，这个数据块用于测试训练好的模型效果。



![image-20190513203038046](/Users/stellazhao/EasyML_BOOK/_image/image-20190513203038046.png)

 图6: 正向链接交叉验证

图6。 展示了前向链接 CV 是如何工作的。 在这里，有一个滞后项。 因此，我们将模型从第一阶段训练到第三阶段 / 分钟 / 小时 / 天等等，然后进行验证等等。 既然我们已经熟悉了 TS 问题，那么我们就选择一个时间序列问题，建立一个预测模型。

## 实战

### 预测每周销售交易

想象一下，一个商店的经理要求我们建立一个机器学习模型来预测下周的销售数量。 模型必须在每个星期天运行，预测结果必须在每个星期一上午报告。 然后，经理可以决定一周的订单数量。 经理向我们提供了811种产品52周的销售数据。 销售数据在 [*UCI Repository*](https://archive.ics.uci.edu/ml/datasets/Sales_Transactions_Dataset_Weekly) or [*kaggle*](https://www.kaggle.com/crawford/weekly-sales-transactions).

让我们来看看数据



![img](https://cdn-images-1.medium.com/max/800/1*kfNiaQabjto_MQYjqvDN1Q.png)



许多数据科学家可能会为每个产品创建一个单一的模型来预测销售数量。 虽然这可以很好地工作，我们可能会有问题，因为每个模型只有52个数据点，这是非常低的！ 尽管这种方法是可行的，但可能不是最好的解决方案。 此外，如果两个或两个以上产品的销售数量之间存在交互作用，我们可能会因为为每个产品建立单一模型而错过它们的交互作用。 因此，在本帖中，我们将研究如何建立一个多元时间序列预测模型。

### 数据准备

原始数据有一列是产品代码，52周用于销售。 首先，我们将通过融合周的数据来创建一个新的data frame。 因此，新的数据框架有三列，产品代码，周和销售。 此外,"w"和"p"分别从week和product中删除。 那么，让我们来看看新data frame的头尾



![img](https://cdn-images-1.medium.com/max/800/1*auCR3nYHBI770hG4o0mS7A.png)

为了熟悉数据集，销售分布图绘制在图7。 可以看出，有大量的产品只有很少的销售量，而且数据也向左倾斜。 这个问题对建模的影响将在后面讨论。



![img](https://cdn-images-1.medium.com/max/800/1*a58zHt6n8FV4n-zvv1alJQ.png)



图7)销售分布图。 有许多产品销售项目的销售额非常低

### 基本特征工程

由于这篇文章的目标不是 TS 的特征工程，我们将使这一部分尽可能简单。 让我们创建两个通常用于时间序列的特征。 时间倒退一步，1-lag(shift=1)和购买次数之间的差距一周前(w1)和它的前一周，意味着，两个星期前(W2)。 在此之后，由于延迟和差异导致数据集中有空值，请参见图4，我们删除它们。 因此，当我们查看data frame的头部时，它从第2周开始。



![img](https://cdn-images-1.medium.com/max/800/1*jGmRonHpD9b5jD-ZYgLONw.png)

"ToSupervised"和"ToSupervisedDiff"类，代码1和代码2，显示在编码部分，用于通过一个简单的管道获取新的data frame:

```python
steps = [('1_step',
          ToSupervised('Sales','Product_Code',1)),
         ('1_step_diff',
          ToSupervisedDiff('1_Week_Ago_Sales',
          'Product_Code',1,dropna=True))]
super_1 = Pipeline(steps).fit_transform(df)
```

现在，这些数据有了一个合适的形状，可以在有监督的机器学习中使用。

 

### 前向链接交叉验证（Forward-Chaining Cross-Validation）

研究时间序列的另一个问题是时间序列的交叉验证。 我们选择正向链接（forward-chaining）进行模型验证。 为了避免在短短几周内得到一个非常好的模型，我们将每周使用40到52个，每次重复一个过程，并计算分数。 因此，这个模式中的 k-fold 代码可以在 c. 3中找到。

```python
kf = Kfold_time(target='Sales',date_col = 'Week', 
                   date_init=40, date_final=52)
```

因为这篇文章只是一个演示，所以我不会分离一个测试数据集。 在一个真实的项目中，总是保留一些时间段，作为一个测试数据集，用未来的数据来评估模型。

### 评估指标

由于问题是回归，有几个著名的度量来评估模型，如均方误差(Mean Square Error，MSE) ，均值绝对误差(Mean Absolute Error，MAE) ，均方差误差(Root Mean Squared Error，RMSE) ，均方对数误差(Root Mean Squared Log Error，RMSLE) ，r 平方，等等。 每个度量标准都有自己的使用场景，它们对错误的惩罚不同，但它们之间也有一些相似之处。 在这篇文章中，RMSLE 被选择来评估这个模型。



### 基线（Baseline）

通常，当我们建立一个模型时，我们可能会提出一个非常简单的假设，我们期望使用机器学习可以改进它。 在这里，让我们假设每个产品的销售数量在当前周，它将是相同的下一个星期。 这意味着，如果产品 -1在第一周销售10次，那么第二周的销售数量也将相同。 这通常不是一个坏的假设。 那么，让我们把这个假设当作我们的基准模型。

基线模型编码在 C. 5,，让我们看看基线模型是如何工作的

```python
base_model = BaseEstimator('1_Week_Ago_Sales')
errors = []
for indx,fold in enumerate(kf.split(super_1)):
    X_train, X_test, y_train, y_test = fold
    error = base_model.score(X_test,y_test,rmsle)
    errors.append(error)
    print("Fold: {}, Error: {:.3f}".format(indx,error))
    
print('Total Error {:.3f}'.format(np.mean(errors)))
```

> Fold: 0, Error: 0.520 0，Error: 0.520
> Fold: 1, Error: 0.517 1，Error: 0.517
> Fold: 2, Error: 0.510 2，Error: 0.510
> Fold: 3, Error: 0.508 3，Error: 0.508
> Fold: 4, Error: 0.534 4，Error: 0.534
> Fold: 5, Error: 0.523 5，Error: 0.523
> Fold: 6, Error: 0.500 6，Error: 0.500
> Fold: 7, Error: 0.491 7，Error: 0.491
> Fold: 8, Error: 0.506 8，Error: 0.506
> Fold: 9, Error: 0.505 9，Error: 0.505
> Fold: 10, Error: 0.522 10，Error: 0.522
> Fold: 11, Error: 0.552 11，Error: 0.552
> Total Error 0.516 总误差0.516

在这里，fold0到11表示第40周到第52周。 在这12周的基线模型中 RMSLE 的平均值是0.51。 这可以被认为是一个很大的错误，这可能是由于大量的物品被卖出，而卖出的数量很少，如图7所示。

### 机器学习模型

现在，我们将应用机器学习来改进基线预测。 让我们定义一个时间序列回归（c. 5），它和我们的时间序列交叉验证一起工作。 这个类获取 cv 和模型，并返回模型预测和它的得分。 有很多机器学习算法可以用作估计器。 在这里，我们选择一个随机森林。 简单地说，RF 可以被看作是从随机选择列作为根节点开始构造决策树并进行bagging的一种犯法。 因此，它减少了决策树模型的预测方差。 因此，该方法通常比单一的决策树方法性能摇号，但是比为减少决策树模型的偏差而设计的集成方法的性能要差。

```python
model = RandomForestRegressor(n_estimators=1000,
                               n_jobs=-1,
                                random_state=0)
steps_1 = [('1_step',
              ToSupervised('Sales','Product_Code',1)),
           ('1_step_diff',
              ToSupervisedDiff('1_Week_Ago_Sales',
                       'Product_Code',1,dropna=True)),
           ('predic_1',
              TimeSeriesRegressor(model=model,cv=kf))]
super_1_p = Pipeline(steps_1).fit(df)
Model_1_Error = super_1_p.score(df)
```

我们得到

> Fold: 0, Error: 0.4624 0，Error: 0.4624
> Fold: 1, Error: 0.4596 1，Error: 0.4596
> Fold: 2, Error: 0.4617 2，Error: 0.4617
> Fold: 3, Error: 0.4666 3，Error: 0.4666
> Fold: 4, Error: 0.4712 4，Error: 0.4712
> Fold: 5, Error: 0.4310 5，Error: 0.4310
> Fold: 6, Error: 0.4718 6，Error: 0.4718
> Fold: 7, Error: 0.4494 7，Error: 0.4494
> Fold: 8, Error: 0.4608 8，Error: 0.4608
> Fold: 9, Error: 0.4470 9，Error: 0.4470
> Fold: 10, Error: 0.4746 10，Error: 0.4746
> Fold: 11, Error: 0.4865 11，Error: 0.4865
> Total Error 0.4619 总错误0.4619

仿真结果表明，该模型可行，误差在减小。 让我们添加更多的滞后项再次评估模型。 由于我们建立了管道，增加更多的滞后将是非常简单的。

```python
steps_3 = [('1_step',
            ToSupervised('Sales','Product_Code',3)),
           ('1_step_diff',
            ToSupervisedDiff('1_Week_Ago_Sales','Product_Code',1)),
           ('2_step_diff',
            ToSupervisedDiff('2_Week_Ago_Sales','Product_Code',1)),
           ('3_step_diff',
            ToSupervisedDiff('3_Week_Ago_Sales',
                  'Product_Code',1,dropna=True)),
           ('predic_3',
            TimeSeriesRegressor(model=model,cv=kf,scoring=rmsle))]
super_3_p = Pipeline(steps_3).fit(df)
```

> Fold: 0, Error: 0.4312 0，Error: 0.4312
> Fold: 1, Error: 0.4385 1，Error: 0.4385
> Fold: 2, Error: 0.4274 2，Error: 0.4274
> Fold: 3, Error: 0.4194 3，Error: 0.4194
> Fold: 4, Error: 0.4479 4，Error: 0.4479
> Fold: 5, Error: 0.4070 5，Error: 0.4070
> Fold: 6, Error: 0.4395 6，Error: 0.4395
> Fold: 7, Error: 0.4333 7，Error: 0.4333
> Fold: 8, Error: 0.4387 8，Error: 0.4387
> Fold: 9, Error: 0.4305 9，Error: 0.4305
> Fold: 10, Error: 0.4591 10，Error: 0.4591
> Fold: 11, Error: 0.4534 11，Error: 0.4534
> Total Error 0.4355 总错误0.4355

结果表明，模型的预测误差再次减小，模型的学习能力增强。 我们可以继续添加滞后，看看模型的性能如何变化; 然而，我们将推迟这个过程，而是先使用 LGBM 作为一个估计器。

### 统计变换

图7所示的销售分布情况表明，数据偏向于低销售数字或左侧。 通常，当应用于偏态分布时，Log 变换是有用的，因为它们倾向于扩大降低幅度范围内的值，并倾向于压缩或减少降低幅度范围内的值。 当我们进行统计变换时，模型的可解释性会发生变化，因为系数不再告诉我们原始特征，而是告诉我们转换后的特征。 因此，当我们对销售数字应用 np.log1p 将其分布转换为更接近正态分布时，我们也对预测结果应用 np.expm1，参见 c. 6，TimeSeriesRegressorLog。 现在，我们用上面提到的转换重复计算

```python
steps_3_log = [('1_step',
                 ToSupervised('Sales','Product_Code',3)),
               ('1_step_diff',
                 ToSupervisedDiff('1_Week_Ago_Sales',
                                    'Product_Code',1)),
               ('2_step_diff',
                 ToSupervisedDiff('2_Week_Ago_Sales',
                                    'Product_Code',1)),
               ('3_step_diff',
                 ToSupervisedDiff('3_Week_Ago_Sales',
                                    'Product_Code',1,dropna=True)),
               ('predic_3',
                 TimeSeriesRegressorLog(model=model,
                                     cv=kf,scoring=rmsle))]
super_3_p_log = Pipeline(steps_3_log).fit(df)
```

所以我们有

> Fold: 0, Error: 0.4168 0，Error: 0.4168
> Fold: 1, Error: 0.4221 1，Error: 0.4221
> Fold: 2, Error: 0.4125 2，Error: 0.4125
> Fold: 3, Error: 0.4035 3，Error: 0.4035
> Fold: 4, Error: 0.4332 4，Error: 0.4332
> Fold: 5, Error: 0.3977 5，Error: 0.3977
> Fold: 6, Error: 0.4263 6，Error: 0.4263
> Fold: 7, Error: 0.4122 7，Error: 0.4122
> Fold: 8, Error: 0.4301 8，Error: 0.4301
> Fold: 9, Error: 0.4375 9，Error: 0.4375
> Fold: 10, Error: 0.4462 10，Error: 0.4462
> Fold: 11, Error: 0.4727 11，Error: 0.4727
> Total Error 0.4259 

这表明该模型的性能得到了提高，误差得到了进一步的减小。

### 集成的机器学习模型

现在，是时候使用一个更强的 ML 估计来改进预测了。 我们选择 LightGBM 作为一种新的估计器。 那么让我们重复一下计算流程

```python
model_lgb = LGBMRegressor(n_estimators=1000, learning_rate=0.01)
steps_3_log_lgbm = [('1_step',
                       ToSupervised('Sales','Product_Code',3)),
                    ('1_step_diff',
                       ToSupervisedDiff('1_Week_Ago_Sales',
                                          'Product_Code',1)),
                    ('2_step_diff',
                       ToSupervisedDiff('2_Week_Ago_Sales',
                                          'Product_Code',1)),
                    ('3_step_diff',
                       ToSupervisedDiff('3_Week_Ago_Sales',
                                          'Product_Code',1,
                                                dropna=True)),
                   ('predic_3',
                       TimeSeriesRegressorLog(model=model_lgb, 
                                              cv=kf,scoring=rmsle))]
super_3_p_log_lgbm = Pipeline(steps_3_log_lgbm).fit(df)
```

运行完的结果：

> Fold: 0, Error: 0.4081 0，
> Fold: 1, Error: 0.3980 1，
> Fold: 2, Error: 0.3953 2，
> Fold: 3, Error: 0.3949 3，
> Fold: 4, Error: 0.4202 4，
> Fold: 5, Error: 0.3768 5，
> Fold: 6, Error: 0.4039 6，
> Fold: 7, Error: 0.3868 7，
> Fold: 8, Error: 0.3984 8，
> Fold: 9, Error: 0.4075 9，
> Fold: 10, Error: 0.4209 10，
> Fold: 11, Error: 0.4520 11，
> Total Error 0.4052

同样，我们成功地改进了预测。

### 调整滞后阶数(step)

在本节中，我们将调整步长的大小(滞后 / 差异)。 我故意将这部分推迟到回归器（即 LGBM ）之后。因为它比 RF 快。 图8清楚地表明，通过增加更多的步骤，模型的误差减少; 然而，正如我们所期望的，可以看到，在通过一个阈值大约为14，进一步增加步长并不会显著减少误差。 您可能对定义迭代终止的错误阈值感兴趣， 请查阅code C 7. A and B。这里选取的阈值是Steps= 20。 。

```python
model_lgbm = LGBMRegressor(n_estimators=1000, learning_rate=0.01)
list_scores2 = stepsTune(df,TimeSeriesRegressorLog(model=model_lgbm,
                           scoring=rmsle,cv=kf,verbosity=False),20)
```



![img](https://cdn-images-1.medium.com/max/800/1*VmTkleLgTzKDfVZKBhFF5w.png)


 图8)表示调整滞后 / 差异（lags/diff，也就是x轴）的值对模型预测效果的影响。

 可以看到，通过提升步长，模型效果有了提升; 

然而，当step超过14后，模型效果的提升变得不显著了。

### 调整机器学习模型参数

在这一部分，我们将在pipeline中实现网格搜索方法进行调参，参见代码8a ，b，c。 8a是从 Sklearn借来的。 这一部分的目的不是建立一个完全调整的模型。 我们试图展示工作流程是怎样的。 稍微调整后，残差变为

> RMSLE= 0.3868

对于这两个超参数{'learning rate': 0.005,'n estimators': 1500}。

```python
params = {'n_estimators':[100,500,1000,1500,2000],
         'learning_rate':[0.005,.01,.1]}
steps_20 = getDataFramePipeline(20)
super_20 = Pipeline(steps_20).fit_transform(df)
model_lgbm2 = LGBMRegressor(random_state=0)
tune_lgbm =TimeSeriesGridSearch(model = model_lgbm2, cv = kf,
                  param_grid=params,verbosity=False,scoring=rmsle)
```

当超参调优返回的最优参数位于给定网格边缘时，意味着我们必须重新考虑网格的范围，并重新计算模型。然而在本文中我们不会这样做。

### 预测与实际销售额对

图9显示第52周的预测值与销售值的对比。 可以看出，该模型在15岁以下的销售数字上运行良好; 然而，该模型对30岁左右的销售预测不佳。 正如我们在图7中所讨论的，我们可能会为不同的销售范围建立不同的模型，以克服这个问题，并有一个更稳健的预测模型，尽管进一步的建模超出了这篇文章，这篇文章已经很长了。



![img](https://cdn-images-1.medium.com/max/800/1*kzmuH1RLfNX3gMT0mxxNoQ.png)



图9)销售额与实际销售额的预测。 可以看出，该模型适用于销售数量较少(小于15)的情况; 然而，它不适用于销售数量较大的情况。 因此，这可能是一个很好的动机，为低和高销量的商品分别构建两个模型

最后，图10显示了我们预测销售额的所有尝试。 我们以一个非常简单的假设作为基准，并尝试通过使用不同的滞后 / 差分(lags/diff)、统计变换和应用不同的机器学习算法来改进预测。 基线误差为0.516，调参后的模型误差为0.3868，这意味着误差减少了25% 。



![img](https://cdn-images-1.medium.com/max/800/1*l0LbsLO-Y9uMER-jtNgR6A.png)

图10)我们的不同的模型得分，可以减少25% 的基线误差

还有很多方法可以改进现有的模型，例如，正确地将产品作为分类变量处理，更广泛的特征工程，调整超参数，使用各种机器学习算法以及混合（blending）和堆叠（stacking）。

## 总结

我们建立了一个时间序列预测管道来预测每周的销售额：

- 我们从一个简单的逻辑假设作为基线模型（baseline model）开始; 
- 然后，我们可以通过构建一个包括基本特征工程、统计转换、应用随机森林和 LGBM 并最终调整它们的管道来减少25% 的基线误差。 
- 【重点】此外，我们还讨论了不同的时间序列交叉验证方法（思考，我们的模型并没有交叉验证）。
-  此外，我们还展示了如何使用 Sklearn 基类来构建管道。

## 代码

本文的完整代码可以在我的  [GitHub](https://github.com/pourya-ir/Medium/blob/master/Time%20Series%20Machine%20Learning%20Regression%20Framework.ipynb) 找到

Code 1.

```python
class ToSupervised(base.BaseEstimator,base.TransformerMixin):
    
    def __init__(self,col,groupCol,numLags,dropna=False):
        
        self.col = col
        self.groupCol = groupCol
        self.numLags = numLags
        self.dropna = dropna
        
    def fit(self,X,y=None):
        self.X = X
        return self
    
    def transform(self,X):
        tmp = self.X.copy()
        for i in range(1,self.numLags+1):
            tmp[str(i)+'_Week_Ago'+"_"+self.col] =
              tmp.groupby([self.groupCol])[self.col].shift(i) 
            
        if self.dropna:
            tmp = tmp.dropna()
            tmp = tmp.reset_index(drop=True)
            
        
            
        return tmp
```

Code 2.



```python
class ToSupervisedDiff(base.BaseEstimator,base.TransformerMixin):
    
    def __init__(self,col,groupCol,numLags,dropna=False):
        
        self.col = col
        self.groupCol = groupCol
        self.numLags = numLags
        self.dropna = dropna
        
    def fit(self,X,y=None):
        self.X = X
        return self
    
    def transform(self,X):
        tmp = self.X.copy()
        for i in range(1,self.numLags+1):
            tmp[str(i)+'_Week_Ago_Diff_'+"_"+self.col] = 
               tmp.groupby([self.groupCol])[self.col].diff(i) 
            
        if self.dropna:
            tmp = tmp.dropna()
            tmp = tmp.reset_index(drop=True)
            
        return tmp
```

Code 3.



```python
from itertools import chain
class Kfold_time(object):
    
    def __init__(self,**options):
        
        
        self.target     = options.pop('target', None)
        self.date_col   = options.pop('date_col', None)
        self.date_init  = options.pop('date_init', None)
        self.date_final = options.pop('date_final', None)
        if options:
            raise TypeError("Invalid parameters passed: %s" %
                               str(options))
            
        if ((self.target==None )|(self.date_col==None )|
            (self.date_init==None )|(self.date_final==None )):
             
             raise TypeError("Incomplete inputs")
    
    def _train_test_split_time(self,X):
        n_arrays = len(X)
        if n_arrays == 0:
            raise ValueError("At least one array required as input")
         for i in range(self.date_init,self.date_final):
            train = X[X[self.date_col] < i]
            val   = X[X[self.date_col] == i]
             X_train, X_test = train.drop([self.target], axis=1),
                                val.drop([self.target], axis=1)
            y_train, y_test = train[self.target].values,
                               val[self.target].values
            yield X_train, X_test, y_train, y_test
     def split(self,X):
        cv_t = self._train_test_split_time(X)
        return chain(cv_t)
```

Code 4.

```
class BaseEstimator(base.BaseEstimator, base.RegressorMixin):
    def __init__(self, predCol):
        """
            As a base model we assume the number of sales 
            last week and this week are the same
            Input: 
                    predCol: l-week ago sales
        """
        self.predCol = predCol
    def fit(self, X, y):
        return self
    def predict(self, X):
        prediction = X[self.predCol].values
        return prediction
    def score(self, X, y,scoring):
        
        prediction = self.predict(X)
    
        error =scoring(y, prediction)
        return error
```

Code 5.

```python
class TimeSeriesRegressor(base.BaseEstimator, base.RegressorMixin):
    
    def __init__(self,model,cv,scoring,verbosity=True):
        self.model = model
        self.cv = cv
        self.verbosity = verbosity
        self.scoring = scoring 
        
            
    def fit(self,X,y=None):
        return self
        
    
    def predict(self,X=None):
        
        pred = {}
        for indx,fold in enumerate(self.cv.split(X)):
            X_train, X_test, y_train, y_test = fold    
            self.model.fit(X_train, y_train)
            pred[str(indx)+'_fold'] = self.model.predict(X_test)
            
        prediction = pd.DataFrame(pred)
    
        return prediction
    def score(self,X,y=None):
        errors = []
        for indx,fold in enumerate(self.cv.split(X)):
            X_train, X_test, y_train, y_test = fold    
            self.model.fit(X_train, y_train)
            prediction = self.model.predict(X_test)
            error = self.scoring(y_test, prediction)
            errors.append(error)
            if self.verbosity:
                print("Fold: {}, Error: {:.4f}".format(indx,error))
         if self.verbosity:
            print('Total Error {:.4f}'.format(np.mean(errors)))
        return errors
```

Code 6.



```python
class TimeSeriesRegressorLog(base.BaseEstimator,
                                 base.RegressorMixin):
    
    def __init__(self,model,cv,scoring,verbosity=True):
        self.model = model
        self.cv = cv
        self.verbosity = verbosity
        self.scoring = scoring
        
            
    def fit(self,X,y=None):
        return self
        
    
    def predict(self,X=None):
        
        pred = {}
        for indx,fold in enumerate(self.cv.split(X)):
            X_train, X_test, y_train, y_test = fold    
            self.model.fit(X_train, y_train)
            pred[str(indx)+'_fold'] = self.model.predict(X_test)
            
        prediction = pd.DataFrame(pred)
    
        return prediction
    def score(self,X,y=None):#**options):
        errors = []
        for indx,fold in enumerate(self.cv.split(X)):
            X_train, X_test, y_train, y_test = fold    
            self.model.fit(X_train, np.log1p(y_train))
            prediction = np.expm1(self.model.predict(X_test))
            error = self.scoring(y_test, prediction)
            errors.append(error)
            if self.verbosity:
                print("Fold: {}, Error: {:.4f}".format(indx,error))
        if self.verbosity:
            print('Total Error {:.4f}'.format(np.mean(errors)))
        return errors
```

Code 7.



A:

```python
def getDataFramePipeline(i):
    steps = [(str(i)+'_step',
              ToSupervised('Sales','Product_Code',i))]
    for j in range(1,i+1):
        if i==j:
            pp = (str(j)+'_step_diff',
                  ToSupervisedDiff(str(i)+'_Week_Ago_Sales',
                                   'Product_Code',1,dropna=True))
            steps.append(pp)
        else:
            pp = (str(j)+'_step_diff',  
                  ToSupervisedDiff(str(i)+'_Week_Ago_Sales',
                                   'Product_Code',1))
            steps.append(pp)
            
    return steps
```

B:



```python
from tqdm import tqdm
def stepsTune(X,model,num_steps,init=1):
    scores = []
    for i in tqdm(range(init,num_steps+1)):
        steps = []
        steps.extend(getDataFramePipeline(i))
        steps.append(('predic_1',model))
        super_ = Pipeline(steps).fit(X)
        score_ = np.mean(super_.score(X))
        scores.append((i,score_))
        
    return scores
```

Code 8.

A:

```python
from collections.abc import Mapping, Sequence, Iterable
from itertools import product
from functools import partial, reduce
import operator
class TimeGridBasic(base.BaseEstimator, base.RegressorMixin):
    
    def __init__(self,param_grid):
        
    
        if not isinstance(param_grid, (Mapping, Iterable)):
                raise TypeError('Parameter grid is not a dict or '
                                'a list ({!r})'.format(param_grid))
        if isinstance(param_grid, Mapping):
                # wrap dictionary in a singleton list to support
                  either dict
                # or list of dicts
                param_grid = [param_grid]
        if isinstance(param_grid, Mapping):
                # wrap dictionary in a singleton list to support
                  either dict
                # or list of dicts
                param_grid = [param_grid]
        # check if all entries are dictionaries of lists
        for grid in param_grid:
            if not isinstance(grid, dict):
                raise TypeError('Parameter grid is not a '
                                'dict ({!r})'.format(grid))
            for key in grid:
                if not isinstance(grid[key], Iterable):
                    raise TypeError('Parameter grid value is not
                                     iterable '
                                    '(key={!r}, value={!r})'
                                    .format(key, grid[key]))
        self.param_grid = param_grid
                
    def __iter__(self):
        """Iterate over the points in the grid.
        Returns
        -------
        params : iterator over dict of string to any
            Yields dictionaries mapping each estimator parameter to
            one of its
            allowed values.
        """
        for p in self.param_grid:
            # Always sort the keys of a dictionary, for
             reproducibility
            items = sorted(p.items())
            if not items:
                yield {}
            else:
                keys, values = zip(*items)
                for v in product(*values):
                    params = dict(zip(keys, v))
                    yield params
```

B:

```python
class TimeSeriesGridSearch(TimeGridBasic,base.BaseEstimator,
                              base.RegressorMixin):
    
    
    def __init__(self,**options):
        
        self.model      = options.pop('model', None)
        self.cv         = options.pop('cv', None)
        self.verbosity  = options.pop('verbosity', False)
        self.scoring    = options.pop('scoring', None)
        param_grid      = options.pop('param_grid', None)
        self.param_grid = TimeGridBasic(param_grid)
        
        if options:
            raise TypeError("Invalid parameters passed: %s" %
                              str(options))
        if ((self.model==None )| (self.cv==None)):
            raise TypeError("Incomplete inputs")
            
            
    def fit(self,X,y=None):
        self.X = X
        return self
    def _get_score(self,param):
        errors = []
        for indx,fold in enumerate(self.cv.split(self.X)):
            X_train, X_test, y_train, y_test = fold    
            self.model.set_params(**param).fit(X_train, y_train)
            prediction = self.model.predict(X_test)
            error = self.scoring(y_test, prediction)
            errors.append(error)
            if self.verbosity:
                print("Fold: {}, Error: {:.4f}".format(indx,error))
        if self.verbosity:
            print('Total Error {:.4f}'.format(np.mean(errors)))
                
        
        return errors
     def score(self):
        errors=[]
        get_param = []
        for param in self.param_grid:
            
            if self.verbosity:
                print(param)
                
            errors.append(np.mean(self._get_score(param)))
            get_param.append(param)
        self.sorted_errors,self.sorted_params = 
          (list(t) for t in zip(*sorted(zip(errors,get_param))))
        
        return self.sorted_errors,self.sorted_params
    
    
    def best_estimator(self,verbosity=False):
        if verbosity:
            print('error: {:.4f} \n'.format(self.sorted_errors[0]))
            print('Best params:')
            print(self.sorted_params[0])
        return self.sorted_params[0]
```

