[TOC]

# 1.引言

利用深度学习的最新进展来预测股票价格走势

![img](https://cdn-images-1.medium.com/max/1600/1*h6eC4YRmN1JDbnJO4kd11A.jpeg)

完整结构概述

> Link to the complete notebook: 链接到完整的笔记本:<https://github.com/borisbanushev/stockpredictionai>


在这个笔记本中，我将创建一个预测股票价格走势的完整流程。 继续下去，我们将取得一些相当不错的结果。 为了达到这个目的，我们将使用生成对抗体网络(Generative Adversarial Network，GAN)，LSTM 作为generator，CNN 作为discriminator。 我们使用 LSTM 显然是为了预测时间序列数据。 为什么我们使用 GAN，特别是 CNN 作为discriminator？ 这是一个很好的问题: 后面会有专门的章节讨论。

成功训练 GAN 的非常棘手的部分是获得正确的超参数集。 出于这个原因，我们将使用贝叶斯优化(和高斯过程)和深强化学习(DRL)来决定何时以及如何改变 GAN 的超参数(探索与开发的困境)。 在构建强化学习模型时，我将使用该领域的最新进展，如**Rainbow** 和 **PPO**。

我们将使用不同类型的输入数据。 除了股票的历史交易数据和技术指标，我们将使用 

- NLP 的最新进展(BERT，一种 NLP 的迁移学习)来创建情感分析(作为基本面分析的一个来源) ，

- 傅里叶变换来提取总体趋势方向

- 堆叠式自动编码器（ **stacked autoencoders** ）来识别其他高级特征

- Eigen 投资组合来寻找相关资产

-  ARIMA模型来预测股票价格

以获取尽可能多的关于股票的信息，模式，相关性 等

为了创建所有的神经网络，将使用 MXNet 及其高级 API ー Gluon，并在多个 gpu 上训练它们。[链接](https://medium.com/p/2edd6fac689d#42bb)。

准确地预测股票变动是一项复杂的任务，因为一只股票朝着特定的方向运动有数以百万计的事件和前提条件。 所以我们需要尽可能多地捕捉这些前提条件。 我们还需要做出几个重要的假设: 

- 1)市场不是100% 随机的，
- 2)历史重复，
- 3)市场遵循人们的理性行为，
- 4)市场是"完美的"。 

------

# 2. 数据


我们需要了解是什么影响了高盛的股价是上涨还是下跌。 这是人们作为一个整体的想法。 我们需要纳入尽可能多的信息(描述股票从不同的方面和角度)。我们将使用以下几类特征:

1. 相关资产ーー这些是其他资产(任何类型，不一定是股票，如大宗商品、外汇、指数，甚至固定收益证券)。 像高盛这样的大公司显然不是生活在一个孤立的世界里ーー它依赖许多外部因素，并与之互动，包括竞争对手、客户、全球经济、地缘政治形势（ geo-political situation）、财政和货币政策、获得资本的途径等等。 具体细节稍后列出
2. 技术指标ーー许多投资者追随技术指标。 我们将包括最流行的指标作为独立的特征。 其中ー7天和21天移动平均线、指数移动平均线、动量、布林带（Bollinger bands）、 MACD
3. 基本面分析ーー一股票是上升还是下降的非常重要的特征。 有两个特征可以用于基本面分析: 
    1. 使用10-K 和10-Q 报告分析公司业绩，分析净资产收益率（ROE）和市盈率（PE）等(我们不会使用这个) 
    2. 新闻——潜在的新闻可以显示即将发生的事件，可能会推动股票朝某个方向走。 我们将阅读高盛的所有每日新闻，并摘录当天对高盛的总体情绪是积极的、中性的，还是消极的(得分从0到1)。 随着许多投资者密切关注新闻，并根据新闻(当然是部分)做出投资决策，如果(比如说)高盛今天的消息极为乐观，那么该股明天将大幅飙升的可能性有些高。 最重要的一点，稍后我们将对每个特征(包括这个特征)执行特征重要性(这意味着它对于 GS 的移动有多么重要) ，并决定是否使用它。 稍后将详细介绍。 为了创建准确的情绪预测，我们将使用神经语言处理(NLP)。 我们将使用 BERT ー Google 最近宣布的NLP的迁移学习方法，进行新闻情绪提取进而进行情感分类。
4. 傅立叶变换ーー除了每日收盘价外，我们将创建傅立叶变换，以概括几个长期和短期趋势。 使用这些变换，我们将消除大量的噪音(随机游动) ，并构建逼近真正的股票运动的信号。 近似的趋势可以帮助 LSTM 网络更准确地预测趋势。
5. ARIMA模型时间序列(ARIMA)ー这是预测时间序列数据未来值(在神经网络之前的时代)最流行的技术之一。 让我们添加它，看看它是否是一个重要的有预测性的特征。
6. 堆叠式自动编码器ー大多数上述特征(基本分析，技术分析等)是人们经过几十年的研究发现的。 但也许我们漏掉了什么。 也许由于海量的数据点、事件、资产、图表等等，人们无法理解其中隐藏的相关性。 通过堆叠式自动编码器(一种神经网络) ，我们可以利用计算机的能力，并可能发现影响股票走势的新类型的特征。 尽管我们无法理解人类语言中的这些特征，但我们将在 GAN 中使用它们。
7. 使用**深度非监督式学习**对期权价格异常检测。 我们将使用另一个特征ーー我们会添加每天的高盛股票90天看涨期权的价格。 期权定价本身包含了大量的数据。 期权合约的价格取决于股票的未来价值(分析师也试图预测价格，以便为看涨期权提供最准确的价格)。 使用深度非监督式学习(Self-organized Maps) ，我们将尝试在每天的定价中发现异常。 异常(例如定价的剧烈变化)可能隐含着一个事件，这个事件可能有助于 LSTM 了解整个股票模式。

接下来，有了这么多特征，我们需要执行几个重要步骤:

1. 对数据的"质量"进行统计检查： 如果我们创建的数据是有缺陷的，那么无论我们的算法多么复杂，结果都不会是正面的。 这些检查包括确保数据不受异方差性、多重共线性或序列相关性的影响
2. 特性重要性： 如果一个特征(例如另一只股票或一个技术指标)与我们想要预测的股票没有解释力，那么我们就没有必要在神经网络的训练中使用它。 我们将使用 XGBoost (eXtreme Gradient Boosting) ，这是一种增强的回归树算法


作为我们数据准备的最后一步，我们还将使用主成分分析(PCA)创建特征投资组合，以降低由自动编码器创建的特征的维数。

```python
print('There are {} number of days in the dataset.'.format(dataset_ex_df.shape[0]))
output >>> There are 2265 number of days in the dataset.
```

下图是高盛过去九年的股票价格（2010年1月1日至2018年12月31日的每日收盘价），7年用于训练，2年用于验证。 虚线垂直线表示训练数据和测试数据的分割线。

![img](https://cdn-images-1.medium.com/max/1600/1*eHeqBsFLcfMzDIvyL01-eg.png)

 高盛股票价格(纽约证券交易所: GS)

## 2.1. 相关资产

正如前面解释的，我们将使用其他资产作为特征，而不仅仅是GS(高盛)。

那么，还有哪些资产会影响 GS 的股价走势呢？ 对公司、业务范围、竞争环境、依赖性、供应商和客户类型等有良好的了解，对于选择正确的相关资产非常重要:

- 首先是与 GS 类似的公司。 我们将把摩根大通和摩根士丹利等公司加入到数据集中
- 作为一家投资银行，高盛依赖全球经济。 糟糕或动荡的经济意味着没有并购（M&A）或首次公开发行(ipo) ，自营交易（proprietary trading）收益可能受损。 这就是为什么我们将包括全球经济指数。 此外，我们还将包括伦敦银行同业拆借利率(LIBOR，以美元和英镑计价) ，因为分析师设定这些利率可能会对经济造成冲击，以及其他金融工具证券
- Daily volatility index (**VIX**)  日波动率指数(VIX)ーー原因如前所述
- **Composite indices** ()综合指数）：例如纳斯达克（NASDAQ）和纽约证券交易所(NYSE)、 FTSE100(英国)、 Nikkei225(日本)、恒生指数和 BSE Sensex 指数
- **Currencies**  货币ーー全球贸易多次反映在货币的走势上，因此我们将使用一篮子货币(如美元兑日元、 GBPUSD 等)作为特征

我们的数据集中还有72种其他资产ーー每种资产的每日价格 

## 2.2. 技术指标

我们已经讨论了什么是技术指标，以及为什么要使用它们，所以让我们直接跳到代码。 我们将为GS 构建技术指标。

```python
""" Function to create the technical indicators """
def get_technical_indicators(dataset):
    # Create 7 and 21 days Moving Average
    dataset['ma7'] = dataset['price'].rolling(window=7).mean()
    dataset['ma21'] = dataset['price'].rolling(window=21).mean()
    
    # Create MACD
    dataset['26ema'] = pd.ewma(dataset['price'], span=26)
    dataset['12ema'] = pd.ewma(dataset['price'], span=12)
    dataset['MACD'] = (dataset['12ema']-dataset['26ema'])
# Create Bollinger Bands
    dataset['20sd'] = pd.stats.moments.rolling_std(dataset['price'],20)
    dataset['upper_band'] = dataset['ma21'] + (dataset['20sd']*2)
    dataset['lower_band'] = dataset['ma21'] - (dataset['20sd']*2)
    
    # Create Exponential moving average
    dataset['ema'] = dataset['price'].ewm(com=0.5).mean()
    
    # Create Momentum
    dataset['momentum'] = dataset['price']-1
    
    return dataset
```

所以我们有每个交易日的技术指标(包括 MACD，Bollinger 波段，等等)。 我们总共有12个技术指标。

让我们看一下这些指标过去400天的情况。



![img](https://cdn-images-1.medium.com/max/1600/1*TQEcFB7KMrM0x6Dp1l-LEQ.png)

高盛的技术指标ーー过去400天


## 2.3. 基本面分析

对于基本面分析，我们将对所有关于 GS 的日常新闻进行情感分析。 在最后使用 sigmoid，结果在0到1之间。 得分越接近0，负面消息就越多(接近1表示正面情绪)。对每一天我们构建一个日均得分(介于0和1之间) ，将它作为一个特征加入。


### 2.3.1.  BERT


为了将新闻分为正面或负面(或中性) ，我们将使用 [BERT](https://arxiv.org/abs/1810.04805)，这是一种预训练的语言表征。

预训练的 BERT 模型在MXNet/Gluon中已经可用。 我们只需要实例化他们，并添加两个(或任意数量)`Dense`层，接着使用softmax计算出1个得分。

```python
import bert
```



## 2.4. 使用傅里叶变换做趋势分析


**傅里叶变换**用来对函数做一次变换，产生一系列正弦波(具有不同的振幅和帧)。 合并这些正弦波后得到的信号近似于原函数。 从数学的角度来说，变换看起来是这样的:

![img](https://cdn-images-1.medium.com/max/1600/1*64AWoIDiBdVJLw5KkkqzOw.png)


我们将使用傅立叶变换提取 GS 股票的全局和局部趋势，同时也减少一些噪音：s

```python
""" Code to create the Fuorier trasfrom  """
data_FT = dataset_ex_df[['Date', 'GS']]
close_fft = np.fft.fft(np.asarray(data_FT['GS'].tolist()))
fft_df = pd.DataFrame({'fft':close_fft})
fft_df['absolute'] = fft_df['fft'].apply(lambda x: np.abs(x))
fft_df['angle'] = fft_df['fft'].apply(lambda x: np.angle(x))
plt.figure(figsize=(14, 7), dpi=100)
fft_list = np.asarray(fft_df['fft'].tolist())
for num_ in [3, 6, 9, 100]:
    fft_list_m10= np.copy(fft_list); fft_list_m10[num_:-num_]=0
    plt.plot(np.fft.ifft(fft_list_m10), label='Fourier transform with {} components'.format(num_))
plt.plot(data_FT['GS'],  label='Real')
plt.xlabel('Days')
plt.ylabel('USD')
plt.title('Figure 3: Goldman Sachs (close) stock prices & Fourier transforms')
plt.legend()
plt.show()
```



![img](https://cdn-images-1.medium.com/max/1600/1*UTWq-m6nsWp4NrlP47NGhw.png)

图3: 高盛股票的傅里叶变换


正如图3所示，我们使用的傅里叶变换分量越多，逼近函数就越接近真实的股票价格(100个成分的转换几乎与原始函数相同ー红线和紫线几乎重叠)。 我们使用傅立叶变换来提取长期和短期趋势，因此我们将分别使用3、6和9个成分的转换。 可以推断出，包含3个成分的转换表示长期趋势。


另一种用来去除数据噪声的技术叫做 **小波**。 小波和傅里叶变换给出了类似的结果，所以我们只使用傅立叶变换。


## 2.5. 使用ARIMA作为特征


**Arima**是一种时间序列数据的预测技术。我们将展示如何使用它，虽然我们最终不会使用ARIMA预测，但我们将用它来降噪，并(可能)提取一些新的模式或特征。

![img](https://cdn-images-1.medium.com/max/1600/1*sp4wrN9u3XkMCT5r3oaNQA.png)

在高盛股票上应用ARIMA

```python
error = mean_squared_error(test, predictions)
print('Test MSE: %.3f' % error)
output >>> Test MSE: 10.151
```

从图5中看到的，ARIMA 给出了一个非常好的股票价格近似值。 我们将使用 ARIMA 的预测价格作为 LSTM 的输入特征，因为正如我们之前提到的，我们希望捕捉尽可能多的关于高盛股票的特征和模式。 我们去测试 MSE (均方差)的10.151，这本身是一个不错的结果(考虑到我们确实有很多测试数据) ，但是，我们仍然只使用它作为 LSTM 的一个特征。

## 2.6. 统计检测

确保数据具有良好的质量对于我们的模型非常重要。 为了确保我们的数据是合适的，我们将执行一些简单的检查，以确保我们实现和观察的结果是真实的，而不是由于假设数据分布错误而受到损失。


### 2.6.1. 异方差，多重共线性，序列相关

- **异方差（Conditional Heteroskedasticity）**：当误差项(回归预测值与实际值之差)依赖于数据时，就会发生条件异方差性，例如，当数据点(沿 x 轴)增长时，误差项就会增长。
- **多重共线性（Multicollinearity）**：多重共线性是指错误项(也称为残差)相关。
- **序列相关（Serial correlation）**：  序列相关是当一个数据(特征)是另一个特征的表达式，或者完全依赖另外一个特征。

这里我们不会深入讨论代码，因为它很简单，而且我们的重点更多地放在深度学习部分，但是数据是定性的。


## 2.7. 特征工程

```python
print('Total dataset has {} samples, and {} features.'.format(dataset_total_df.shape[0],                                                          dataset_total_df.shape[1]))
output >>> Total dataset has 2265 samples, and 112 features.
```

因此，在添加了所有类型的数据(相关资产、技术指标、基本面分析、傅立叶和 Arima)之后，我们在2265天内总共有112个特征(然而，正如前面提到的，只有1585天用于训练数据)。我们还有一些自动编码器生成的特征。


### 2.7.1. 使用 XGBoost计算特性重要性

拥有如此多的特征之后，我们必须考虑是否所有这些特性都能预测 GS股票的走势。 例如，我们在数据集中包括了以美元计价的伦敦银行同业拆借利率（LIBOR），因为我们认为伦敦银行同业拆借利率的变化可能预示着经济的变化，相应的，可能预示着 GS 股票行为的变化。 但是我们需要测试。 有许多方法可以测试特征的重要性，但是我们将要应用XGBoost，因为它在分类和回归问题上都提供了最好的结果。

由于特征数据非常大，为了在这里进行演示，我们将只使用技术指标。 在真正的特征重要性测试时，所有特征都很重要，所以我们不扔掉任何特征，而是直接训练GAN。

```python
regressor = xgb.XGBRegressor(gamma=0.0,n_estimators=150,base_score=0.7,colsample_bytree=1,learning_rate=0.05)
xgbModel = regressor.fit(X_train_FI,y_train_FI, eval_set = [(X_train_FI, y_train_FI), (X_test_FI, y_test_FI)], verbose=False)
fig = plt.figure(figsize=(8,8))
plt.xticks(rotation='vertical')
plt.bar([i for i in range(len(xgbModel.feature_importances_))], xgbModel.feature_importances_.tolist(), tick_label=X_test_FI.columns)
plt.title('Figure 6: Feature importance of the technical indicators.')
plt.show()
```



![img](https://cdn-images-1.medium.com/max/1600/1*rWs7xnMkjm7V6R7v5QhstA.png)

使用XGBoost 的特性重要性

毫不奇怪(对于那些有股票交易经验的人来说) ，MA7、 MACD 和 BB 是其中的重要特征。


我按照同样的逻辑对整个数据集执行特征重要性操作ーー训练花费了更长的时间，而且结果有点难以解读，和只有少数几个特征的情况相比。


## 2.8. 基于堆叠自编码器提取高级特征

在我们继续使用自编码器之前，我们将探索一种替代的激活函数。


### 2.8.1. 激活函数ー GELU (Gaussian Error)

最近提出了 GELU- [link](https://arxiv.org/pdf/1606.08415.pdf). 作者在论文中给出了几个实例，结果表明使用 GELU 作为激活函数的神经网络优于使用 ReLU 作为激活函数的神经网络。BERT中也使用了GELU，这是我们用于新闻情感分析的 NLP 方法。

我们将使用 GELU 作为自动编码器。

**注意**: 下面的单元格显示了 GELU 数学背后的逻辑。 它并不是一个激活函数的真实实现。 我必须在 MXNet 中实现 GELU。 如果您将代码从 `act_type='relu'` 改为 `act_type='gelu'`，它不起作用，除非您更改 MXNet 的实现。 对整个项目发出请求，以访问 GELU 的 MXNet 实现。

让我们可视化 GELU、 ReLU 和 LeakyReLU (最后一个主要用于 GANs ——我们也使用它)。

```python
def gelu(x):
    return 0.5 * x * (1 + math.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * math.pow(x, 3))))
def relu(x):
    return max(x, 0)
def lrelu(x):
    return max(0.01*x, x)
plt.figure(figsize=(15, 5))
plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=.5, hspace=None)
ranges_ = (-10, 3, .25)
plt.subplot(1, 2, 1)
plt.plot([i for i in np.arange(*ranges_)], [relu(i) for i in np.arange(*ranges_)], label='ReLU', marker='.')
plt.plot([i for i in np.arange(*ranges_)], [gelu(i) for i in np.arange(*ranges_)], label='GELU')
plt.hlines(0, -10, 3, colors='gray', linestyles='--', label='0')
plt.title('Figure 7: GELU as an activation function for autoencoders')
plt.ylabel('f(x) for GELU and ReLU')
plt.xlabel('x')
plt.legend()
plt.subplot(1, 2, 2)
plt.plot([i for i in np.arange(*ranges_)], [lrelu(i) for i in np.arange(*ranges_)], label='Leaky ReLU')
plt.hlines(0, -10, 3, colors='gray', linestyles='--', label='0')
plt.ylabel('f(x) for Leaky ReLU')
plt.xlabel('x')
plt.title('Figure 8: LeakyReLU')
plt.legend()
plt.show()
```



![img](https://cdn-images-1.medium.com/max/1600/1*XAJdlKP_tHY6dWuTnKc6lg.png)

Gelu、 ReLU 和 LeakyReLU 的比较

**注意**: 在这个笔记本的未来版本中，我将尝试使用 **U-Net** ([link](https://arxiv.org/abs/1505.04597))，并尝试利用卷积层提取(和创建)更多股票的运动模式的特征。 现在，我们将只使用一个简单的自编码器只从`dense`层。

好了，回到自动编码器，下面描述(图像只是示意图，它不代表真正的layers，units。

**注意**: 在后面的版本中讨论的一件事情是移除decoder的最后一层。 一般情况下，在autoencoders中encoders的数量等于decoders的数量。 但是，我们希望提取更高级别的特征(而不是创建相同的输入) ，所以我们就可以跳过decoders的最后一层。 在训练期间，我们用相同数量的层来构建编码器和解码器，但是当我们创建输出时，我们使用了倒数第二层，因为它包含了更高层次的特征。



![img](https://cdn-images-1.medium.com/max/1600/1*-9iJNftM1g9eYksBNNTLyQ.jpeg)





我们从autoencoder中构建了112个特征。 由于我们只想要高层次的特征(整体模式) ，我们对112个特征使用主成分分析分析(PCA)。 这将减少数据的维度(列数)。 

注意: 再一次，这是纯实验性的。 我不能100% 确定所描述的逻辑是否正确。 就像人工智能和深度学习中的其他东西一样，这是一门艺术，需要实验。


# 3 生成对抗网络(GAN)

![img](https://cdn-images-1.medium.com/max/1600/1*hN0QKvuY4n07jxQCwRSmpg.jpeg)

GAN的架构图



GANs是如何工作的？

一个 GAN 网络由两个模型组成: 一个Generator(G)和Discriminator(D)。 训练GANS的步骤如下:

1. Generator：使用随机数据(**z**)生成数据，试图使"生成"的数据与真实数据难以区分，或者非常接近真实数据。 其目的是学习真实数据的分布。
2. Discriminator就是一个分类器，通过学习真实的和生成的数据，来判断数据是来自Generator还是真实世界的。 D估计输入样本在真实数据集分布上的概率。 (两种分布的更多信息参考3.2 ).
3. 然后，将 G 和 D 的losses合并，并向后传播给generator。 因此，generator的loss取决于generator和Discriminator。 这一步能帮助 Generator 更好的学习真实数据的分布。 如果Generator不能很好地生成真实数据(即跟真实数据有相同的分布) ，那么Discriminator就很容易区分出真实的和生成的。 因此，Discriminator的损失将非常小。 小的Discriminator损失会导致较大的generator损失。这使得构建discriminator有点棘手，因为太好的Discriminator总是会导致巨大的generator损失，使generator无法学习。
4.  这个过程一直持续，直到Discriminator不能从区分真实数据和生成数据。

当D和G组合在一起时，D和G就像在玩一个极小极大的游戏(Generator试图愚弄Discriminator，使它增加了生成数据的概率，即最小化$$ E_z ∼ p_z (z)[ log (1-d (g (z)))]$$。 Discriminator希望通过最大化 $$E_x ∼ p_r (x)[ logD (x)]$$来分离来自Generator的数据$$ D(G (z))$$的数据。 然而，在分离了损失函数之后，我们还不清楚如何将这两个函数聚合在一起(这就是为什么我们使用了一些进阶版的gans，如 Wasserstein GAN)。 总的来说，综合损失函数看起来像:

注意: 训练GANS的资料可以在这里找到。 [here](https://github.com/soumith/ganhacks).


## 3.1. 为什么使用GAN 用于股票市场预测

生成式对抗网络(GAN)最近主要用于创造逼真的图像、绘画和视频剪辑。GAN在预测时间序列数据方面的应用并不多，就像我们的例子一样。 然而，主要思想应该是相同的ーー我们希望预测未来的股市走势。 在未来，GS 股票的模式和行为应该或多或少跟历史是相同的(除非它开始以一种完全不同的方式运作，或者经济发生巨大的变化)。 因此，我们希望为未来"生成"数据，这些数据的分布与我们已有的数据——历史交易数据——相似(当然不是完全相同)。 因此，在理论上可行。

## 3.2. Metropolis-Hastings GAN 和 Wasserstein GAN

####  I. Metropolis-Hastings GAN(MHGAN)

Uber的工程团队最近对传统的 GANs 进行了改进，称为 Metropolis-Hastings GAN (MHGAN)。 Uber 方法背后的理念(他们是这么说的)有点类似于谷歌和加州大学伯克利分校创造的另一种方法——**Discriminator Rejection Sampling** ([DRS](https://arxiv.org/pdf/1810.06758.pdf))。 基本上，当我们训练 GAN 时，我们使用D的唯一目的是更好地训练G。 通常，在对 GAN训练好后，我们不再使用D。 然而，MHGAN 和 DRS 试图使用D来选择G生成的样本中接近真实数据分布的数据(MHGAN 和 DRS的细微差别在于 MHGAN 使用马尔科夫蒙特卡洛(MCMC)进行抽样)。

MHGAN从G中产生K个样本($$x_0'$$到$$ x_K'$$) ，并依次传入D,让D决定是否保留。 


图10: MHGAN 的可视化表示(来自最初的 Uber 帖子)。



![img](https://cdn-images-1.medium.com/max/1600/1*0iif-P3BGvCfDlsziH5xcg.png)

#### II. Wasserstein GAN

训练GANs是相当困难的。 模型可能永远不会收敛，模式崩溃很容易发生。 我们将使用 GAN改良版--**Wasserstein** GAN 。

同样，我们不会详细讨论，但最值得注意的是:GANs 背后的主要目标是让 Generator 开始将随机噪声转换成我们想要模拟的给定数据。 因此，比较两个分布之间的相似性在GANS中是非常必要的。 使用最广泛的两个指标是:
  - **KL Divergence** (Kullback–Leibler) ：Kl 散度， 当 p (x)等于 q (x)时，DKL 为零,

  - **JS Divergence** (Jensen–Shannon). Js 散度以0和1为界，与 KL 散度不同，JS 散度是对称的、平滑的。 当损失从 KL 转换到 JS 发散时，GAN训练取得了显著的成功

Wasserstein 距离：WGAN 使用 Wasserstein 距离。与 KL 和 JS 散度相比，Wasserstein 度量给出了一个平滑的度量(在发散中没有突然的跳跃)。 这使得它更适合在梯度下降法期间创建一个稳定的训练过程。另外，与 KL 和 JS 相比，Wasserstein 距离几乎处处可微。 正如我们所知，在反向传播过程中，我们对损失函数求导，从而求梯度，进而更新权重。 因此，有一个可微的损失函数是相当重要的。


## 3.4. The Generator — 单层 RNN

### 3.4.1. Lstm 或 GRU


前面已经提到generator是LSTM ，它是一种Rnn。 Rnn常用于时间序列数据，因为它能记录历史数据，并可以捕捉随时间变化的模式。 由于 RNNs 的特性，它们经常受到梯度消失的困扰，也就是说，在训练过程中权值的变化变得很小，以至于它们不会发生变化，使得网络不能收敛到最小的损失(当梯度变得太大时，有时也会出现相反的问题)。 这就是所谓的梯度爆炸，但解决这个问题相当简单---- 如果梯度开始超过某个常数，那么就对梯度clip掉，即梯度clip。 针对这一问题，提出了门控循环单元(GRU)和长短时记忆(LSTM)两种改进算法。 两者最大的区别是: 

- 1) GRU 有2个门(更新和重置) ，LSTM 有4个门(更新、输入、忘记和输出) ，
- 2) LSTM 保持内存状态，而 GRU 没有，
- 3) LSTM 在输出门之前使用非线性(sigmoid) ，而 GRU 没有。


在大多数情况下，LSTM 和 GRU 在准确性方面给出了类似的结果，但是 GRU 的计算强度要小得多，因为 GRU 的训练参数要少得多。 然而，lstm应用更多。

严格地说，LSTM 单元(gate)的数学公式:



![img](https://cdn-images-1.medium.com/max/1600/1*DUeR85B1raizYc_heyeRRA.png)

 LSTM cell背后的数学，其中⊙是点乘运算符，对于所有的 $$x= [ x_1，x_2，... ，x_k ]^T \in R^k $$,两个激活函数:



![img](https://cdn-images-1.medium.com/max/1600/1*nyZL1-UP-AZQ6vNXRi34kQ.png)

### 3.4.2. Lstm 结构

Lstm 结构非常简单: 一个 LSTM 层有112个输入units(因为我们在数据集中有112个特征)和500个隐藏units，一个`Dense`层有1个输出——每天的价格。 初始化式是 Xavier，我们将使用 L1损失。

注意: 在代码中你可以看到我们使用 Adam (学习率为. 01)作为优化器。 现在不要太在意这一点——有一节专门解释我们使用的超参数(学习速率被排除在外，因为我们有学习速率调度器——3.4.3节) 以及我们如何优化这些超参数-第3.6节。

```python
gan_num_features = dataset_total_df.shape[1]
sequence_length = 17
class RNNModel(gluon.Block):
    def __init__(self, num_embed, num_hidden, num_layers, bidirectional=False, sequence_length=sequence_length, **kwargs):
        super(RNNModel, self).__init__(**kwargs)
        self.num_hidden = num_hidden
        with self.name_scope():
            self.rnn = rnn.LSTM(num_hidden, num_layers, input_size=num_embed, bidirectional=bidirectional, layout='TNC')
            self.decoder = nn.Dense(1, in_units=num_hidden)
    
    def forward(self, inputs, hidden):
        output, hidden = self.rnn(inputs, hidden)
        decoded = self.decoder(output.reshape((-1,self.num_hidden)))
        return decoded, hidden
    
    def begin_state(self, *args, **kwargs):
        return self.rnn.begin_state(*args, **kwargs)
    
lstm_model = RNNModel(num_embed=gan_num_features, num_hidden=500, num_layers=1)
lstm_model.collect_params().initialize(mx.init.Xavier(), ctx=mx.cpu())
trainer = gluon.Trainer(lstm_model.collect_params(), 'adam', {'learning_rate': .01})
loss = gluon.loss.L1Loss()
```


我们将在 LSTM 层使用500个神经元(neurons)，并使用 Xavier 初始化。 我们将使用 L1作为正规化。 让我们看看MXNet 的`LSTM` 中有什么。

```python
print(lstm_model)
output >>>
RNNModel(
   (rnn): LSTM(112 -> 500, TNC)
   (decoder): Dense(500 -> 1, linear)
)
```

我们可以看到，LSTM 的输入是112个特征(`dataset_total_df.shape[1]`)。然后LSTM 层有500个神经元，然后转换成一个单一的输出-股票价值。


Lstm 背后的逻辑是: 我们用17天(`sequence_length`)的数据(同样，这些数据是 GS 股票每天的股票价格 + 该日相关资产的所有其他特征，情感等) ，并试图预测第18天。 然后我们把17天窗口往前滑动一天，再次预测第18天。 我们在整个数据集(当然是批处理)像这样迭代。


在另一篇文章中，我将探讨修改普通的 LSTM 是否会更有益，例如:

- 使用双向 LSTM layers：在理论上，向后(从数据集的末端到开始)可能有助于 LSTM 找出股票的运动模式
- 使用堆叠 RNN 结构：不仅有一个 LSTM 层，而且有2个或更多层。 然而，这可能是危险的，因为我们可能会过拟合，因为我们没有太多的数据(我们只有1585天的数据)
- 探索 GRU ーー正如已经解释过的，GRUs 的cells要简单得多
- 向RNN添加注意力向量



### 3.4.3. 学习速率scheduler

最重要的超参数之一是学习率。 在训练神经网络时，设置几乎每个优化器(如 SGD、 Adam 或 RMSProp)的学习速率至关重要，因为它控制着网络的收敛速度和最终性能。 最简单的学习率策略之一是在整个训练过程中有一个固定的学习率。 选择一个小的学习速率可以让优化器找到好的解决方案，但是这是以限制初始收敛速度为代价的。 随着时间的推移，改变学习速率可以克服这种权衡。


最近的一些论文，比如 [这个](https://arxiv.org/pdf/1806.01593.pdf) ，展示了在训练过程中改变全局学习速度的好处，包括收敛性和时间。 让我们画出每个epoch的学习速率。

```python
schedule = CyclicalSchedule(TriangularSchedule, min_lr=0.5, max_lr=2, cycle_length=500)
iterations=1500
plt.plot([i+1 for i in range(iterations)],[schedule(i) for i in range(iterations)])
plt.title('Learning rate for each epoch')
plt.xlabel("Epoch")
plt.ylabel("Learning Rate")
plt.show()
```

![img](https://cdn-images-1.medium.com/max/1600/1*kY6bUOtF9AlyUBwei8Noug.png)

### 3.4.4. 如何防止过拟合和偏差-方差权衡


神经网络有很多的特征，我们需要确保我们没有过拟合。我们使用了几种技术来防止过拟合(不仅在 LSTM 中，而且在 CNN 和自动编码器中) :

- **确保数据质量**。 我们已经进行了统计检查，确保数据不会受到多重共线性或序列自相关的影响。 进一步，我们对每个特征进行了特征重要性检查。 最后，初始特征选择(例如选择相关资产、技术指标等)是利用股票市场运行机制的一些领域知识完成的
- **正规化(或加权惩罚**):最常用的两种正则化技术是 LASSO (L1)和 Ridge (L2)。L 1加上平均绝对误差 mean absolute error ，l 2加上均方差。 在不涉及太多数学细节的情况下，它们的基本区别是: L1同时进行变量选择和参数收缩，而岭回归只进行参数收缩，最终包括模型中的所有系数。 在存在相关变量的情况下，岭回归可能是首选。 此外，岭回归工作最好的情况下，最小二乘估计有较高的方差。 因此，这取决于我们的模型目标。 这两种调整的影响是完全不同的。 L1正则化使得 L1正则化函数在零点处是不可微的。 L2正则化倾向于更小的权重，但 L1正则化倾向于权重趋于零。 因此，使用 L1正则化，您可以得到一个稀疏模型ー一个参数较少的模型。 在这两种情况下，L1和 L2正则化模型的参数"收缩"，但在 L1正则化情况下，收缩直接影响模型的复杂性(参数数目)。 确切地说，岭回归在最小二乘估计方差较大的情况下效果最好。 L1对异常值更具鲁棒性，在数据稀疏时使用，并创建特征的重要性。 我们将使用 L1
- **Dropout**.  Dropout层随机删除隐藏层中的节点
- **Dense-sparse-dense training**. ：稠疏稠密训练， [链接](https://arxiv.org/pdf/1607.04381v1.pdf) 
- **Early stopping**. 提前终止迭代


建立复杂神经网络的另一个重要考虑因素是偏差-方差权衡。 基本上，训练网络的误差是偏差、方差和不可忽略的误差$$\sigma$$(噪声和随机性造成的误差)的函数。 最简单的折衷公式是: $$Error=bias^2+variance+\sigma.$$

- 偏见： 偏差衡量一个经过训练的(训练数据集上的)算法在看不见的数据上的概括能力。 高偏差(欠拟合)意味着该模型不能很好地处理未知数据。
- 方差。 方差度量模型对数据集变化的敏感性。 高方差是过度拟合


## 3.5. Discriminator--一维cnn

### 3.5.1. 为什么使用 CNN作为discriminator？

我们通常使用 cnn 处理与图像相关的工作(图像分类、上下文提取等)。 它们在提取特征方面功能非常强大。 例如，在狗的图像中，第一卷积层将检测边缘，第二层将开始检测圆圈，第三层将检测鼻子。 在我们的案例中，数据点形成小趋势，小趋势形成大趋势，趋势反过来形成模式。 Cnn 检测特征的能力可用于提取 GS 股票价格波动模式的信息。


使用 CNN 的另一个原因是 CNN 能很好地处理空间数据ーー也就是说，相互靠近的数据点彼此之间的联系要比散布在各处的数据点之间的联系更加紧密。 这对于时间序列数据来说也是适用的。 在我们的例子中，每个数据点(每个特征)都是连续的每一天。 人们自然而然地认为，两天的时间越接近，彼此之间的关系就越密切。 还需要考虑的一件事(尽管本文没有涉及)是季节性以及它可能如何改变(如果有的话) CNN 的工作。

注意: 和这个笔记本的其他部分一样，使用 CNN 获取时间序列数据是实验性的。 我们将检查结果，而不提供数学或其他证明。 使用不同的数据、激活函数等，结果可能会有所不同。


### 3.5.2.  CNN的结构

![img](https://cdn-images-1.medium.com/max/1600/1*My1hiYMJeYWIBbuUQJfqKg.jpeg)

 CNN 模型的体系结构

我们将只显示由 MXNet的 CNN。

```python
Sequential(
   (0): Conv1D(None -> 32, kernel_size=(5,), stride=(2,)) 
   (1): LeakyReLU(0.01) 
   (2): Conv1D(None -> 64, kernel_size=(5,), stride=(2,)) 
   (3): LeakyReLU(0.01) 
   (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None) 
   (5): Conv1D(None -> 128, kernel_size=(5,), stride=(2,)) 
   (6): LeakyReLU(0.01) 
   (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None) 
   (8): Dense(None -> 220, linear) 
   (9): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=None) 
   (10): LeakyReLU(0.01) 
   (11): Dense(None -> 220, linear) 
   (12): Activation(relu) 
   (13): Dense(None -> 1, linear) 
)
```

## 3.6. 超参


我们将跟踪和优化的超参数是:

- `batch_size` :  LSTM 和 CNN 的批量大小
- `cnn_lr`: CNN 的学习速度
- `strides`: CNN的strides
- `lrelu_alpha`: GAN中LeakyReLU 的 alpha
- `batchnorm_momentum`:  CNN中正则化的动量
- `padding`: CNN的填充
- `kernel_size`:1CNN中核函数大小
- `dropout`:  LSTM 的dropout
- `filters`: 过滤器个数的初始值

我们将训练200多轮`epochs`。


# 4. 超参优化

当 GAN 在训练完200个epochs后，它将记录 MAE (这是 LSTM，GG 中的错误函数) ，并将其作为奖励值传递给强化学习，后者将决定后面的训练中是否改变超参。 正如后面所描述的，这种方法严格地用于 RL 的实验。

如果 RL 决定更新超参数，它将调用`Bayesian optimisation`库(下面讨论)，它将提供next step段对超参数的最佳估计。


## 4.1. 使用强化学习优化超参


为什么我们要在超参数优化中使用强化学习？ 股票市场一直在变化。 即使我们设法训练我们的 GAN 和 LSTM 来创建极其精确的结果，结果可能只在一定时期内有效。 也就是说，我们需要不断优化整个过程。 为了优化过程，我们可以:

- 添加或删除特征（例如添加可能相关的新股票或货币)
- 改进我们的深度学习模式。 改进模型的最重要的方法之一是通过超参数(在第5节中列出)。 一旦找到了一组特定的超参数，我们就需要决定什么时候更改它们，什么时候使用已知的超参数集(探索与开发)。 同时，股票市场是一个依赖于数百万个参数的连续空间

**注意**: 这本笔记本的整个强化学习部分的目的是更多的研究导向。 我们将使用GAN作为背景探索不同 RL 方法。 有许多方法可以成功地对我们的深度学习模型进行超参数优化，而无需使用 RL。 但是... 为什么不呢。


注: 接下来的几节假设你有一些 RL 的知识，特别是policy方法和Q-learning。


### 4.1.1. 强化学习理论

在没有解释 RL 的基础知识的情况下，我们将跳转到实现的具体方法的细节。 我们将使用无模型 RL 算法，显然是因为我们不了解整个经济环境，因此不能定义环经济境如何运作的模型ーー如果有的话，我们就不需要预测股票价格的走势ーー他们只会遵循这个模型。 回到正题，我们将使用无模型 RL的两个子集: 策略优化和 Q-learning。

- **Q-learning** ：在 Q-learning中 ，我们学习从给定**state**状态采取某个**action**行动的**value**（值）。 Q 值是采取行动后的预期收益。 我们将使用 **Rainbow**，它是七个Q-learning算法的组合。
- **Policy Optimization**(策略优化) ：在策略优化中，我们从给定状态，去学习采取何种行动。(如果我们使用像 actor / critic 这样的方法)我们还可以知道处于给定状态下的值。 

建立 RL 算法的一个关键是准确地设置奖励函数（reward）。 它必须捕获环境的所有方面以及代理与环境的交互。 我们将奖励定义为 **R**:
$$Reward=2∗lossG+lossD+accuracyG$$

其中， lossG, accuracyG, and lossD 分别是Generator的损失和准确率，以及Discriminator的损失。 环境是 **GAN**和 LSTM 训练的结果。 不同的agents可以采取的行动是如何改变 GAN的D和G的超参数。

#### 4.1.1.1. **什么是Rainbow?**


**Rainbow** ([链接](https://arxiv.org/pdf/1710.02298.pdf)) 是一种基于 q 学习的非策略深度强化学习算法，它将7种算法结合在一起:

- **DQN**：Dqn 是q learning算法的一个扩展，它使用神经网络来表示Q value。 类似于有监督(深度)学习，在 DQN中，我们训练一个神经网络，并试图最小化损失函数。 我们通过随机采样转换(state, action, reward)来训练网络。 这些层不仅可以是完全连接的，还可以是卷积的。
- **Double Q Learning**：处理 Q learning中的一个大问题，即高偏差（overestimation bias）。
- **Prioritized replay**（优先重放）： 在普通 DQN 中，所有transitions都存储在重播缓冲区（replay buffer）中，它从这个缓冲区均匀采样。 然而，并不是所有的transitions在学习阶段都同样有益(这也使得学习效率低下，因为需要更多的episodes)。 经验优先的重放（Prioritized experience replay）不是均匀采样，而是根据一个概率分布采样，这个分布对那些前几次迭代中具有高Q loss的transition，给予更高的概率。
- **Dueling networks.** （决斗网络）： 决斗网络稍微改变了 Q learning的结构，它使用两个独立的流(即拥有两个不同的微型神经网络)。 一个流是为了价值，一个流是为了advantage。 它们都共享一个卷积编码器。 棘手的部分是流的合并ー它使用了一个特殊的聚合器(Wang 等人，2016)
优点，公式是$$ A(s,a)=Q(s,a)−V(s),$$ ，一般来说作为一个动作（Q(s,a)）与一个特定状态下的平均动作（V(s)）的比较。 当一个"错误"的action不能用负的reward来惩罚时，Advantages会被使用，也就是说advantage会进一步奖励相对平均行为来说的好行为。)

- **Multi-step learning.** （多步学习）。 多步学习背后最大的区别是它使用 n 步返回值(不仅仅是下一步返回值)来计算Q-values，这自然应该更准确

- **Distributional RL**（分布式RL）：Q learning采用估计Q-value的平均值作为目标。 然而，在许多情况下，q 值在不同situations下可能是不一样的。 分布式 RL 可以直接学习(或近似) Q-values的分布，而不是求平均值。 同样，数学要比这复杂得多，但对我们来说，好处是Q-values的采样更准确。
- **Noisy Nets**：基本的DQN 实现了一个简单的$$\epsilon-greedy$$机制来进行探索。 这种探索方法有时效率不高。  Noisy Nets处理这个问题的方法是，添加一个噪声线性层。 随着时间的推移，网络将学会如何忽略噪音(作为一个添加的噪声流)。 但是考虑到状态探索，这种学习方法在不同的状态空间中的学习速度不一样。

#### 4.1.1.2. Proximal Policy Optimization

**Proximal Policy Optimization** ([最近策略优化](https://arxiv.org/pdf/1707.06347.pdf)) 是一种无模型的策略优化强化学习. 它比其他算法实现起来简单得多，并且得到了很好的结果。

我们为什么要使用 PPO？ 

- Ppo 的优点之一是它可以直接学习策略，而不是通过values间接学习( 如Q Learnin使用  Q-values学习策略)。 它可以很好的应用在连续动作空间中，可以学习(通过均值和标准差)分布概率(如果softmax作为一个输出)。

- 策略梯度方法的问题在于，它们对步长的选择极为敏感ーー如果步长较小，则进展时间过长(很可能主要是由于需要一个二阶导数矩阵) ; 如果步长较大，则存在大量噪声，从而显著降低了性能。 由于策略的变化(也会因为reward和observations的分布发生变化)，输入数据是非平稳的。 与监督式学习相比，选择不当的步骤可能更具破坏性，因为它影响到下一次访问的概率分布。 Ppo 可以解决这些问题。 更重要的是，与其他一些方法相比，PPO更简单，例如， ACER 就需要额外的代码来保持非策略关联性，还需要一个重放缓冲区（replay buffer），**TRPO**  对代理目标函数有约束条件（新旧策略之间的 KL 差异)。 这种约束可以控制policy不会变化太大ーー也可能会造成不稳定。 Ppo可以减少计算量(由约束创建)，它将代理目标函数的截断到[1-，1 + ]区间，并且在目标函数中增加一个更新的惩罚项 。


注意: 代码可以在这里找到。[here](https://github.com/openai/baselines).


### 4.1.2. 关于强化学习的进一步工作


关于进一步探索强化学习的一些想法:

- 使用增强随机搜索(**Augmented Random Search** ([链接](https://arxiv.org/pdf/1803.07055.pdf)) )作为替代算法。 该算法的作者(来自加州大学伯克利分校)已经实现了与其他最先进的方法(如 PPO)类似的奖励结果，但平均要快15倍
- 选择reward函数是非常重要的。我会尝试使用不同的reward函数
- 使用**Curiosity**作为一种探索策略
- 按照伯克利人工智能研究团队(BAIR)ー [链接](https://bair.berkeley.edu/blog/2018/12/12/rllib/). 的提议，创建多agent 结构


## 4.2. 贝叶斯优化

我们将使用贝叶斯优化，而不是网格搜索，这需要花费大量的时间来寻找超参数的最佳组合。 我们将要使用的库已经有人实现了ー  [链接](https://github.com/fmfn/BayesianOptimization).。


### 4.2.1. 高斯过程


![img](https://cdn-images-1.medium.com/max/1600/1*JCO5-noInHvLHeZaqU5Saw.png)

贝叶斯超参数优化的高斯过程



# 5. 结果

最后，测试数据用作输入后，我们将比较不同阶段的 LSTM 的输出。

1. 第一轮epoch后画图

```python
from utils import plot_prediction
plot_prediction('Predicted and Real price - after first epoch.')
```


![img](https://cdn-images-1.medium.com/max/1600/1*uKkExoSy4o6zo3dwfPoPwg.png)

2. 50轮epoch后画图

```python
plot_prediction('Predicted and Real price - after first 50 epochs.')
```



![img](https://cdn-images-1.medium.com/max/1600/1*cqfAntAtxKMw-eo8s1b3MA.png)

```python
plot_prediction('Predicted and Real price - after first 200 epochs.')
```


![img](https://cdn-images-1.medium.com/max/1600/1*-VuHm3t1eGQMziCU7xjcVA.png)

The RL run for ten episodes (we define an eposide to be one full GAN training on the 200 epochs.)

 RL运行10episodes(我们定义了一次episodes是一个完整的GAN训练200个epochs。)

```python
plot_prediction('Final result.')
```

![img](https://cdn-images-1.medium.com/max/1600/1*FeWF_24neEhH9Gpra1DGmA.png)

对比arima

![img](https://cdn-images-1.medium.com/max/1600/1*sp4wrN9u3XkMCT5r3oaNQA.png)

下一步，我将尝试将所有事情分开，并提供一些关于什么起作用以及为什么起作用的分析。 为什么我们会得到这样的结果，仅仅是巧合吗？ 所以请继续关注


# 6 总结

构造时序预测模型(历史数据lstm) ---- >

构造包含更多信息的时序预测模型(多源输入+特征工程+lstm) ---- >

构造包含更多信息的更精准的时序预测模型(多源输入+特征工程+GAN，GAN=lstm + cnn）---->

构造包含更多信息的更精准的能随时自动调整超参的时序预测模型(多源输入+特征工程+GAN + RL+BO，GAN=lstm + cnn)

RL决定要不要更新超参

BO决定超参应该更新到什么值

